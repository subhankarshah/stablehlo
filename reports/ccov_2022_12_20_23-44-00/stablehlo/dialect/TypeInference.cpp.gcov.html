<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - cov.info - stablehlo/dialect/TypeInference.cpp</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">stablehlo/dialect</a> - TypeInference.cpp<span style="font-size: 80%;"> (source / <a href="TypeInference.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">cov.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">1535</td>
            <td class="headerCovTableEntry">1570</td>
            <td class="headerCovTableEntryHi">97.8 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2022-12-20 23:44:01</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">83</td>
            <td class="headerCovTableEntry">83</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* Copyright 2019 The TensorFlow Authors. All Rights Reserved.</a>
<a name="2"><span class="lineNum">       2 </span>            :    Copyright 2022 The StableHLO Authors.</a>
<a name="3"><span class="lineNum">       3 </span>            : </a>
<a name="4"><span class="lineNum">       4 </span>            : Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</a>
<a name="5"><span class="lineNum">       5 </span>            : you may not use this file except in compliance with the License.</a>
<a name="6"><span class="lineNum">       6 </span>            : You may obtain a copy of the License at</a>
<a name="7"><span class="lineNum">       7 </span>            : </a>
<a name="8"><span class="lineNum">       8 </span>            :     http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="9"><span class="lineNum">       9 </span>            : </a>
<a name="10"><span class="lineNum">      10 </span>            : Unless required by applicable law or agreed to in writing, software</a>
<a name="11"><span class="lineNum">      11 </span>            : distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</a>
<a name="12"><span class="lineNum">      12 </span>            : WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</a>
<a name="13"><span class="lineNum">      13 </span>            : See the License for the specific language governing permissions and</a>
<a name="14"><span class="lineNum">      14 </span>            : limitations under the License.</a>
<a name="15"><span class="lineNum">      15 </span>            : ==============================================================================*/</a>
<a name="16"><span class="lineNum">      16 </span>            : </a>
<a name="17"><span class="lineNum">      17 </span>            : #include &quot;stablehlo/dialect/TypeInference.h&quot;</a>
<a name="18"><span class="lineNum">      18 </span>            : </a>
<a name="19"><span class="lineNum">      19 </span>            : #include &lt;assert.h&gt;</a>
<a name="20"><span class="lineNum">      20 </span>            : #include &lt;stddef.h&gt;</a>
<a name="21"><span class="lineNum">      21 </span>            : #include &lt;stdint.h&gt;</a>
<a name="22"><span class="lineNum">      22 </span>            : </a>
<a name="23"><span class="lineNum">      23 </span>            : #include &lt;algorithm&gt;</a>
<a name="24"><span class="lineNum">      24 </span>            : #include &lt;array&gt;</a>
<a name="25"><span class="lineNum">      25 </span>            : #include &lt;cstdint&gt;</a>
<a name="26"><span class="lineNum">      26 </span>            : #include &lt;functional&gt;</a>
<a name="27"><span class="lineNum">      27 </span>            : #include &lt;numeric&gt;</a>
<a name="28"><span class="lineNum">      28 </span>            : #include &lt;set&gt;</a>
<a name="29"><span class="lineNum">      29 </span>            : #include &lt;unordered_map&gt;</a>
<a name="30"><span class="lineNum">      30 </span>            : #include &lt;utility&gt;</a>
<a name="31"><span class="lineNum">      31 </span>            : </a>
<a name="32"><span class="lineNum">      32 </span>            : #include &quot;llvm/ADT/APInt.h&quot;</a>
<a name="33"><span class="lineNum">      33 </span>            : #include &quot;llvm/ADT/ArrayRef.h&quot;</a>
<a name="34"><span class="lineNum">      34 </span>            : #include &quot;llvm/ADT/DenseMap.h&quot;</a>
<a name="35"><span class="lineNum">      35 </span>            : #include &quot;llvm/ADT/STLExtras.h&quot;</a>
<a name="36"><span class="lineNum">      36 </span>            : #include &quot;llvm/ADT/SmallSet.h&quot;</a>
<a name="37"><span class="lineNum">      37 </span>            : #include &quot;llvm/ADT/SmallVector.h&quot;</a>
<a name="38"><span class="lineNum">      38 </span>            : #include &quot;llvm/ADT/StringExtras.h&quot;</a>
<a name="39"><span class="lineNum">      39 </span>            : #include &quot;llvm/ADT/StringRef.h&quot;</a>
<a name="40"><span class="lineNum">      40 </span>            : #include &quot;llvm/ADT/Twine.h&quot;</a>
<a name="41"><span class="lineNum">      41 </span>            : #include &quot;llvm/ADT/iterator_range.h&quot;</a>
<a name="42"><span class="lineNum">      42 </span>            : #include &quot;llvm/Support/Casting.h&quot;</a>
<a name="43"><span class="lineNum">      43 </span>            : #include &quot;llvm/Support/MathExtras.h&quot;</a>
<a name="44"><span class="lineNum">      44 </span>            : #include &quot;mlir/IR/Attributes.h&quot;</a>
<a name="45"><span class="lineNum">      45 </span>            : #include &quot;mlir/IR/BuiltinAttributes.h&quot;</a>
<a name="46"><span class="lineNum">      46 </span>            : #include &quot;mlir/IR/BuiltinTypes.h&quot;</a>
<a name="47"><span class="lineNum">      47 </span>            : #include &quot;mlir/IR/Diagnostics.h&quot;</a>
<a name="48"><span class="lineNum">      48 </span>            : #include &quot;mlir/IR/Location.h&quot;</a>
<a name="49"><span class="lineNum">      49 </span>            : #include &quot;mlir/IR/Operation.h&quot;</a>
<a name="50"><span class="lineNum">      50 </span>            : #include &quot;mlir/IR/OperationSupport.h&quot;</a>
<a name="51"><span class="lineNum">      51 </span>            : #include &quot;mlir/IR/TypeUtilities.h&quot;</a>
<a name="52"><span class="lineNum">      52 </span>            : #include &quot;mlir/IR/Types.h&quot;</a>
<a name="53"><span class="lineNum">      53 </span>            : #include &quot;mlir/IR/Value.h&quot;</a>
<a name="54"><span class="lineNum">      54 </span>            : #include &quot;mlir/Interfaces/InferTypeOpInterface.h&quot;</a>
<a name="55"><span class="lineNum">      55 </span>            : #include &quot;mlir/Support/LLVM.h&quot;</a>
<a name="56"><span class="lineNum">      56 </span>            : #include &quot;mlir/Support/LogicalResult.h&quot;</a>
<a name="57"><span class="lineNum">      57 </span>            : #include &quot;stablehlo/dialect/AssemblyFormat.h&quot;</a>
<a name="58"><span class="lineNum">      58 </span>            : #include &quot;stablehlo/dialect/Base.h&quot;</a>
<a name="59"><span class="lineNum">      59 </span>            : </a>
<a name="60"><span class="lineNum">      60 </span>            : namespace mlir {</a>
<a name="61"><span class="lineNum">      61 </span>            : namespace hlo {</a>
<a name="62"><span class="lineNum">      62 </span>            : </a>
<a name="63"><span class="lineNum">      63 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="64"><span class="lineNum">      64 </span>            : // Utils for shape functions.</a>
<a name="65"><span class="lineNum">      65 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="66"><span class="lineNum">      66 </span>            : </a>
<a name="67"><span class="lineNum">      67 </span>            : // Checks if the vector `nums` has duplicates.</a>
<a name="68"><span class="lineNum">      68 </span><span class="lineCov">         54 : const auto hasDuplicates = [](const ArrayRef&lt;int64_t&gt; nums) {</span></a>
<a name="69"><span class="lineNum">      69 </span><span class="lineCov">         54 :   llvm::SmallDenseSet&lt;int64_t&gt; set(nums.begin(), nums.end());</span></a>
<a name="70"><span class="lineNum">      70 </span><span class="lineCov">         54 :   return set.size() != nums.size();</span></a>
<a name="71"><span class="lineNum">      71 </span><span class="lineCov">         54 : };</span></a>
<a name="72"><span class="lineNum">      72 </span>            : </a>
<a name="73"><span class="lineNum">      73 </span>            : // Return true if type1 and type2 are tensors and have the same</a>
<a name="74"><span class="lineNum">      74 </span>            : // element-type, else return false. With float element-types, ignore comparing</a>
<a name="75"><span class="lineNum">      75 </span>            : // floating-point precision if ignoreFpPrecision is True.</a>
<a name="76"><span class="lineNum">      76 </span><span class="lineCov">       2139 : bool tensorsHaveSameElType(Type type1, Type type2, bool ignoreFpPrecision) {</span></a>
<a name="77"><span class="lineNum">      77 </span><span class="lineCov">       2139 :   auto tensorTy1 = type1.dyn_cast&lt;TensorType&gt;();</span></a>
<a name="78"><span class="lineNum">      78 </span><span class="lineCov">       2139 :   auto tensorTy2 = type2.dyn_cast&lt;TensorType&gt;();</span></a>
<a name="79"><span class="lineNum">      79 </span>            : </a>
<a name="80"><span class="lineNum">      80 </span><span class="lineCov">       2139 :   if (!tensorTy1 || !tensorTy2) return false;</span></a>
<a name="81"><span class="lineNum">      81 </span>            : </a>
<a name="82"><span class="lineNum">      82 </span><span class="lineCov">       2139 :   if (ignoreFpPrecision &amp;&amp; tensorTy1.getElementType().isa&lt;FloatType&gt;() &amp;&amp;</span></a>
<a name="83"><span class="lineNum">      83 </span><span class="lineCov">       1328 :       tensorTy2.getElementType().isa&lt;FloatType&gt;())</span></a>
<a name="84"><span class="lineNum">      84 </span><span class="lineCov">       1306 :     return true;</span></a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span><span class="lineCov">        833 :   return tensorTy1.getElementType() == tensorTy2.getElementType();</span></a>
<a name="87"><span class="lineNum">      87 </span><span class="lineCov">       2139 : }</span></a>
<a name="88"><span class="lineNum">      88 </span>            : </a>
<a name="89"><span class="lineNum">      89 </span>            : // Return true if type1 and type2 are shape-compatible and have same element</a>
<a name="90"><span class="lineNum">      90 </span>            : // type. If 'ignoreFpPrecision' is True, then allow floats with different</a>
<a name="91"><span class="lineNum">      91 </span>            : // precisions while checking element-types.</a>
<a name="92"><span class="lineNum">      92 </span><span class="lineCov">       1695 : bool compatibleShapeAndElementType(Type type1, Type type2,</span></a>
<a name="93"><span class="lineNum">      93 </span><span class="lineCov">       1695 :                                    bool ignoreFpPrecision) {</span></a>
<a name="94"><span class="lineNum">      94 </span><span class="lineCov">       1695 :   if (failed(verifyCompatibleShape(type1, type2))) return false;</span></a>
<a name="95"><span class="lineNum">      95 </span><span class="lineCov">       3374 :   return tensorsHaveSameElType(type1.cast&lt;ShapedType&gt;(),</span></a>
<a name="96"><span class="lineNum">      96 </span><span class="lineCov">       1687 :                                type2.cast&lt;ShapedType&gt;(), ignoreFpPrecision);</span></a>
<a name="97"><span class="lineNum">      97 </span><span class="lineCov">       1695 : }</span></a>
<a name="98"><span class="lineNum">      98 </span>            : </a>
<a name="99"><span class="lineNum">      99 </span>            : // Convert a 1D dense int64 attribute to a list of values.</a>
<a name="100"><span class="lineNum">     100 </span><span class="lineCov">        938 : FailureOr&lt;SmallVector&lt;int64_t&gt;&gt; convert1DAttribute(</span></a>
<a name="101"><span class="lineNum">     101 </span>            :     Optional&lt;DenseIntElementsAttr&gt; optionalAttr, Optional&lt;Location&gt; loc,</a>
<a name="102"><span class="lineNum">     102 </span><span class="lineCov">        938 :     StringRef attrName) {</span></a>
<a name="103"><span class="lineNum">     103 </span><span class="lineCov">        938 :   if (!optionalAttr.has_value()) return SmallVector&lt;int64_t&gt;{};</span></a>
<a name="104"><span class="lineNum">     104 </span>            : </a>
<a name="105"><span class="lineNum">     105 </span><span class="lineCov">        730 :   DenseIntElementsAttr attr = *optionalAttr;</span></a>
<a name="106"><span class="lineNum">     106 </span><span class="lineCov">        730 :   auto attrType = attr.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="107"><span class="lineNum">     107 </span><span class="lineCov">        730 :   if (attrType.getRank() != 1)</span></a>
<a name="108"><span class="lineNum">     108 </span><span class="lineCov">         20 :     return emitOptionalError(loc, &quot;expects the shape of &quot;, attrName,</span></a>
<a name="109"><span class="lineNum">     109 </span>            :                              &quot; attribute to be 1-D, but got {&quot;,</a>
<a name="110"><span class="lineNum">     110 </span><span class="lineCov">         10 :                              attrType.getShape(), &quot;}.&quot;);</span></a>
<a name="111"><span class="lineNum">     111 </span><span class="lineCov">        720 :   auto values = attr.getValues&lt;int64_t&gt;();</span></a>
<a name="112"><span class="lineNum">     112 </span><span class="lineCov">        720 :   return SmallVector&lt;int64_t&gt;{values.begin(), values.end()};</span></a>
<a name="113"><span class="lineNum">     113 </span><span class="lineCov">        938 : }</span></a>
<a name="114"><span class="lineNum">     114 </span>            : </a>
<a name="115"><span class="lineNum">     115 </span>            : // Convert a Nx2 dense int64 padding attribute to a list of tuples.</a>
<a name="116"><span class="lineNum">     116 </span><span class="lineCov">        280 : FailureOr&lt;SmallVector&lt;std::pair&lt;int64_t, int64_t&gt;&gt;&gt; convertPaddingAttribute(</span></a>
<a name="117"><span class="lineNum">     117 </span><span class="lineCov">        280 :     Optional&lt;DenseIntElementsAttr&gt; optionalAttr, Optional&lt;Location&gt; loc) {</span></a>
<a name="118"><span class="lineNum">     118 </span><span class="lineCov">        280 :   if (!optionalAttr.has_value())</span></a>
<a name="119"><span class="lineNum">     119 </span><span class="lineCov">         18 :     return SmallVector&lt;std::pair&lt;int64_t, int64_t&gt;&gt;{};</span></a>
<a name="120"><span class="lineNum">     120 </span>            : </a>
<a name="121"><span class="lineNum">     121 </span><span class="lineCov">        262 :   DenseIntElementsAttr attr = *optionalAttr;</span></a>
<a name="122"><span class="lineNum">     122 </span><span class="lineCov">        262 :   auto attrType = attr.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="123"><span class="lineNum">     123 </span><span class="lineCov">        262 :   if (attrType.getRank() != 2 || attrType.getShape()[1] != 2)</span></a>
<a name="124"><span class="lineNum">     124 </span><span class="lineCov">          4 :     return emitOptionalError(</span></a>
<a name="125"><span class="lineNum">     125 </span><span class="lineCov">          4 :         loc, &quot;expects the shape of padding-attribute to be {N, 2}, but got {&quot;,</span></a>
<a name="126"><span class="lineNum">     126 </span><span class="lineCov">          4 :         attrType.getShape(), &quot;}.&quot;);</span></a>
<a name="127"><span class="lineNum">     127 </span>            : </a>
<a name="128"><span class="lineNum">     128 </span><span class="lineCov">        258 :   auto it = attr.getValues&lt;int64_t&gt;().begin();</span></a>
<a name="129"><span class="lineNum">     129 </span><span class="lineCov">        258 :   SmallVector&lt;std::pair&lt;int64_t, int64_t&gt;&gt; out(attr.getNumElements() / 2);</span></a>
<a name="130"><span class="lineNum">     130 </span><span class="lineCov">        858 :   for (auto&amp; item : out) {</span></a>
<a name="131"><span class="lineNum">     131 </span><span class="lineCov">        600 :     int64_t first = *it;</span></a>
<a name="132"><span class="lineNum">     132 </span><span class="lineCov">        600 :     ++it;</span></a>
<a name="133"><span class="lineNum">     133 </span><span class="lineCov">        600 :     int64_t second = *it;</span></a>
<a name="134"><span class="lineNum">     134 </span><span class="lineCov">        600 :     ++it;</span></a>
<a name="135"><span class="lineNum">     135 </span><span class="lineCov">        600 :     item = {first, second};</span></a>
<a name="136"><span class="lineNum">     136 </span><span class="lineCov">        600 :   }</span></a>
<a name="137"><span class="lineNum">     137 </span><span class="lineCov">        258 :   return out;</span></a>
<a name="138"><span class="lineNum">     138 </span><span class="lineCov">        280 : }</span></a>
<a name="139"><span class="lineNum">     139 </span>            : </a>
<a name="140"><span class="lineNum">     140 </span>            : // Convert a 1D dense bool attribute to a list of values.</a>
<a name="141"><span class="lineNum">     141 </span><span class="lineCov">        228 : FailureOr&lt;SmallVector&lt;bool&gt;&gt; convertWindowReversalAttribute(</span></a>
<a name="142"><span class="lineNum">     142 </span>            :     Optional&lt;DenseElementsAttr&gt; optionalAttr, Optional&lt;Location&gt; loc,</a>
<a name="143"><span class="lineNum">     143 </span><span class="lineCov">        228 :     StringRef attrName) {</span></a>
<a name="144"><span class="lineNum">     144 </span><span class="lineCov">        228 :   if (!optionalAttr.has_value()) return SmallVector&lt;bool&gt;{};</span></a>
<a name="145"><span class="lineNum">     145 </span>            : </a>
<a name="146"><span class="lineNum">     146 </span><span class="lineCov">         20 :   DenseElementsAttr attr = *optionalAttr;</span></a>
<a name="147"><span class="lineNum">     147 </span><span class="lineCov">         20 :   auto attrType = attr.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="148"><span class="lineNum">     148 </span><span class="lineCov">         20 :   if (attrType.getRank() != 1)</span></a>
<a name="149"><span class="lineNum">     149 </span><span class="lineNoCov">          0 :     return emitOptionalError(loc, &quot;expects the shape of &quot;, attrName,</span></a>
<a name="150"><span class="lineNum">     150 </span>            :                              &quot; attribute to be 1-D, but got {&quot;,</a>
<a name="151"><span class="lineNum">     151 </span><span class="lineNoCov">          0 :                              attrType.getShape(), &quot;}.&quot;);</span></a>
<a name="152"><span class="lineNum">     152 </span><span class="lineCov">         20 :   auto values = attr.getValues&lt;bool&gt;();</span></a>
<a name="153"><span class="lineNum">     153 </span><span class="lineCov">         20 :   return SmallVector&lt;bool&gt;{values.begin(), values.end()};</span></a>
<a name="154"><span class="lineNum">     154 </span><span class="lineCov">        228 : }</span></a>
<a name="155"><span class="lineNum">     155 </span>            : </a>
<a name="156"><span class="lineNum">     156 </span>            : // If a window with the given bound in some dimension is dilated with the given</a>
<a name="157"><span class="lineNum">     157 </span>            : // dilation factor in that dimension, then the value returned is the bound for</a>
<a name="158"><span class="lineNum">     158 </span>            : // the array in that dimension after dilation.</a>
<a name="159"><span class="lineNum">     159 </span>            : //</a>
<a name="160"><span class="lineNum">     160 </span>            : // For a 1D array with 3 entries 1, 2, 3, a dilation factor of 2 yields a new</a>
<a name="161"><span class="lineNum">     161 </span>            : // window with values 1, x, 2, x, 3, where x indicates holes left by the</a>
<a name="162"><span class="lineNum">     162 </span>            : // dilation. So DilatedBound(3, 2) == 5.</a>
<a name="163"><span class="lineNum">     163 </span><span class="lineCov">        856 : int64_t dilatedBound(int64_t bound, int64_t dilation) {</span></a>
<a name="164"><span class="lineNum">     164 </span><span class="lineCov">        856 :   assert(bound &gt;= 0 &amp;&amp; &quot;The dimension to dialate must be &gt;= 0&quot;);</span></a>
<a name="165"><span class="lineNum">     165 </span><span class="lineCov">        856 :   if (bound == 0) return 0;</span></a>
<a name="166"><span class="lineNum">     166 </span>            : </a>
<a name="167"><span class="lineNum">     167 </span>            :   // Suppose the array has three entries 123 and the dilation factor is 4. Then</a>
<a name="168"><span class="lineNum">     168 </span>            :   // the dilated array has 9 entries 1xxx2xxx3. Here, each original entry except</a>
<a name="169"><span class="lineNum">     169 </span>            :   // the last expands into 4 entries, so that is (bound - 1) * dilation. Then we</a>
<a name="170"><span class="lineNum">     170 </span>            :   // add 1 to account for the final input element.</a>
<a name="171"><span class="lineNum">     171 </span><span class="lineCov">        856 :   return (bound - 1) * dilation + 1;</span></a>
<a name="172"><span class="lineNum">     172 </span><span class="lineCov">        856 : }</span></a>
<a name="173"><span class="lineNum">     173 </span>            : </a>
<a name="174"><span class="lineNum">     174 </span>            : // Returns the number of valid positions of a window with the given size and</a>
<a name="175"><span class="lineNum">     175 </span>            : // stride within an array with the given bound. This is the bound of an output</a>
<a name="176"><span class="lineNum">     176 </span>            : // array with one element per valid position of the window.</a>
<a name="177"><span class="lineNum">     177 </span>            : //</a>
<a name="178"><span class="lineNum">     178 </span>            : // For example, for arguments of (bound=5, window_size=2, stride=2), the</a>
<a name="179"><span class="lineNum">     179 </span>            : // returned value is 2. There are valid positions at offset 0 and offset 2,</a>
<a name="180"><span class="lineNum">     180 </span>            : // while offset 4 is not valid since the window's last entry would be at 5,</a>
<a name="181"><span class="lineNum">     181 </span>            : // which is beyond the bound of 5.</a>
<a name="182"><span class="lineNum">     182 </span><span class="lineCov">        428 : int64_t stridedBound(int64_t bound, int64_t windowSize, int64_t stride) {</span></a>
<a name="183"><span class="lineNum">     183 </span><span class="lineCov">        428 :   assert(windowSize &gt;= 0 &amp;&amp; &quot;Expected window size to be &gt;= 0&quot;);</span></a>
<a name="184"><span class="lineNum">     184 </span><span class="lineCov">        428 :   assert(bound &gt;= 0 &amp;&amp; &quot;Expected bound to be &gt;= 0&quot;);</span></a>
<a name="185"><span class="lineNum">     185 </span>            : </a>
<a name="186"><span class="lineNum">     186 </span><span class="lineCov">        428 :   if (bound == 0 || windowSize &gt; bound) return 0;</span></a>
<a name="187"><span class="lineNum">     187 </span>            : </a>
<a name="188"><span class="lineNum">     188 </span>            :   // Without considering stride, the maximum valid offset is bound -</a>
<a name="189"><span class="lineNum">     189 </span>            :   // window_size. Taking stride into account, the valid offsets then have the</a>
<a name="190"><span class="lineNum">     190 </span>            :   // form q * stride for q = 0, ..., Q such that q * stride &lt;= bound -</a>
<a name="191"><span class="lineNum">     191 </span>            :   // window_size. This implies that Q equals floor(bound - window_size /</a>
<a name="192"><span class="lineNum">     192 </span>            :   // stride). There are Q + 1 valid values of q, yielding the formula below.</a>
<a name="193"><span class="lineNum">     193 </span><span class="lineCov">        428 :   return (bound - windowSize) / stride + 1;</span></a>
<a name="194"><span class="lineNum">     194 </span><span class="lineCov">        428 : }</span></a>
<a name="195"><span class="lineNum">     195 </span>            : </a>
<a name="196"><span class="lineNum">     196 </span><span class="lineCov">         96 : LogicalResult verifyBatchNorm(Optional&lt;Location&gt; location, Value operand,</span></a>
<a name="197"><span class="lineNum">     197 </span><span class="lineCov">         96 :                               Value scale, int64_t feature_index) {</span></a>
<a name="198"><span class="lineNum">     198 </span><span class="lineCov">         96 :   auto operandType = operand.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="199"><span class="lineNum">     199 </span><span class="lineCov">         96 :   if (feature_index &gt;= operandType.getRank())</span></a>
<a name="200"><span class="lineNum">     200 </span><span class="lineCov">          6 :     return emitOptionalError(</span></a>
<a name="201"><span class="lineNum">     201 </span><span class="lineCov">          6 :         location,</span></a>
<a name="202"><span class="lineNum">     202 </span>            :         &quot;expects feature_index to be smaller than the rank of &quot;</a>
<a name="203"><span class="lineNum">     203 </span>            :         &quot;operand type; got feature_index &quot;,</a>
<a name="204"><span class="lineNum">     204 </span><span class="lineCov">          6 :         feature_index, &quot;, and rank &quot;, operandType.getRank(), &quot;.&quot;);</span></a>
<a name="205"><span class="lineNum">     205 </span>            : </a>
<a name="206"><span class="lineNum">     206 </span><span class="lineCov">         90 :   if (feature_index &lt; 0)</span></a>
<a name="207"><span class="lineNum">     207 </span><span class="lineCov">          6 :     return emitOptionalError(location, &quot;expects feature_index to be a &quot;,</span></a>
<a name="208"><span class="lineNum">     208 </span>            :                              &quot;non-negative number, got &quot;, feature_index, &quot;.&quot;);</a>
<a name="209"><span class="lineNum">     209 </span>            : </a>
<a name="210"><span class="lineNum">     210 </span>            :   // Note: the above checks '0 &lt;= feature-index &lt; operandType.getRank()'</a>
<a name="211"><span class="lineNum">     211 </span>            :   // imply 'operand_type.getRank() &gt;= 1'.</a>
<a name="212"><span class="lineNum">     212 </span>            : </a>
<a name="213"><span class="lineNum">     213 </span><span class="lineCov">         84 :   const int64_t featureCount = operandType.getDimSize(feature_index);</span></a>
<a name="214"><span class="lineNum">     214 </span><span class="lineCov">        168 :   const int64_t scaleShape =</span></a>
<a name="215"><span class="lineNum">     215 </span><span class="lineCov">         84 :       scale.getType().cast&lt;RankedTensorType&gt;().getDimSize(0);</span></a>
<a name="216"><span class="lineNum">     216 </span>            :   // As ODS enforces `scale`, `mean`, `variance`, `offset` are AllShapesMatch,</a>
<a name="217"><span class="lineNum">     217 </span>            :   // this also infers that featureCount is aligned with them.</a>
<a name="218"><span class="lineNum">     218 </span><span class="lineCov">         84 :   if (scaleShape != featureCount)</span></a>
<a name="219"><span class="lineNum">     219 </span><span class="lineCov">          8 :     return emitOptionalError(</span></a>
<a name="220"><span class="lineNum">     220 </span><span class="lineCov">          8 :         location,</span></a>
<a name="221"><span class="lineNum">     221 </span>            :         &quot;expects the size of scale factor to be same as the &quot;</a>
<a name="222"><span class="lineNum">     222 </span>            :         &quot;feature count, but the size of scale factor is &quot;,</a>
<a name="223"><span class="lineNum">     223 </span><span class="lineCov">          8 :         dimSizeToString(scaleShape), &quot; and the feature count is &quot;,</span></a>
<a name="224"><span class="lineNum">     224 </span><span class="lineCov">          8 :         dimSizeToString(featureCount), &quot;.&quot;);</span></a>
<a name="225"><span class="lineNum">     225 </span>            : </a>
<a name="226"><span class="lineNum">     226 </span><span class="lineCov">         76 :   return success();</span></a>
<a name="227"><span class="lineNum">     227 </span><span class="lineCov">         96 : }</span></a>
<a name="228"><span class="lineNum">     228 </span>            : </a>
<a name="229"><span class="lineNum">     229 </span>            : // Verifies various properties of window-attributes (viz., stride, padding,</a>
<a name="230"><span class="lineNum">     230 </span>            : // lhs_dilation and rhs_dilation) and collects all the window-attributes for</a>
<a name="231"><span class="lineNum">     231 </span>            : // each kernel spatial dimensions.</a>
<a name="232"><span class="lineNum">     232 </span>            : FailureOr&lt;SmallVector&lt;WindowDimension&gt;&gt;</a>
<a name="233"><span class="lineNum">     233 </span><span class="lineCov">        270 : verifyWindowAttributesAndInferWindowDimensions(</span></a>
<a name="234"><span class="lineNum">     234 </span>            :     ArrayRef&lt;int64_t&gt; windowDimensions, ArrayRef&lt;int64_t&gt; windowStrides,</a>
<a name="235"><span class="lineNum">     235 </span>            :     ArrayRef&lt;std::pair&lt;int64_t, int64_t&gt;&gt; padding,</a>
<a name="236"><span class="lineNum">     236 </span>            :     ArrayRef&lt;int64_t&gt; lhsDilation, ArrayRef&lt;int64_t&gt; rhsDilation,</a>
<a name="237"><span class="lineNum">     237 </span><span class="lineCov">        270 :     ArrayRef&lt;bool&gt; windowReversal, Optional&lt;Location&gt; loc) {</span></a>
<a name="238"><span class="lineNum">     238 </span><span class="lineCov">       1568 :   const auto verifySize = [&amp;](const size_t attrSize,</span></a>
<a name="239"><span class="lineNum">     239 </span><span class="lineCov">       1298 :                               StringRef attrName) -&gt; LogicalResult {</span></a>
<a name="240"><span class="lineNum">     240 </span><span class="lineCov">       1298 :     if (attrSize == 0 || attrSize == windowDimensions.size()) return success();</span></a>
<a name="241"><span class="lineNum">     241 </span><span class="lineCov">         24 :     return emitOptionalError(</span></a>
<a name="242"><span class="lineNum">     242 </span><span class="lineCov">         24 :         loc, &quot;expects &quot;, attrName,</span></a>
<a name="243"><span class="lineNum">     243 </span>            :         &quot; to have same dimension-size as size of window dimensions (&quot;,</a>
<a name="244"><span class="lineNum">     244 </span><span class="lineCov">         24 :         windowDimensions.size(), &quot;), but got: &quot;, attrSize, &quot;.&quot;);</span></a>
<a name="245"><span class="lineNum">     245 </span><span class="lineCov">       1298 :   };</span></a>
<a name="246"><span class="lineNum">     246 </span>            : </a>
<a name="247"><span class="lineNum">     247 </span><span class="lineCov">        270 :   if (failed(verifySize(windowStrides.size(), &quot;window-strides&quot;)))</span></a>
<a name="248"><span class="lineNum">     248 </span><span class="lineCov">          6 :     return failure();</span></a>
<a name="249"><span class="lineNum">     249 </span><span class="lineCov">        264 :   if (failed(verifySize(lhsDilation.size(), &quot;base-dilation factors&quot;)))</span></a>
<a name="250"><span class="lineNum">     250 </span><span class="lineCov">          4 :     return failure();</span></a>
<a name="251"><span class="lineNum">     251 </span><span class="lineCov">        260 :   if (failed(verifySize(rhsDilation.size(), &quot;window-dilation factors&quot;)))</span></a>
<a name="252"><span class="lineNum">     252 </span><span class="lineCov">          4 :     return failure();</span></a>
<a name="253"><span class="lineNum">     253 </span><span class="lineCov">        256 :   if (failed(verifySize(padding.size(), &quot;padding-entries&quot;))) return failure();</span></a>
<a name="254"><span class="lineNum">     254 </span><span class="lineCov">        248 :   if (failed(verifySize(windowReversal.size(), &quot;window-reversal&quot;)))</span></a>
<a name="255"><span class="lineNum">     255 </span><span class="lineCov">          2 :     return failure();</span></a>
<a name="256"><span class="lineNum">     256 </span>            : </a>
<a name="257"><span class="lineNum">     257 </span><span class="lineCov">        246 :   SmallVector&lt;WindowDimension&gt; window(windowDimensions.size());</span></a>
<a name="258"><span class="lineNum">     258 </span><span class="lineCov">        830 :   for (size_t i = 0; i &lt; windowDimensions.size(); i++) {</span></a>
<a name="259"><span class="lineNum">     259 </span><span class="lineCov">        584 :     WindowDimension&amp; dim = window[i];</span></a>
<a name="260"><span class="lineNum">     260 </span>            : </a>
<a name="261"><span class="lineNum">     261 </span><span class="lineCov">        584 :     dim.size = windowDimensions[i];</span></a>
<a name="262"><span class="lineNum">     262 </span><span class="lineCov">        584 :     if (!isDynamicDimSize(dim.size) &amp;&amp; dim.size &lt;= 0)</span></a>
<a name="263"><span class="lineNum">     263 </span><span class="lineCov">         12 :       return emitOptionalError(loc,</span></a>
<a name="264"><span class="lineNum">     264 </span>            :                                &quot;expects window to have positive value for &quot;, i,</a>
<a name="265"><span class="lineNum">     265 </span><span class="lineCov">          6 :                                &quot;-th window dimension, but got &quot;, dim.size, &quot;.&quot;);</span></a>
<a name="266"><span class="lineNum">     266 </span>            : </a>
<a name="267"><span class="lineNum">     267 </span><span class="lineCov">        578 :     if (!windowStrides.empty()) dim.stride = windowStrides[i];</span></a>
<a name="268"><span class="lineNum">     268 </span><span class="lineCov">        578 :     if (dim.stride &lt;= 0)</span></a>
<a name="269"><span class="lineNum">     269 </span><span class="lineCov">          6 :       return emitOptionalError(</span></a>
<a name="270"><span class="lineNum">     270 </span><span class="lineCov">          6 :           loc, &quot;expects window to have positive stride for &quot;, i,</span></a>
<a name="271"><span class="lineNum">     271 </span><span class="lineCov">          6 :           &quot;-th window dimension, but got &quot;, dim.stride, &quot;.&quot;);</span></a>
<a name="272"><span class="lineNum">     272 </span>            : </a>
<a name="273"><span class="lineNum">     273 </span><span class="lineCov">        572 :     if (!lhsDilation.empty()) dim.baseDilation = lhsDilation[i];</span></a>
<a name="274"><span class="lineNum">     274 </span><span class="lineCov">        572 :     if (dim.baseDilation &lt;= 0)</span></a>
<a name="275"><span class="lineNum">     275 </span><span class="lineCov">          4 :       return emitOptionalError(</span></a>
<a name="276"><span class="lineNum">     276 </span><span class="lineCov">          4 :           loc, &quot;expects window to have positive base dilation factor for &quot;, i,</span></a>
<a name="277"><span class="lineNum">     277 </span><span class="lineCov">          4 :           &quot;-th window dimension, but got &quot;, dim.baseDilation, &quot;.&quot;);</span></a>
<a name="278"><span class="lineNum">     278 </span>            : </a>
<a name="279"><span class="lineNum">     279 </span><span class="lineCov">        568 :     if (!rhsDilation.empty()) dim.windowDilation = rhsDilation[i];</span></a>
<a name="280"><span class="lineNum">     280 </span><span class="lineCov">        568 :     if (dim.windowDilation &lt;= 0)</span></a>
<a name="281"><span class="lineNum">     281 </span><span class="lineCov">          4 :       return emitOptionalError(</span></a>
<a name="282"><span class="lineNum">     282 </span><span class="lineCov">          4 :           loc, &quot;expects window to have positive window dilation factor for &quot;, i,</span></a>
<a name="283"><span class="lineNum">     283 </span><span class="lineCov">          4 :           &quot;-th window dimension, but got &quot;, dim.windowDilation, &quot;.&quot;);</span></a>
<a name="284"><span class="lineNum">     284 </span>            : </a>
<a name="285"><span class="lineNum">     285 </span><span class="lineCov">        564 :     if (!padding.empty()) {</span></a>
<a name="286"><span class="lineNum">     286 </span><span class="lineCov">        508 :       dim.paddingLow = padding[i].first;</span></a>
<a name="287"><span class="lineNum">     287 </span><span class="lineCov">        508 :       dim.paddingHigh = padding[i].second;</span></a>
<a name="288"><span class="lineNum">     288 </span><span class="lineCov">        508 :     }</span></a>
<a name="289"><span class="lineNum">     289 </span><span class="lineCov">        584 :   }</span></a>
<a name="290"><span class="lineNum">     290 </span>            : </a>
<a name="291"><span class="lineNum">     291 </span><span class="lineCov">        226 :   return window;</span></a>
<a name="292"><span class="lineNum">     292 </span><span class="lineCov">        270 : }</span></a>
<a name="293"><span class="lineNum">     293 </span>            : </a>
<a name="294"><span class="lineNum">     294 </span>            : // Infer the shape of the output window.</a>
<a name="295"><span class="lineNum">     295 </span>            : //  Foreach dimension d,</a>
<a name="296"><span class="lineNum">     296 </span>            : //    output-window-shape[d] =</a>
<a name="297"><span class="lineNum">     297 </span>            : //            stridedBound(padding_low + dilatedBound(base_shape[d]) +</a>
<a name="298"><span class="lineNum">     298 </span>            : //            padding_high,</a>
<a name="299"><span class="lineNum">     299 </span>            : //                         dilatedBound(window_shape[d]))</a>
<a name="300"><span class="lineNum">     300 </span>            : //      where (padding_low, padding_high) is the padding-pair for d.</a>
<a name="301"><span class="lineNum">     301 </span><span class="lineCov">        176 : SmallVector&lt;int64_t&gt; inferWindowOutputShape(</span></a>
<a name="302"><span class="lineNum">     302 </span><span class="lineCov">        176 :     const ArrayRef&lt;int64_t&gt; baseShape, const ArrayRef&lt;WindowDimension&gt; window) {</span></a>
<a name="303"><span class="lineNum">     303 </span><span class="lineCov">        176 :   assert(baseShape.size() == window.size() &amp;&amp;</span></a>
<a name="304"><span class="lineNum">     304 </span>            :          &quot;Size of window dimensions must match the size of base shape.&quot;);</a>
<a name="305"><span class="lineNum">     305 </span>            : </a>
<a name="306"><span class="lineNum">     306 </span><span class="lineCov">        176 :   SmallVector&lt;int64_t&gt; outputDimensions(window.size());</span></a>
<a name="307"><span class="lineNum">     307 </span><span class="lineCov">        612 :   for (int64_t i = 0; i &lt; static_cast&lt;int64_t&gt;(window.size()); ++i) {</span></a>
<a name="308"><span class="lineNum">     308 </span><span class="lineCov">        436 :     if (isDynamicDimSize(baseShape[i]) || isDynamicDimSize(window[i].size)) {</span></a>
<a name="309"><span class="lineNum">     309 </span><span class="lineCov">          8 :       outputDimensions[i] = ShapedType::kDynamic;</span></a>
<a name="310"><span class="lineNum">     310 </span><span class="lineCov">          8 :     } else {</span></a>
<a name="311"><span class="lineNum">     311 </span><span class="lineCov">        428 :       const auto&amp; dim = window[i];</span></a>
<a name="312"><span class="lineNum">     312 </span>            : </a>
<a name="313"><span class="lineNum">     313 </span><span class="lineCov">        428 :       const int64_t dilatedBase = dilatedBound(baseShape[i], dim.baseDilation);</span></a>
<a name="314"><span class="lineNum">     314 </span><span class="lineCov">        856 :       const int64_t paddedDilatedBase =</span></a>
<a name="315"><span class="lineNum">     315 </span><span class="lineCov">        428 :           dim.paddingLow + dilatedBase + dim.paddingHigh;</span></a>
<a name="316"><span class="lineNum">     316 </span><span class="lineCov">        428 :       const int64_t dilatedWindow = dilatedBound(dim.size, dim.windowDilation);</span></a>
<a name="317"><span class="lineNum">     317 </span>            : </a>
<a name="318"><span class="lineNum">     318 </span><span class="lineCov">        428 :       outputDimensions[i] =</span></a>
<a name="319"><span class="lineNum">     319 </span><span class="lineCov">        428 :           stridedBound(paddedDilatedBase, dilatedWindow, dim.stride);</span></a>
<a name="320"><span class="lineNum">     320 </span><span class="lineCov">        428 :     }</span></a>
<a name="321"><span class="lineNum">     321 </span><span class="lineCov">        436 :   }</span></a>
<a name="322"><span class="lineNum">     322 </span>            : </a>
<a name="323"><span class="lineNum">     323 </span><span class="lineCov">        176 :   return outputDimensions;</span></a>
<a name="324"><span class="lineNum">     324 </span><span class="lineCov">        176 : }</span></a>
<a name="325"><span class="lineNum">     325 </span>            : </a>
<a name="326"><span class="lineNum">     326 </span><span class="lineCov">        108 : unsigned potentiallyComplexBitwidth(Type type) {</span></a>
<a name="327"><span class="lineNum">     327 </span><span class="lineCov">        108 :   auto complexTy = type.dyn_cast&lt;ComplexType&gt;();</span></a>
<a name="328"><span class="lineNum">     328 </span><span class="lineCov">        108 :   return complexTy ? 2 * complexTy.getElementType().getIntOrFloatBitWidth()</span></a>
<a name="329"><span class="lineNum">     329 </span><span class="lineCov">        100 :                    : type.getIntOrFloatBitWidth();</span></a>
<a name="330"><span class="lineNum">     330 </span><span class="lineCov">        108 : }</span></a>
<a name="331"><span class="lineNum">     331 </span>            : </a>
<a name="332"><span class="lineNum">     332 </span><span class="lineCov">        186 : LogicalResult verifyReplicaGroups(Optional&lt;Location&gt; location,</span></a>
<a name="333"><span class="lineNum">     333 </span>            :                                   DenseIntElementsAttr replicaGroups,</a>
<a name="334"><span class="lineNum">     334 </span>            :                                   bool allGroupsMustHaveSameSize,</a>
<a name="335"><span class="lineNum">     335 </span>            :                                   bool useGlobalDeviceIds,</a>
<a name="336"><span class="lineNum">     336 </span><span class="lineCov">        186 :                                   Optional&lt;size_t&gt; expectedGroupSize) {</span></a>
<a name="337"><span class="lineNum">     337 </span><span class="lineCov">        186 :   auto replicaGroupType = replicaGroups.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="338"><span class="lineNum">     338 </span>            : </a>
<a name="339"><span class="lineNum">     339 </span><span class="lineCov">        186 :   if (replicaGroupType.getRank() != 2)</span></a>
<a name="340"><span class="lineNum">     340 </span><span class="lineCov">          8 :     return emitOptionalError(location,</span></a>
<a name="341"><span class="lineNum">     341 </span>            :                              &quot;replica groups should be a rank 2 tensor&quot;);</a>
<a name="342"><span class="lineNum">     342 </span>            : </a>
<a name="343"><span class="lineNum">     343 </span>            :   // Revisit the following check in light of #498.</a>
<a name="344"><span class="lineNum">     344 </span><span class="lineCov">        178 :   if (useGlobalDeviceIds &amp;&amp;</span></a>
<a name="345"><span class="lineNum">     345 </span><span class="lineCov">         42 :       (replicaGroupType.getShape()[0] * replicaGroupType.getShape()[1] == 0)) {</span></a>
<a name="346"><span class="lineNum">     346 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="347"><span class="lineNum">     347 </span>            :                              &quot;if `use_global_device_ids` is set, the replica &quot;</a>
<a name="348"><span class="lineNum">     348 </span>            :                              &quot;groups cannot be empty&quot;);</a>
<a name="349"><span class="lineNum">     349 </span>            :   }</a>
<a name="350"><span class="lineNum">     350 </span>            : </a>
<a name="351"><span class="lineNum">     351 </span><span class="lineCov">        174 :   auto replicaIds = replicaGroups.getValues&lt;int64_t&gt;();</span></a>
<a name="352"><span class="lineNum">     352 </span><span class="lineCov">        174 :   llvm::SmallSet&lt;int64_t, 8&gt; replicaIdsSeen;</span></a>
<a name="353"><span class="lineNum">     353 </span><span class="lineCov">       1066 :   for (int64_t replicaId : replicaIds) {</span></a>
<a name="354"><span class="lineNum">     354 </span>            :     // Replica groups are stored in a 2D tensor. If the op supports non-uniform</a>
<a name="355"><span class="lineNum">     355 </span>            :     // groups, null replica IDs are stored as -1.</a>
<a name="356"><span class="lineNum">     356 </span><span class="lineCov">        892 :     if (replicaId == -1) {</span></a>
<a name="357"><span class="lineNum">     357 </span><span class="lineCov">         12 :       if (allGroupsMustHaveSameSize) {</span></a>
<a name="358"><span class="lineNum">     358 </span><span class="lineCov">          2 :         return emitOptionalError(location, &quot;Invalid replica id -1&quot;);</span></a>
<a name="359"><span class="lineNum">     359 </span>            :       }</a>
<a name="360"><span class="lineNum">     360 </span><span class="lineCov">         10 :       continue;</span></a>
<a name="361"><span class="lineNum">     361 </span>            :     }</a>
<a name="362"><span class="lineNum">     362 </span>            : </a>
<a name="363"><span class="lineNum">     363 </span><span class="lineCov">        880 :     if (!replicaIdsSeen.insert(replicaId).second) {</span></a>
<a name="364"><span class="lineNum">     364 </span><span class="lineCov">          8 :       return emitOptionalError(location, &quot;replica id #&quot;, replicaId,</span></a>
<a name="365"><span class="lineNum">     365 </span>            :                                &quot; seen more than once&quot;);</a>
<a name="366"><span class="lineNum">     366 </span>            :     }</a>
<a name="367"><span class="lineNum">     367 </span><span class="lineCov">        892 :   }</span></a>
<a name="368"><span class="lineNum">     368 </span>            : </a>
<a name="369"><span class="lineNum">     369 </span><span class="lineCov">        980 :   for (size_t id = 0; id &lt; replicaIdsSeen.size(); id++) {</span></a>
<a name="370"><span class="lineNum">     370 </span><span class="lineCov">        816 :     if (!replicaIdsSeen.contains(id)) {</span></a>
<a name="371"><span class="lineNum">     371 </span><span class="lineCov">         12 :       return emitOptionalError(location, &quot;replica id #&quot;, id,</span></a>
<a name="372"><span class="lineNum">     372 </span>            :                                &quot; not seen in replica groups&quot;);</a>
<a name="373"><span class="lineNum">     373 </span>            :     }</a>
<a name="374"><span class="lineNum">     374 </span><span class="lineCov">        804 :   }</span></a>
<a name="375"><span class="lineNum">     375 </span>            : </a>
<a name="376"><span class="lineNum">     376 </span><span class="lineCov">        152 :   if (allGroupsMustHaveSameSize &amp;&amp; expectedGroupSize &amp;&amp;</span></a>
<a name="377"><span class="lineNum">     377 </span><span class="lineCov">         80 :       (replicaIds.size() / replicaGroupType.getShape()[0] !=</span></a>
<a name="378"><span class="lineNum">     378 </span><span class="lineCov">         40 :        *expectedGroupSize))</span></a>
<a name="379"><span class="lineNum">     379 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;group size of replica_groups must be &quot;,</span></a>
<a name="380"><span class="lineNum">     380 </span><span class="lineCov">          2 :                              *expectedGroupSize);</span></a>
<a name="381"><span class="lineNum">     381 </span>            : </a>
<a name="382"><span class="lineNum">     382 </span><span class="lineCov">        150 :   return success();</span></a>
<a name="383"><span class="lineNum">     383 </span><span class="lineCov">        186 : }</span></a>
<a name="384"><span class="lineNum">     384 </span>            : </a>
<a name="385"><span class="lineNum">     385 </span><span class="lineCov">        327 : LogicalResult verifyReduceOpInputsAndInferShape(</span></a>
<a name="386"><span class="lineNum">     386 </span>            :     Optional&lt;Location&gt; location, SmallVector&lt;TensorType&gt; inputArgTypes,</a>
<a name="387"><span class="lineNum">     387 </span>            :     SmallVector&lt;TensorType&gt; initValueTypes, DenseIntElementsAttr dimensions,</a>
<a name="388"><span class="lineNum">     388 </span><span class="lineCov">        327 :     SmallVector&lt;int64_t&gt;&amp; newDimensions, Attribute&amp; encoding) {</span></a>
<a name="389"><span class="lineNum">     389 </span>            :   // Check for unranked tensors in input operands.</a>
<a name="390"><span class="lineNum">     390 </span><span class="lineCov">        327 :   uint64_t numInputs = inputArgTypes.size();</span></a>
<a name="391"><span class="lineNum">     391 </span><span class="lineCov">        327 :   int64_t rankedInputIdx = -1;</span></a>
<a name="392"><span class="lineNum">     392 </span><span class="lineCov">        654 :   for (uint64_t inputIdx = 0; inputIdx &lt; numInputs; ++inputIdx) {</span></a>
<a name="393"><span class="lineNum">     393 </span><span class="lineCov">        327 :     if (inputArgTypes[inputIdx].hasRank()) {</span></a>
<a name="394"><span class="lineNum">     394 </span><span class="lineCov">        305 :       rankedInputIdx = inputIdx;</span></a>
<a name="395"><span class="lineNum">     395 </span><span class="lineCov">        305 :       break;</span></a>
<a name="396"><span class="lineNum">     396 </span>            :     }</a>
<a name="397"><span class="lineNum">     397 </span><span class="lineCov">         22 :   }</span></a>
<a name="398"><span class="lineNum">     398 </span><span class="lineCov">        327 :   bool allInputsUnranked = (rankedInputIdx == -1);</span></a>
<a name="399"><span class="lineNum">     399 </span>            : </a>
<a name="400"><span class="lineNum">     400 </span><span class="lineCov">        327 :   if (!allInputsUnranked) {</span></a>
<a name="401"><span class="lineNum">     401 </span><span class="lineCov">        696 :     for (uint64_t inputIdx = 0; inputIdx &lt; numInputs; ++inputIdx) {</span></a>
<a name="402"><span class="lineNum">     402 </span><span class="lineCov">        780 :       if (failed(mlir::verifyCompatibleShape(inputArgTypes[rankedInputIdx],</span></a>
<a name="403"><span class="lineNum">     403 </span><span class="lineCov">        390 :                                              inputArgTypes[inputIdx]))) {</span></a>
<a name="404"><span class="lineNum">     404 </span><span class="lineCov">          4 :         return emitOptionalError(</span></a>
<a name="405"><span class="lineNum">     405 </span><span class="lineCov">          4 :             location, &quot;expects all inputs to have compatible shapes. Shape at&quot;,</span></a>
<a name="406"><span class="lineNum">     406 </span>            :             &quot; input-index &quot;, inputIdx,</a>
<a name="407"><span class="lineNum">     407 </span>            :             &quot; is not compatible with shape at input-index &quot;, rankedInputIdx);</a>
<a name="408"><span class="lineNum">     408 </span>            :       }</a>
<a name="409"><span class="lineNum">     409 </span><span class="lineCov">        386 :     }</span></a>
<a name="410"><span class="lineNum">     410 </span><span class="lineCov">        302 :   }</span></a>
<a name="411"><span class="lineNum">     411 </span>            : </a>
<a name="412"><span class="lineNum">     412 </span><span class="lineCov">        323 :   DenseSet&lt;int64_t&gt; dimensionsToReduceSet;</span></a>
<a name="413"><span class="lineNum">     413 </span><span class="lineCov">        649 :   for (int64_t dimension : dimensions.getValues&lt;int64_t&gt;()) {</span></a>
<a name="414"><span class="lineNum">     414 </span><span class="lineCov">        932 :     if ((!allInputsUnranked &amp;&amp;</span></a>
<a name="415"><span class="lineNum">     415 </span><span class="lineCov">        304 :          dimension &gt;= inputArgTypes[rankedInputIdx].getRank()) ||</span></a>
<a name="416"><span class="lineNum">     416 </span><span class="lineCov">        324 :         dimension &lt; 0) {</span></a>
<a name="417"><span class="lineNum">     417 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="418"><span class="lineNum">     418 </span><span class="lineCov">          2 :           location, &quot;Out-of-bounds dimension &quot;, dimension,</span></a>
<a name="419"><span class="lineNum">     419 </span><span class="lineCov">          2 :           &quot; for input-tensor rank: &quot;, inputArgTypes[rankedInputIdx].getRank());</span></a>
<a name="420"><span class="lineNum">     420 </span>            :     }</a>
<a name="421"><span class="lineNum">     421 </span>            : </a>
<a name="422"><span class="lineNum">     422 </span><span class="lineCov">        324 :     if (!dimensionsToReduceSet.insert(dimension).second) {</span></a>
<a name="423"><span class="lineNum">     423 </span><span class="lineCov">          2 :       return emitOptionalError(location,</span></a>
<a name="424"><span class="lineNum">     424 </span>            :                                &quot;Duplicate reduction dimension: &quot;, dimension);</a>
<a name="425"><span class="lineNum">     425 </span>            :     }</a>
<a name="426"><span class="lineNum">     426 </span><span class="lineCov">        326 :   }</span></a>
<a name="427"><span class="lineNum">     427 </span>            : </a>
<a name="428"><span class="lineNum">     428 </span><span class="lineCov">        320 :   if (!allInputsUnranked) {</span></a>
<a name="429"><span class="lineNum">     429 </span><span class="lineCov">        298 :     auto rankedInput = inputArgTypes[rankedInputIdx].cast&lt;RankedTensorType&gt;();</span></a>
<a name="430"><span class="lineNum">     430 </span>            : </a>
<a name="431"><span class="lineNum">     431 </span><span class="lineCov">        298 :     ArrayRef&lt;int64_t&gt; inputBounds = encodingToBounds(rankedInput.getEncoding());</span></a>
<a name="432"><span class="lineNum">     432 </span><span class="lineCov">        298 :     SmallVector&lt;int64_t&gt; newBounds;</span></a>
<a name="433"><span class="lineNum">     433 </span><span class="lineCov">        881 :     for (int inputIdx = 0; inputIdx &lt; rankedInput.getRank(); ++inputIdx) {</span></a>
<a name="434"><span class="lineNum">     434 </span><span class="lineCov">        583 :       if (!dimensionsToReduceSet.count(inputIdx)) {</span></a>
<a name="435"><span class="lineNum">     435 </span><span class="lineCov">        286 :         newDimensions.push_back(rankedInput.getDimSize(inputIdx));</span></a>
<a name="436"><span class="lineNum">     436 </span><span class="lineCov">        286 :         if (!inputBounds.empty()) {</span></a>
<a name="437"><span class="lineNum">     437 </span><span class="lineCov">         28 :           newBounds.push_back(inputBounds[inputIdx]);</span></a>
<a name="438"><span class="lineNum">     438 </span><span class="lineCov">         28 :         }</span></a>
<a name="439"><span class="lineNum">     439 </span><span class="lineCov">        286 :       }</span></a>
<a name="440"><span class="lineNum">     440 </span><span class="lineCov">        583 :     }</span></a>
<a name="441"><span class="lineNum">     441 </span><span class="lineCov">        298 :     if (!inputBounds.empty()) {</span></a>
<a name="442"><span class="lineNum">     442 </span><span class="lineCov">         14 :       encoding = boundsToEncoding(rankedInput.getEncoding(), newBounds);</span></a>
<a name="443"><span class="lineNum">     443 </span><span class="lineCov">         14 :     }</span></a>
<a name="444"><span class="lineNum">     444 </span><span class="lineCov">        298 :   }</span></a>
<a name="445"><span class="lineNum">     445 </span><span class="lineCov">        320 :   return success();</span></a>
<a name="446"><span class="lineNum">     446 </span><span class="lineCov">        327 : }</span></a>
<a name="447"><span class="lineNum">     447 </span>            : </a>
<a name="448"><span class="lineNum">     448 </span>            : // TODO(zhouxin) remove args `allInputsUnranked` and `numInputs`</a>
<a name="449"><span class="lineNum">     449 </span><span class="lineCov">        469 : LogicalResult verifyReducerShape(Optional&lt;Location&gt; loc, Block&amp; block,</span></a>
<a name="450"><span class="lineNum">     450 </span>            :                                  ArrayRef&lt;TensorType&gt; inputArgTypes,</a>
<a name="451"><span class="lineNum">     451 </span>            :                                  ArrayRef&lt;TensorType&gt; initValueTypes,</a>
<a name="452"><span class="lineNum">     452 </span>            :                                  int64_t numInputs,</a>
<a name="453"><span class="lineNum">     453 </span>            :                                  ArrayRef&lt;int64_t&gt; allowedDimensions,</a>
<a name="454"><span class="lineNum">     454 </span><span class="lineCov">        469 :                                  bool allInputsUnranked) {</span></a>
<a name="455"><span class="lineNum">     455 </span>            :   // Check that the number of reduction-region arguments matches with that of</a>
<a name="456"><span class="lineNum">     456 </span>            :   // reduce-op's arguments.</a>
<a name="457"><span class="lineNum">     457 </span><span class="lineCov">        469 :   if (static_cast&lt;int64_t&gt;(block.getArguments().size()) != numInputs * 2)</span></a>
<a name="458"><span class="lineNum">     458 </span><span class="lineCov">         24 :     return emitOptionalError(loc, &quot;Reduction-region must take &quot;, numInputs * 2,</span></a>
<a name="459"><span class="lineNum">     459 </span>            :                              &quot; parameters, but takes &quot;,</a>
<a name="460"><span class="lineNum">     460 </span><span class="lineCov">         12 :                              block.getArguments().size(), &quot; parameter(s)&quot;);</span></a>
<a name="461"><span class="lineNum">     461 </span>            : </a>
<a name="462"><span class="lineNum">     462 </span>            :   // Check if the reduction-region produces non-zero outputs.</a>
<a name="463"><span class="lineNum">     463 </span><span class="lineCov">        457 :   if (block.getTerminator()-&gt;getOperands().empty())</span></a>
<a name="464"><span class="lineNum">     464 </span><span class="lineCov">         12 :     return emitOptionalError(</span></a>
<a name="465"><span class="lineNum">     465 </span><span class="lineCov">         12 :         loc, &quot;The reduction-region expected to return some value(s)&quot;);</span></a>
<a name="466"><span class="lineNum">     466 </span>            : </a>
<a name="467"><span class="lineNum">     467 </span>            :   // Check that the reduction-region returns list- of tensors.</a>
<a name="468"><span class="lineNum">     468 </span>            :   // The number of result-tensors must match the `numInputs`.</a>
<a name="469"><span class="lineNum">     469 </span><span class="lineCov">        890 :   if (static_cast&lt;int64_t&gt;(block.getTerminator()-&gt;getOperands().size()) !=</span></a>
<a name="470"><span class="lineNum">     470 </span><span class="lineCov">        445 :       numInputs)</span></a>
<a name="471"><span class="lineNum">     471 </span><span class="lineCov">         20 :     return emitOptionalError(loc, &quot;Reduction-region here must produce &quot;,</span></a>
<a name="472"><span class="lineNum">     472 </span>            :                              numInputs, &quot; tensors, but produces &quot;,</a>
<a name="473"><span class="lineNum">     473 </span><span class="lineCov">         10 :                              block.getTerminator()-&gt;getOperands().size(),</span></a>
<a name="474"><span class="lineNum">     474 </span>            :                              &quot; instead&quot;);</a>
<a name="475"><span class="lineNum">     475 </span>            : </a>
<a name="476"><span class="lineNum">     476 </span><span class="lineCov">        435 :   SmallVector&lt;TensorType&gt; accumulatorSubShapes;</span></a>
<a name="477"><span class="lineNum">     477 </span><span class="lineCov">        954 :   for (Value retOperand : block.getTerminator()-&gt;getOperands()) {</span></a>
<a name="478"><span class="lineNum">     478 </span><span class="lineCov">        519 :     auto tensorTy = retOperand.getType().dyn_cast&lt;TensorType&gt;();</span></a>
<a name="479"><span class="lineNum">     479 </span><span class="lineCov">        519 :     if (!tensorTy)</span></a>
<a name="480"><span class="lineNum">     480 </span><span class="lineCov">         32 :       return emitOptionalError(loc,</span></a>
<a name="481"><span class="lineNum">     481 </span>            :                                &quot;Reduction-region here must produce &quot;</a>
<a name="482"><span class="lineNum">     482 </span>            :                                &quot;tensor-typed result(s), but &quot;</a>
<a name="483"><span class="lineNum">     483 </span>            :                                &quot;produces &quot;,</a>
<a name="484"><span class="lineNum">     484 </span><span class="lineCov">         16 :                                retOperand.getType(), &quot; instead&quot;);</span></a>
<a name="485"><span class="lineNum">     485 </span>            : </a>
<a name="486"><span class="lineNum">     486 </span><span class="lineCov">        503 :     accumulatorSubShapes.push_back(tensorTy);</span></a>
<a name="487"><span class="lineNum">     487 </span><span class="lineCov">        519 :   }</span></a>
<a name="488"><span class="lineNum">     488 </span>            : </a>
<a name="489"><span class="lineNum">     489 </span>            :   // Consider typical reduce-* op syntax:</a>
<a name="490"><span class="lineNum">     490 </span>            :   //</a>
<a name="491"><span class="lineNum">     491 </span>            :   //      op(I(i), V(j)):</a>
<a name="492"><span class="lineNum">     492 </span>            :   //       block(BI(i), BV(j)):</a>
<a name="493"><span class="lineNum">     493 </span>            :   //         ... some computation ...</a>
<a name="494"><span class="lineNum">     494 </span>            :   //         return(R(i))</a>
<a name="495"><span class="lineNum">     495 </span>            :   //</a>
<a name="496"><span class="lineNum">     496 </span>            :   // where</a>
<a name="497"><span class="lineNum">     497 </span>            :   //  I(i)  : i-th input of op</a>
<a name="498"><span class="lineNum">     498 </span>            :   //  V(j)  : j-th init-value of op</a>
<a name="499"><span class="lineNum">     499 </span>            :   //  BI(i) : i-th input of reducer-function</a>
<a name="500"><span class="lineNum">     500 </span>            :   //  BV(j) : j-th init-value of reducer-function</a>
<a name="501"><span class="lineNum">     501 </span>            :   //  R(i)  : i-th return-type</a>
<a name="502"><span class="lineNum">     502 </span>            :   //</a>
<a name="503"><span class="lineNum">     503 </span>            :   //  Note that: |I(i)| == |V(j)| == |BI(i)| == |BV(j)| == |R(i)|</a>
<a name="504"><span class="lineNum">     504 </span>            :   //</a>
<a name="505"><span class="lineNum">     505 </span>            :   //  Here are the type-constraints among V(j), BI(i), BV(j), and R(i).</a>
<a name="506"><span class="lineNum">     506 </span>            :   //    C1 : Check that BI(i) and R(i) have same shape and element-type.</a>
<a name="507"><span class="lineNum">     507 </span>            :   //    C2 : Check that BV(j) and R(i) have same shape and element-type.</a>
<a name="508"><span class="lineNum">     508 </span>            :   //    C3 : Check that V(j) and R(i) have same shape and element-type.</a>
<a name="509"><span class="lineNum">     509 </span>            :   //</a>
<a name="510"><span class="lineNum">     510 </span>            :   //  From C1, C2, and C3, we can infer that V(j), BI(i), BV(j), and R(i) all</a>
<a name="511"><span class="lineNum">     511 </span>            :   //  have compatible shapes and element-types.</a>
<a name="512"><span class="lineNum">     512 </span>            :   //  The next check, C4, adds constraints on how the type if I(i) is related</a>
<a name="513"><span class="lineNum">     513 </span>            :   //  to any_of(V(j), BI(i), BV(j), and R(i)), say BV(j);</a>
<a name="514"><span class="lineNum">     514 </span>            :   //</a>
<a name="515"><span class="lineNum">     515 </span>            :   //  C4.1 : Check that I(i) and BV(j) have same element-type.</a>
<a name="516"><span class="lineNum">     516 </span>            :   //  C4.2 : Check that shape of BV(j) is a 'sub-sequence' of</a>
<a name="517"><span class="lineNum">     517 </span>            :   //         'allowedDimensions'. 'allowedDimensions' is a list of dimensions</a>
<a name="518"><span class="lineNum">     518 </span>            :   //         which any of BI(i), BV(j), and R(i) is allowed to have.</a>
<a name="519"><span class="lineNum">     519 </span><span class="lineCov">        908 :   for (int64_t inputIdx = 0; inputIdx &lt; numInputs; ++inputIdx) {</span></a>
<a name="520"><span class="lineNum">     520 </span>            :     // Check C1.</a>
<a name="521"><span class="lineNum">     521 </span><span class="lineCov">        978 :     if (!compatibleShapeAndElementType(accumulatorSubShapes[inputIdx],</span></a>
<a name="522"><span class="lineNum">     522 </span><span class="lineCov">        489 :                                        block.getArgument(inputIdx).getType()))</span></a>
<a name="523"><span class="lineNum">     523 </span><span class="lineCov">         14 :       return emitOptionalError(</span></a>
<a name="524"><span class="lineNum">     524 </span><span class="lineCov">         14 :           loc, &quot;The type of reduction-region's parameter at index &quot;, inputIdx,</span></a>
<a name="525"><span class="lineNum">     525 </span>            :           &quot; is different than the corresponding result type: &quot;,</a>
<a name="526"><span class="lineNum">     526 </span><span class="lineCov">         14 :           block.getArgument(inputIdx).getType(), &quot; vs &quot;,</span></a>
<a name="527"><span class="lineNum">     527 </span><span class="lineCov">         14 :           accumulatorSubShapes[inputIdx]);</span></a>
<a name="528"><span class="lineNum">     528 </span>            : </a>
<a name="529"><span class="lineNum">     529 </span>            :     // Check C2.</a>
<a name="530"><span class="lineNum">     530 </span><span class="lineCov">        475 :     if (!compatibleShapeAndElementType(</span></a>
<a name="531"><span class="lineNum">     531 </span><span class="lineCov">        475 :             accumulatorSubShapes[inputIdx],</span></a>
<a name="532"><span class="lineNum">     532 </span><span class="lineCov">        475 :             block.getArgument(numInputs + inputIdx).getType(),</span></a>
<a name="533"><span class="lineNum">     533 </span>            :             /*ignoreFpPrecision=*/true))</a>
<a name="534"><span class="lineNum">     534 </span><span class="lineCov">         10 :       return emitOptionalError(</span></a>
<a name="535"><span class="lineNum">     535 </span><span class="lineCov">         10 :           loc, &quot;The type of reduction-region's parameter at index &quot;,</span></a>
<a name="536"><span class="lineNum">     536 </span><span class="lineCov">         10 :           numInputs + inputIdx,</span></a>
<a name="537"><span class="lineNum">     537 </span>            :           &quot; is different than the corresponding result type: &quot;,</a>
<a name="538"><span class="lineNum">     538 </span><span class="lineCov">         10 :           block.getArgument(numInputs + inputIdx).getType(), &quot; vs &quot;,</span></a>
<a name="539"><span class="lineNum">     539 </span><span class="lineCov">         10 :           accumulatorSubShapes[inputIdx]);</span></a>
<a name="540"><span class="lineNum">     540 </span>            : </a>
<a name="541"><span class="lineNum">     541 </span>            :     // Check C3.</a>
<a name="542"><span class="lineNum">     542 </span><span class="lineCov">        930 :     if (!compatibleShapeAndElementType(accumulatorSubShapes[inputIdx],</span></a>
<a name="543"><span class="lineNum">     543 </span><span class="lineCov">        465 :                                        initValueTypes[inputIdx],</span></a>
<a name="544"><span class="lineNum">     544 </span>            :                                        /*ignoreFpPrecision=*/true))</a>
<a name="545"><span class="lineNum">     545 </span><span class="lineCov">         12 :       return emitOptionalError(</span></a>
<a name="546"><span class="lineNum">     546 </span><span class="lineCov">         12 :           loc, &quot;The type of reduction-region's result type at index &quot;, inputIdx,</span></a>
<a name="547"><span class="lineNum">     547 </span>            :           &quot; differs from the op's corresponding init-value type: &quot;,</a>
<a name="548"><span class="lineNum">     548 </span><span class="lineCov">         12 :           accumulatorSubShapes[inputIdx], &quot; vs &quot;, initValueTypes[inputIdx]);</span></a>
<a name="549"><span class="lineNum">     549 </span>            : </a>
<a name="550"><span class="lineNum">     550 </span>            :     // Check C4.1.</a>
<a name="551"><span class="lineNum">     551 </span><span class="lineCov">        453 :     if (!tensorsHaveSameElType(</span></a>
<a name="552"><span class="lineNum">     552 </span><span class="lineCov">        453 :             inputArgTypes[inputIdx],</span></a>
<a name="553"><span class="lineNum">     553 </span><span class="lineCov">        453 :             block.getArgument(numInputs + inputIdx).getType(), true))</span></a>
<a name="554"><span class="lineNum">     554 </span><span class="lineCov">          8 :       return emitOptionalError(</span></a>
<a name="555"><span class="lineNum">     555 </span><span class="lineCov">          8 :           loc, &quot;The element-type of reduction-region's argument at index &quot;,</span></a>
<a name="556"><span class="lineNum">     556 </span><span class="lineCov">          8 :           numInputs + inputIdx, &quot; is expected to be &quot;,</span></a>
<a name="557"><span class="lineNum">     557 </span><span class="lineCov">          8 :           inputArgTypes[inputIdx].getElementType(), &quot;, but got &quot;,</span></a>
<a name="558"><span class="lineNum">     558 </span><span class="lineCov">          8 :           block.getArgument(numInputs + inputIdx).getType(), &quot; as its type.&quot;);</span></a>
<a name="559"><span class="lineNum">     559 </span>            : </a>
<a name="560"><span class="lineNum">     560 </span>            :     // Check C4.2.</a>
<a name="561"><span class="lineNum">     561 </span><span class="lineCov">        445 :     Type blockArgType = block.getArgument(numInputs + inputIdx).getType();</span></a>
<a name="562"><span class="lineNum">     562 </span><span class="lineCov">        445 :     auto blockArgTensorTy = blockArgType.cast&lt;TensorType&gt;();</span></a>
<a name="563"><span class="lineNum">     563 </span>            : </a>
<a name="564"><span class="lineNum">     564 </span><span class="lineCov">        445 :     if (allInputsUnranked || !blockArgTensorTy.hasRank()) return success();</span></a>
<a name="565"><span class="lineNum">     565 </span>            : </a>
<a name="566"><span class="lineNum">     566 </span><span class="lineCov">        413 :     auto argShape = blockArgTensorTy.getShape();</span></a>
<a name="567"><span class="lineNum">     567 </span><span class="lineCov">        413 :     if (argShape.size() &gt; allowedDimensions.size())</span></a>
<a name="568"><span class="lineNum">     568 </span><span class="lineCov">          6 :       return emitOptionalError(</span></a>
<a name="569"><span class="lineNum">     569 </span><span class="lineCov">          6 :           loc, &quot;The rank of reduction-region's argument at index &quot;,</span></a>
<a name="570"><span class="lineNum">     570 </span><span class="lineCov">          6 :           numInputs + inputIdx,</span></a>
<a name="571"><span class="lineNum">     571 </span><span class="lineCov">          6 :           &quot; is expected to be &lt;= &quot;, allowedDimensions.size(), &quot;, got &quot;,</span></a>
<a name="572"><span class="lineNum">     572 </span><span class="lineCov">          6 :           argShape.size());</span></a>
<a name="573"><span class="lineNum">     573 </span>            : </a>
<a name="574"><span class="lineNum">     574 </span><span class="lineCov">        407 :     int64_t argShapeIdx = 0;</span></a>
<a name="575"><span class="lineNum">     575 </span><span class="lineCov">        932 :     for (int64_t outputShapeIdx = 0;</span></a>
<a name="576"><span class="lineNum">     576 </span><span class="lineCov">        466 :          outputShapeIdx &lt; static_cast&lt;int64_t&gt;(allowedDimensions.size()) &amp;&amp;</span></a>
<a name="577"><span class="lineNum">     577 </span><span class="lineCov">        249 :          argShapeIdx &lt; static_cast&lt;int64_t&gt;(argShape.size());</span></a>
<a name="578"><span class="lineNum">     578 </span><span class="lineCov">         59 :          outputShapeIdx++)</span></a>
<a name="579"><span class="lineNum">     579 </span><span class="lineCov">        155 :       if (allowedDimensions[outputShapeIdx] == ShapedType::kDynamic ||</span></a>
<a name="580"><span class="lineNum">     580 </span><span class="lineCov">         48 :           argShape[argShapeIdx] == ShapedType::kDynamic ||</span></a>
<a name="581"><span class="lineNum">     581 </span><span class="lineCov">        107 :           allowedDimensions[outputShapeIdx] == argShape[argShapeIdx])</span></a>
<a name="582"><span class="lineNum">     582 </span><span class="lineCov">         49 :         argShapeIdx++;</span></a>
<a name="583"><span class="lineNum">     583 </span>            : </a>
<a name="584"><span class="lineNum">     584 </span><span class="lineCov">        407 :     if (argShapeIdx != static_cast&lt;int64_t&gt;(argShape.size()))</span></a>
<a name="585"><span class="lineNum">     585 </span><span class="lineCov">          4 :       return emitOptionalError(</span></a>
<a name="586"><span class="lineNum">     586 </span><span class="lineCov">          4 :           loc, &quot;The shape of reduction-region's argument at index &quot;,</span></a>
<a name="587"><span class="lineNum">     587 </span><span class="lineCov">          4 :           numInputs + inputIdx,</span></a>
<a name="588"><span class="lineNum">     588 </span>            :           &quot; is not compatible with that of reduce-op's input-parameter &quot;</a>
<a name="589"><span class="lineNum">     589 </span>            :           &quot;at index &quot;,</a>
<a name="590"><span class="lineNum">     590 </span>            :           inputIdx);</a>
<a name="591"><span class="lineNum">     591 </span><span class="lineCov">        445 :   }</span></a>
<a name="592"><span class="lineNum">     592 </span>            : </a>
<a name="593"><span class="lineNum">     593 </span><span class="lineCov">        333 :   return success();</span></a>
<a name="594"><span class="lineNum">     594 </span><span class="lineCov">        469 : }</span></a>
<a name="595"><span class="lineNum">     595 </span>            : </a>
<a name="596"><span class="lineNum">     596 </span><span class="lineCov">        156 : LogicalResult verifyReduceWindowOpInputsAndInferWindow(</span></a>
<a name="597"><span class="lineNum">     597 </span>            :     Optional&lt;Location&gt; location, SmallVector&lt;TensorType&gt; inputArgTypes,</a>
<a name="598"><span class="lineNum">     598 </span>            :     SmallVector&lt;TensorType&gt; initValueTypes,</a>
<a name="599"><span class="lineNum">     599 </span>            :     DenseIntElementsAttr windowDimensions,</a>
<a name="600"><span class="lineNum">     600 </span>            :     Optional&lt;DenseIntElementsAttr&gt; windowStrides,</a>
<a name="601"><span class="lineNum">     601 </span>            :     Optional&lt;DenseIntElementsAttr&gt; baseDilations,</a>
<a name="602"><span class="lineNum">     602 </span>            :     Optional&lt;DenseIntElementsAttr&gt; windowDilations,</a>
<a name="603"><span class="lineNum">     603 </span>            :     Optional&lt;DenseIntElementsAttr&gt; padding,</a>
<a name="604"><span class="lineNum">     604 </span>            :     Optional&lt;DenseElementsAttr&gt; windowReversal,</a>
<a name="605"><span class="lineNum">     605 </span>            :     SmallVector&lt;int64_t&gt;&amp; windowDims,</a>
<a name="606"><span class="lineNum">     606 </span><span class="lineCov">        156 :     SmallVector&lt;WindowDimension&gt;&amp; inferredWindow) {</span></a>
<a name="607"><span class="lineNum">     607 </span>            :   // Check for unranked tensors in input operands.</a>
<a name="608"><span class="lineNum">     608 </span><span class="lineCov">        156 :   uint64_t numInputs = inputArgTypes.size();</span></a>
<a name="609"><span class="lineNum">     609 </span><span class="lineCov">        156 :   int64_t rankedInputIdx = -1;</span></a>
<a name="610"><span class="lineNum">     610 </span><span class="lineCov">        324 :   for (uint64_t inputIdx = 0; inputIdx &lt; numInputs; ++inputIdx) {</span></a>
<a name="611"><span class="lineNum">     611 </span><span class="lineCov">        168 :     if (inputArgTypes[inputIdx].hasRank()) {</span></a>
<a name="612"><span class="lineNum">     612 </span><span class="lineCov">        156 :       rankedInputIdx = inputIdx;</span></a>
<a name="613"><span class="lineNum">     613 </span><span class="lineCov">        156 :       break;</span></a>
<a name="614"><span class="lineNum">     614 </span>            :     }</a>
<a name="615"><span class="lineNum">     615 </span><span class="lineCov">         12 :   }</span></a>
<a name="616"><span class="lineNum">     616 </span><span class="lineCov">        156 :   bool allInputsUnranked = (rankedInputIdx == -1);</span></a>
<a name="617"><span class="lineNum">     617 </span>            : </a>
<a name="618"><span class="lineNum">     618 </span>            :   // P1.</a>
<a name="619"><span class="lineNum">     619 </span><span class="lineCov">        156 :   if (!allInputsUnranked) {</span></a>
<a name="620"><span class="lineNum">     620 </span><span class="lineCov">        416 :     for (uint64_t inputIdx = 0; inputIdx &lt; numInputs; ++inputIdx) {</span></a>
<a name="621"><span class="lineNum">     621 </span><span class="lineCov">        520 :       if (failed(mlir::verifyCompatibleShape(inputArgTypes[rankedInputIdx],</span></a>
<a name="622"><span class="lineNum">     622 </span><span class="lineCov">        260 :                                              inputArgTypes[inputIdx]))) {</span></a>
<a name="623"><span class="lineNum">     623 </span><span class="lineCov">          2 :         return emitOptionalError(</span></a>
<a name="624"><span class="lineNum">     624 </span><span class="lineCov">          2 :             location, &quot;expects all inputs to have compatible shapes. Shape at&quot;,</span></a>
<a name="625"><span class="lineNum">     625 </span>            :             &quot; input-index &quot;, inputIdx,</a>
<a name="626"><span class="lineNum">     626 </span>            :             &quot; is not compatible with shape at input-index &quot;, rankedInputIdx);</a>
<a name="627"><span class="lineNum">     627 </span>            :       }</a>
<a name="628"><span class="lineNum">     628 </span><span class="lineCov">        258 :     }</span></a>
<a name="629"><span class="lineNum">     629 </span><span class="lineCov">        154 :   }</span></a>
<a name="630"><span class="lineNum">     630 </span>            : </a>
<a name="631"><span class="lineNum">     631 </span>            :   // P2.</a>
<a name="632"><span class="lineNum">     632 </span><span class="lineCov">        154 :   auto windowDimsOrErr =</span></a>
<a name="633"><span class="lineNum">     633 </span><span class="lineCov">        154 :       convert1DAttribute(windowDimensions, location, &quot;window_dimensions&quot;);</span></a>
<a name="634"><span class="lineNum">     634 </span><span class="lineCov">        154 :   if (failed(windowDimsOrErr)) return failure();</span></a>
<a name="635"><span class="lineNum">     635 </span><span class="lineCov">        396 :   for (const auto inputType : inputArgTypes) {</span></a>
<a name="636"><span class="lineNum">     636 </span><span class="lineCov">        246 :     if (!inputType.hasRank()) continue;</span></a>
<a name="637"><span class="lineNum">     637 </span><span class="lineCov">        234 :     if (inputType.getRank() != static_cast&lt;int64_t&gt;((*windowDimsOrErr).size()))</span></a>
<a name="638"><span class="lineNum">     638 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="639"><span class="lineNum">     639 </span><span class="lineCov">          2 :           location, &quot;expects window-dimensions size == input rank, but got &quot;,</span></a>
<a name="640"><span class="lineNum">     640 </span><span class="lineCov">          2 :           &quot;window-dimensions size: &quot;, (*windowDimsOrErr).size(),</span></a>
<a name="641"><span class="lineNum">     641 </span><span class="lineCov">          2 :           &quot; and input: &quot;, inputType, &quot; with rank = &quot;, inputType.getRank(), &quot;.&quot;);</span></a>
<a name="642"><span class="lineNum">     642 </span><span class="lineCov">        246 :   }</span></a>
<a name="643"><span class="lineNum">     643 </span>            : </a>
<a name="644"><span class="lineNum">     644 </span>            :   // P3.</a>
<a name="645"><span class="lineNum">     645 </span><span class="lineCov">        148 :   auto paddingOrErr = convertPaddingAttribute(padding, location);</span></a>
<a name="646"><span class="lineNum">     646 </span><span class="lineCov">        148 :   if (failed(paddingOrErr)) return failure();</span></a>
<a name="647"><span class="lineNum">     647 </span>            : </a>
<a name="648"><span class="lineNum">     648 </span><span class="lineCov">        146 :   auto windowStridesOrErr =</span></a>
<a name="649"><span class="lineNum">     649 </span><span class="lineCov">        146 :       convert1DAttribute(windowStrides, location, &quot;window_strides&quot;);</span></a>
<a name="650"><span class="lineNum">     650 </span><span class="lineCov">        146 :   if (failed(windowStridesOrErr)) return failure();</span></a>
<a name="651"><span class="lineNum">     651 </span><span class="lineCov">        144 :   auto baseDilationsOrErr =</span></a>
<a name="652"><span class="lineNum">     652 </span><span class="lineCov">        144 :       convert1DAttribute(baseDilations, location, &quot;base_dilations&quot;);</span></a>
<a name="653"><span class="lineNum">     653 </span><span class="lineCov">        144 :   if (failed(baseDilationsOrErr)) return failure();</span></a>
<a name="654"><span class="lineNum">     654 </span><span class="lineCov">        142 :   auto windowDilationsOrErr =</span></a>
<a name="655"><span class="lineNum">     655 </span><span class="lineCov">        142 :       convert1DAttribute(windowDilations, location, &quot;window_dilations&quot;);</span></a>
<a name="656"><span class="lineNum">     656 </span><span class="lineCov">        142 :   if (failed(windowDilationsOrErr)) return failure();</span></a>
<a name="657"><span class="lineNum">     657 </span><span class="lineCov">        280 :   auto windowReversalOrErr = convertWindowReversalAttribute(</span></a>
<a name="658"><span class="lineNum">     658 </span><span class="lineCov">        140 :       windowReversal, location, &quot;window_reversal&quot;);</span></a>
<a name="659"><span class="lineNum">     659 </span><span class="lineCov">        140 :   if (failed(windowReversalOrErr)) return failure();</span></a>
<a name="660"><span class="lineNum">     660 </span>            : </a>
<a name="661"><span class="lineNum">     661 </span><span class="lineCov">        280 :   auto windowOrErr = verifyWindowAttributesAndInferWindowDimensions(</span></a>
<a name="662"><span class="lineNum">     662 </span><span class="lineCov">        140 :       *windowDimsOrErr, *windowStridesOrErr, *paddingOrErr,</span></a>
<a name="663"><span class="lineNum">     663 </span><span class="lineCov">        140 :       /*lhsDilation=*/*baseDilationsOrErr,</span></a>
<a name="664"><span class="lineNum">     664 </span><span class="lineCov">        140 :       /*rhsDilation=*/*windowDilationsOrErr, *windowReversalOrErr, location);</span></a>
<a name="665"><span class="lineNum">     665 </span><span class="lineCov">        140 :   if (failed(windowOrErr)) return failure();</span></a>
<a name="666"><span class="lineNum">     666 </span>            : </a>
<a name="667"><span class="lineNum">     667 </span><span class="lineCov">        124 :   windowDims.append(*windowDimsOrErr);</span></a>
<a name="668"><span class="lineNum">     668 </span><span class="lineCov">        124 :   inferredWindow.append(*windowOrErr);</span></a>
<a name="669"><span class="lineNum">     669 </span><span class="lineCov">        124 :   return success();</span></a>
<a name="670"><span class="lineNum">     670 </span><span class="lineCov">        156 : }</span></a>
<a name="671"><span class="lineNum">     671 </span>            : </a>
<a name="672"><span class="lineNum">     672 </span>            : // Shape function can be called directly from autogenerated `build()` function,</a>
<a name="673"><span class="lineNum">     673 </span>            : // which may not guarantee the added region(s) in `odsState.regions` to be</a>
<a name="674"><span class="lineNum">     674 </span>            : // non-empty. Need check it here to avoid a crash for the ops that need regions</a>
<a name="675"><span class="lineNum">     675 </span>            : // in type inference, i.e. `IfOp/CaseOp/MapOp`.</a>
<a name="676"><span class="lineNum">     676 </span><span class="lineCov">        238 : LogicalResult verifyRegionNotEmpty(Optional&lt;Location&gt; location,</span></a>
<a name="677"><span class="lineNum">     677 </span><span class="lineCov">        238 :                                    Region&amp; region) {</span></a>
<a name="678"><span class="lineNum">     678 </span><span class="lineCov">        238 :   if (region.empty())</span></a>
<a name="679"><span class="lineNum">     679 </span><span class="lineNoCov">          0 :     return emitOptionalError(location, &quot;expect non-empty region&quot;);</span></a>
<a name="680"><span class="lineNum">     680 </span><span class="lineCov">        238 :   return success();</span></a>
<a name="681"><span class="lineNum">     681 </span><span class="lineCov">        238 : }</span></a>
<a name="682"><span class="lineNum">     682 </span>            : </a>
<a name="683"><span class="lineNum">     683 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="684"><span class="lineNum">     684 </span>            : // Shape functions for ops.</a>
<a name="685"><span class="lineNum">     685 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="686"><span class="lineNum">     686 </span>            : </a>
<a name="687"><span class="lineNum">     687 </span><span class="lineCov">        130 : LogicalResult inferAbsOp(Optional&lt;Location&gt;, Value operand,</span></a>
<a name="688"><span class="lineNum">     688 </span><span class="lineCov">        130 :                          SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="689"><span class="lineNum">     689 </span><span class="lineCov">        130 :   auto operandTy = operand.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="690"><span class="lineNum">     690 </span><span class="lineCov">        130 :   Type elementTy = operandTy.getElementType();</span></a>
<a name="691"><span class="lineNum">     691 </span><span class="lineCov">        130 :   if (auto complexTy = elementTy.dyn_cast&lt;ComplexType&gt;()) {</span></a>
<a name="692"><span class="lineNum">     692 </span><span class="lineCov">         14 :     elementTy = complexTy.getElementType();</span></a>
<a name="693"><span class="lineNum">     693 </span><span class="lineCov">         14 :   }</span></a>
<a name="694"><span class="lineNum">     694 </span>            : </a>
<a name="695"><span class="lineNum">     695 </span><span class="lineCov">        130 :   Type resultTy;</span></a>
<a name="696"><span class="lineNum">     696 </span><span class="lineCov">        138 :   if (auto rankedOperandTy = operandTy.dyn_cast&lt;RankedTensorType&gt;()) {</span></a>
<a name="697"><span class="lineNum">     697 </span><span class="lineCov">        244 :     resultTy = RankedTensorType::get(operandTy.getShape(), elementTy,</span></a>
<a name="698"><span class="lineNum">     698 </span><span class="lineCov">        122 :                                      rankedOperandTy.getEncoding());</span></a>
<a name="699"><span class="lineNum">     699 </span><span class="lineCov">        130 :   } else if (operandTy.hasRank()) {</span></a>
<a name="700"><span class="lineNum">     700 </span><span class="lineNoCov">          0 :     resultTy = RankedTensorType::get(operandTy.getShape(), elementTy);</span></a>
<a name="701"><span class="lineNum">     701 </span><span class="lineNoCov">          0 :   } else {</span></a>
<a name="702"><span class="lineNum">     702 </span><span class="lineCov">          8 :     resultTy = UnrankedTensorType::get(elementTy);</span></a>
<a name="703"><span class="lineNum">     703 </span>            :   }</a>
<a name="704"><span class="lineNum">     704 </span><span class="lineCov">        130 :   inferredReturnTypes.push_back(resultTy);</span></a>
<a name="705"><span class="lineNum">     705 </span><span class="lineCov">        130 :   return success();</span></a>
<a name="706"><span class="lineNum">     706 </span><span class="lineCov">        130 : }</span></a>
<a name="707"><span class="lineNum">     707 </span>            : </a>
<a name="708"><span class="lineNum">     708 </span><span class="lineCov">         44 : LogicalResult inferAfterAllOp(Dialect* dialect, Optional&lt;Location&gt; location,</span></a>
<a name="709"><span class="lineNum">     709 </span><span class="lineCov">         44 :                               SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="710"><span class="lineNum">     710 </span><span class="lineCov">         44 :   auto hloDialect = cast&lt;HloDialectInterface&gt;(dialect);</span></a>
<a name="711"><span class="lineNum">     711 </span><span class="lineCov">         44 :   inferredReturnTypes.push_back(hloDialect-&gt;createTokenType());</span></a>
<a name="712"><span class="lineNum">     712 </span><span class="lineCov">         44 :   return success();</span></a>
<a name="713"><span class="lineNum">     713 </span><span class="lineCov">         44 : }</span></a>
<a name="714"><span class="lineNum">     714 </span>            : </a>
<a name="715"><span class="lineNum">     715 </span><span class="lineCov">         50 : LogicalResult inferAllToAllOp(</span></a>
<a name="716"><span class="lineNum">     716 </span>            :     Optional&lt;Location&gt; location, Value operand, int64_t splitDimension,</a>
<a name="717"><span class="lineNum">     717 </span>            :     int64_t concatDimension, int64_t splitCount,</a>
<a name="718"><span class="lineNum">     718 </span>            :     DenseIntElementsAttr replicaGroups,</a>
<a name="719"><span class="lineNum">     719 </span><span class="lineCov">         50 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="720"><span class="lineNum">     720 </span><span class="lineCov">         50 :   if (splitCount &lt;= 0)</span></a>
<a name="721"><span class="lineNum">     721 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;AllToAll split_count must be &gt; 0&quot;);</span></a>
<a name="722"><span class="lineNum">     722 </span>            : </a>
<a name="723"><span class="lineNum">     723 </span><span class="lineCov">         96 :   if (failed(hlo::verifyReplicaGroups(location, replicaGroups,</span></a>
<a name="724"><span class="lineNum">     724 </span>            :                                       /*allGroupsMustHaveSameSize=*/true,</a>
<a name="725"><span class="lineNum">     725 </span>            :                                       /*useGlobalDeviceIds=*/false,</a>
<a name="726"><span class="lineNum">     726 </span><span class="lineCov">         48 :                                       splitCount)))</span></a>
<a name="727"><span class="lineNum">     727 </span><span class="lineCov">         10 :     return failure();</span></a>
<a name="728"><span class="lineNum">     728 </span>            : </a>
<a name="729"><span class="lineNum">     729 </span><span class="lineCov">         38 :   if (splitDimension &lt; 0)</span></a>
<a name="730"><span class="lineNum">     730 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="731"><span class="lineNum">     731 </span>            :                              &quot;AllToAll split_dimension cannot be negative&quot;);</a>
<a name="732"><span class="lineNum">     732 </span>            : </a>
<a name="733"><span class="lineNum">     733 </span><span class="lineCov">         36 :   if (concatDimension &lt; 0)</span></a>
<a name="734"><span class="lineNum">     734 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="735"><span class="lineNum">     735 </span>            :                              &quot;AllToAll concat_dimension cannot be negative&quot;);</a>
<a name="736"><span class="lineNum">     736 </span>            : </a>
<a name="737"><span class="lineNum">     737 </span><span class="lineCov">         34 :   Type operandType = operand.getType();</span></a>
<a name="738"><span class="lineNum">     738 </span><span class="lineCov">         34 :   RankedTensorType operandRankedType = operandType.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="739"><span class="lineNum">     739 </span><span class="lineCov">         34 :   if (!operandRankedType) {</span></a>
<a name="740"><span class="lineNum">     740 </span><span class="lineCov">          8 :     inferredReturnShapes.emplace_back(</span></a>
<a name="741"><span class="lineNum">     741 </span><span class="lineCov">          4 :         operandType.cast&lt;TensorType&gt;().getElementType());</span></a>
<a name="742"><span class="lineNum">     742 </span><span class="lineCov">          4 :     return success();</span></a>
<a name="743"><span class="lineNum">     743 </span>            :   }</a>
<a name="744"><span class="lineNum">     744 </span>            : </a>
<a name="745"><span class="lineNum">     745 </span><span class="lineCov">         30 :   int64_t inputRank = operandRankedType.getRank();</span></a>
<a name="746"><span class="lineNum">     746 </span><span class="lineCov">         30 :   if (splitDimension &gt;= inputRank)</span></a>
<a name="747"><span class="lineNum">     747 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;AllToAll split_dimension &quot;,</span></a>
<a name="748"><span class="lineNum">     748 </span>            :                              splitDimension,</a>
<a name="749"><span class="lineNum">     749 </span>            :                              &quot; is out-of-bounds for input rank &quot;, inputRank);</a>
<a name="750"><span class="lineNum">     750 </span><span class="lineCov">         28 :   if (concatDimension &gt;= inputRank)</span></a>
<a name="751"><span class="lineNum">     751 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;AllToAll concat_dimension &quot;,</span></a>
<a name="752"><span class="lineNum">     752 </span>            :                              concatDimension,</a>
<a name="753"><span class="lineNum">     753 </span>            :                              &quot; is out-of-bounds for input rank &quot;, inputRank);</a>
<a name="754"><span class="lineNum">     754 </span>            : </a>
<a name="755"><span class="lineNum">     755 </span>            :   // If operand is ranked, size of split dimension should be a multiple of split</a>
<a name="756"><span class="lineNum">     756 </span>            :   // count.</a>
<a name="757"><span class="lineNum">     757 </span><span class="lineCov">         26 :   auto splitDimSize = operandRankedType.getDimSize(splitDimension);</span></a>
<a name="758"><span class="lineNum">     758 </span><span class="lineCov">         26 :   if (splitDimSize % splitCount != 0)</span></a>
<a name="759"><span class="lineNum">     759 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="760"><span class="lineNum">     760 </span><span class="lineCov">          2 :         location, &quot;split dimension has size &quot;, splitDimSize,</span></a>
<a name="761"><span class="lineNum">     761 </span>            :         &quot;, expected to be a multiple of split_count &quot;, splitCount);</a>
<a name="762"><span class="lineNum">     762 </span><span class="lineCov">         48 :   SmallVector&lt;int64_t&gt; resultShape(operandRankedType.getShape().begin(),</span></a>
<a name="763"><span class="lineNum">     763 </span><span class="lineCov">         24 :                                    operandRankedType.getShape().end());</span></a>
<a name="764"><span class="lineNum">     764 </span><span class="lineCov">         24 :   resultShape[splitDimension] /= splitCount;</span></a>
<a name="765"><span class="lineNum">     765 </span><span class="lineCov">         24 :   resultShape[concatDimension] *= splitCount;</span></a>
<a name="766"><span class="lineNum">     766 </span><span class="lineCov">         48 :   inferredReturnShapes.emplace_back(resultShape,</span></a>
<a name="767"><span class="lineNum">     767 </span><span class="lineCov">         24 :                                     operandRankedType.getElementType());</span></a>
<a name="768"><span class="lineNum">     768 </span><span class="lineCov">         24 :   return success();</span></a>
<a name="769"><span class="lineNum">     769 </span><span class="lineCov">         50 : }</span></a>
<a name="770"><span class="lineNum">     770 </span>            : </a>
<a name="771"><span class="lineNum">     771 </span><span class="lineCov">         36 : LogicalResult inferBatchNormGradOp(</span></a>
<a name="772"><span class="lineNum">     772 </span>            :     Optional&lt;Location&gt; location, Value operand, Value scale,</a>
<a name="773"><span class="lineNum">     773 </span>            :     int64_t featureIndex,</a>
<a name="774"><span class="lineNum">     774 </span><span class="lineCov">         36 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="775"><span class="lineNum">     775 </span><span class="lineCov">         36 :   if (failed(verifyBatchNorm(location, operand, scale, featureIndex)))</span></a>
<a name="776"><span class="lineNum">     776 </span><span class="lineCov">          8 :     return failure();</span></a>
<a name="777"><span class="lineNum">     777 </span><span class="lineCov">         28 :   auto operandType = operand.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="778"><span class="lineNum">     778 </span><span class="lineCov">         28 :   inferredReturnShapes.emplace_back(operandType.cast&lt;ShapedType&gt;());</span></a>
<a name="779"><span class="lineNum">     779 </span>            : </a>
<a name="780"><span class="lineNum">     780 </span><span class="lineCov">         28 :   const int64_t featureCount = operandType.getDimSize(featureIndex);</span></a>
<a name="781"><span class="lineNum">     781 </span><span class="lineCov">         28 :   SmallVector&lt;int64_t&gt; featureShape{featureCount};</span></a>
<a name="782"><span class="lineNum">     782 </span><span class="lineCov">         28 :   inferredReturnShapes.emplace_back(featureShape, operandType.getElementType());</span></a>
<a name="783"><span class="lineNum">     783 </span><span class="lineCov">         28 :   inferredReturnShapes.emplace_back(featureShape, operandType.getElementType());</span></a>
<a name="784"><span class="lineNum">     784 </span><span class="lineCov">         28 :   return success();</span></a>
<a name="785"><span class="lineNum">     785 </span><span class="lineCov">         36 : }</span></a>
<a name="786"><span class="lineNum">     786 </span>            : </a>
<a name="787"><span class="lineNum">     787 </span><span class="lineCov">         26 : LogicalResult inferBatchNormInferenceOp(</span></a>
<a name="788"><span class="lineNum">     788 </span>            :     Optional&lt;Location&gt; location, Value operand, Value scale,</a>
<a name="789"><span class="lineNum">     789 </span>            :     int64_t featureIndex,</a>
<a name="790"><span class="lineNum">     790 </span><span class="lineCov">         26 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="791"><span class="lineNum">     791 </span><span class="lineCov">         26 :   if (failed(verifyBatchNorm(location, operand, scale, featureIndex)))</span></a>
<a name="792"><span class="lineNum">     792 </span><span class="lineCov">          6 :     return failure();</span></a>
<a name="793"><span class="lineNum">     793 </span><span class="lineCov">         20 :   auto operandType = operand.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="794"><span class="lineNum">     794 </span><span class="lineCov">         20 :   inferredReturnShapes.emplace_back(operandType.cast&lt;ShapedType&gt;());</span></a>
<a name="795"><span class="lineNum">     795 </span><span class="lineCov">         20 :   return success();</span></a>
<a name="796"><span class="lineNum">     796 </span><span class="lineCov">         26 : }</span></a>
<a name="797"><span class="lineNum">     797 </span>            : </a>
<a name="798"><span class="lineNum">     798 </span><span class="lineCov">         34 : LogicalResult inferBatchNormTrainingOp(</span></a>
<a name="799"><span class="lineNum">     799 </span>            :     Optional&lt;Location&gt; location, Value operand, Value scale,</a>
<a name="800"><span class="lineNum">     800 </span>            :     int64_t featureIndex,</a>
<a name="801"><span class="lineNum">     801 </span><span class="lineCov">         34 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="802"><span class="lineNum">     802 </span><span class="lineCov">         34 :   if (failed(verifyBatchNorm(location, operand, scale, featureIndex)))</span></a>
<a name="803"><span class="lineNum">     803 </span><span class="lineCov">          6 :     return failure();</span></a>
<a name="804"><span class="lineNum">     804 </span><span class="lineCov">         28 :   auto operandType = operand.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="805"><span class="lineNum">     805 </span><span class="lineCov">         28 :   inferredReturnShapes.emplace_back(operandType.cast&lt;ShapedType&gt;());</span></a>
<a name="806"><span class="lineNum">     806 </span>            : </a>
<a name="807"><span class="lineNum">     807 </span><span class="lineCov">         28 :   const int64_t featureCount = operandType.getDimSize(featureIndex);</span></a>
<a name="808"><span class="lineNum">     808 </span><span class="lineCov">         28 :   SmallVector&lt;int64_t&gt; featureShape{featureCount};</span></a>
<a name="809"><span class="lineNum">     809 </span><span class="lineCov">         28 :   inferredReturnShapes.emplace_back(featureShape, operandType.getElementType());</span></a>
<a name="810"><span class="lineNum">     810 </span><span class="lineCov">         28 :   inferredReturnShapes.emplace_back(featureShape, operandType.getElementType());</span></a>
<a name="811"><span class="lineNum">     811 </span><span class="lineCov">         28 :   return success();</span></a>
<a name="812"><span class="lineNum">     812 </span><span class="lineCov">         34 : }</span></a>
<a name="813"><span class="lineNum">     813 </span>            : </a>
<a name="814"><span class="lineNum">     814 </span><span class="lineCov">         43 : LogicalResult inferBroadcastOp(</span></a>
<a name="815"><span class="lineNum">     815 </span>            :     Optional&lt;Location&gt; location, Value operand,</a>
<a name="816"><span class="lineNum">     816 </span>            :     DenseIntElementsAttr broadcastSizes,</a>
<a name="817"><span class="lineNum">     817 </span><span class="lineCov">         43 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="818"><span class="lineNum">     818 </span><span class="lineCov">         43 :   auto operandType = operand.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="819"><span class="lineNum">     819 </span><span class="lineCov">         43 :   if (!operandType) return failure();</span></a>
<a name="820"><span class="lineNum">     820 </span>            : </a>
<a name="821"><span class="lineNum">     821 </span>            :   // TODO: These should be expressed as type constraints.</a>
<a name="822"><span class="lineNum">     822 </span><span class="lineCov">         43 :   auto sizesRank = broadcastSizes.getType().getRank();</span></a>
<a name="823"><span class="lineNum">     823 </span><span class="lineCov">         43 :   if (sizesRank != 1)</span></a>
<a name="824"><span class="lineNum">     824 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;broadcast_sizes has rank &quot;, sizesRank,</span></a>
<a name="825"><span class="lineNum">     825 </span>            :                              &quot; instead of rank 1&quot;);</a>
<a name="826"><span class="lineNum">     826 </span>            : </a>
<a name="827"><span class="lineNum">     827 </span><span class="lineCov">        113 :   for (int64_t size : broadcastSizes.getValues&lt;int64_t&gt;())</span></a>
<a name="828"><span class="lineNum">     828 </span><span class="lineCov">         72 :     if (size &lt; 0)</span></a>
<a name="829"><span class="lineNum">     829 </span><span class="lineCov">          2 :       return emitOptionalError(location,</span></a>
<a name="830"><span class="lineNum">     830 </span><span class="lineCov">         72 :                                &quot;Broadcast with negative dimension size &quot;, size);</span></a>
<a name="831"><span class="lineNum">     831 </span><span class="lineCov">         39 :   SmallVector&lt;int64_t&gt; shapeValues(broadcastSizes.getValues&lt;int64_t&gt;());</span></a>
<a name="832"><span class="lineNum">     832 </span><span class="lineCov">         39 :   llvm::append_range(shapeValues, operandType.getShape());</span></a>
<a name="833"><span class="lineNum">     833 </span>            : </a>
<a name="834"><span class="lineNum">     834 </span><span class="lineCov">         39 :   inferredReturnShapes.emplace_back(shapeValues, operandType.getElementType());</span></a>
<a name="835"><span class="lineNum">     835 </span><span class="lineCov">         39 :   return success();</span></a>
<a name="836"><span class="lineNum">     836 </span><span class="lineCov">         43 : }</span></a>
<a name="837"><span class="lineNum">     837 </span>            : </a>
<a name="838"><span class="lineNum">     838 </span>            : // Used by IfOp and CaseOp</a>
<a name="839"><span class="lineNum">     839 </span><span class="lineCov">        102 : LogicalResult inferConditionalOp(Optional&lt;Location&gt; location,</span></a>
<a name="840"><span class="lineNum">     840 </span>            :                                  RegionRange branches,</a>
<a name="841"><span class="lineNum">     841 </span><span class="lineCov">        102 :                                  SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="842"><span class="lineNum">     842 </span><span class="lineCov">        102 :   if (branches.empty())</span></a>
<a name="843"><span class="lineNum">     843 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;expect at least one branch&quot;);</span></a>
<a name="844"><span class="lineNum">     844 </span><span class="lineCov">        282 :   for (auto region : branches)</span></a>
<a name="845"><span class="lineNum">     845 </span><span class="lineCov">        182 :     if (failed(verifyRegionNotEmpty(location, *region))) return failure();</span></a>
<a name="846"><span class="lineNum">     846 </span>            : </a>
<a name="847"><span class="lineNum">     847 </span><span class="lineCov">        100 :   ValueTypeRange&lt;OperandRange&gt; branch0ResultTypes =</span></a>
<a name="848"><span class="lineNum">     848 </span><span class="lineCov">        100 :       branches[0]-&gt;front().getTerminator()-&gt;getOperandTypes();</span></a>
<a name="849"><span class="lineNum">     849 </span><span class="lineCov">        278 :   for (unsigned i = 0; i &lt; branches.size(); ++i) {</span></a>
<a name="850"><span class="lineNum">     850 </span><span class="lineCov">        178 :     Twine branchName = &quot;branch &quot; + Twine(i);</span></a>
<a name="851"><span class="lineNum">     851 </span><span class="lineCov">        178 :     Region* region = branches[i];</span></a>
<a name="852"><span class="lineNum">     852 </span><span class="lineCov">        178 :     if (region-&gt;getNumArguments() != 0)</span></a>
<a name="853"><span class="lineNum">     853 </span><span class="lineCov">         12 :       return emitOptionalError(location, branchName,</span></a>
<a name="854"><span class="lineNum">     854 </span>            :                                &quot; must have 0 arguments, but found &quot;,</a>
<a name="855"><span class="lineNum">     855 </span><span class="lineCov">          6 :                                region-&gt;getNumArguments());</span></a>
<a name="856"><span class="lineNum">     856 </span>            : </a>
<a name="857"><span class="lineNum">     857 </span><span class="lineCov">        172 :     auto branchResultTypes = region-&gt;front().getTerminator()-&gt;getOperandTypes();</span></a>
<a name="858"><span class="lineNum">     858 </span><span class="lineCov">        344 :     if (!hlo::isCompatibleForHloTypeInference(branch0ResultTypes,</span></a>
<a name="859"><span class="lineNum">     859 </span><span class="lineCov">        172 :                                               branchResultTypes))</span></a>
<a name="860"><span class="lineNum">     860 </span><span class="lineCov">          6 :       return emitOptionalError(location, &quot;branch 0 and &quot;, branchName,</span></a>
<a name="861"><span class="lineNum">     861 </span>            :                                &quot; have mismatched return types: &quot;,</a>
<a name="862"><span class="lineNum">     862 </span>            :                                branch0ResultTypes, &quot; vs &quot;, branchResultTypes);</a>
<a name="863"><span class="lineNum">     863 </span><span class="lineCov">        178 :   }</span></a>
<a name="864"><span class="lineNum">     864 </span><span class="lineCov">        176 :   for (auto resultType : branch0ResultTypes)</span></a>
<a name="865"><span class="lineNum">     865 </span><span class="lineCov">         88 :     inferredReturnTypes.push_back(resultType);</span></a>
<a name="866"><span class="lineNum">     866 </span><span class="lineCov">         88 :   return success();</span></a>
<a name="867"><span class="lineNum">     867 </span><span class="lineCov">        102 : }</span></a>
<a name="868"><span class="lineNum">     868 </span>            : </a>
<a name="869"><span class="lineNum">     869 </span><span class="lineCov">         54 : LogicalResult inferCaseOp(Optional&lt;Location&gt; location, RegionRange branches,</span></a>
<a name="870"><span class="lineNum">     870 </span><span class="lineCov">         54 :                           SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="871"><span class="lineNum">     871 </span><span class="lineCov">         54 :   return inferConditionalOp(location, branches, inferredReturnTypes);</span></a>
<a name="872"><span class="lineNum">     872 </span>            : }</a>
<a name="873"><span class="lineNum">     873 </span>            : </a>
<a name="874"><span class="lineNum">     874 </span>            : // The following properties are already enforced by the ODS:</a>
<a name="875"><span class="lineNum">     875 </span>            : //   P0. a.element_type is floating or complex</a>
<a name="876"><span class="lineNum">     876 </span>            : // We intend to verify the following properties</a>
<a name="877"><span class="lineNum">     877 </span>            : //   P1. The 'a' argument to Cholesky must have rank &gt;= 2, got shape %s</a>
<a name="878"><span class="lineNum">     878 </span>            : //   P2. The two minor dimensions of 'a' must have equal size, got %s.</a>
<a name="879"><span class="lineNum">     879 </span><span class="lineCov">         34 : LogicalResult inferCholeskyOp(</span></a>
<a name="880"><span class="lineNum">     880 </span>            :     Optional&lt;Location&gt; location, Value a,</a>
<a name="881"><span class="lineNum">     881 </span><span class="lineCov">         34 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="882"><span class="lineNum">     882 </span><span class="lineCov">         34 :   Type aType = a.getType();</span></a>
<a name="883"><span class="lineNum">     883 </span><span class="lineCov">         34 :   RankedTensorType aRankedType = aType.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="884"><span class="lineNum">     884 </span><span class="lineCov">         34 :   if (!aRankedType) {</span></a>
<a name="885"><span class="lineNum">     885 </span><span class="lineNoCov">          0 :     inferredReturnShapes.emplace_back(</span></a>
<a name="886"><span class="lineNum">     886 </span><span class="lineNoCov">          0 :         aType.cast&lt;TensorType&gt;().getElementType());</span></a>
<a name="887"><span class="lineNum">     887 </span><span class="lineNoCov">          0 :     return success();</span></a>
<a name="888"><span class="lineNum">     888 </span>            :   }</a>
<a name="889"><span class="lineNum">     889 </span>            : </a>
<a name="890"><span class="lineNum">     890 </span><span class="lineCov">         34 :   ArrayRef&lt;int64_t&gt; aShape = aRankedType.getShape();</span></a>
<a name="891"><span class="lineNum">     891 </span><span class="lineCov">         34 :   if (aShape.size() &lt; 2) {</span></a>
<a name="892"><span class="lineNum">     892 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="893"><span class="lineNum">     893 </span><span class="lineCov">          2 :         location, &quot;argument 'a' must have rank &gt;= 2, got shape &quot;, aShape, &quot;.&quot;);</span></a>
<a name="894"><span class="lineNum">     894 </span>            :   }</a>
<a name="895"><span class="lineNum">     895 </span>            : </a>
<a name="896"><span class="lineNum">     896 </span><span class="lineCov">         32 :   int64_t lastDim = aShape[aShape.size() - 1];</span></a>
<a name="897"><span class="lineNum">     897 </span><span class="lineCov">         32 :   int64_t penultimateDim = aShape[aShape.size() - 2];</span></a>
<a name="898"><span class="lineNum">     898 </span><span class="lineCov">         32 :   if (!isDynamicDimSize(lastDim) &amp;&amp; !isDynamicDimSize(penultimateDim) &amp;&amp;</span></a>
<a name="899"><span class="lineNum">     899 </span><span class="lineCov">         32 :       lastDim != penultimateDim) {</span></a>
<a name="900"><span class="lineNum">     900 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="901"><span class="lineNum">     901 </span><span class="lineCov">          2 :         location, &quot;minor dimensions of 'a' must have equal size, got shape &quot;,</span></a>
<a name="902"><span class="lineNum">     902 </span>            :         aShape, &quot;.&quot;);</a>
<a name="903"><span class="lineNum">     903 </span>            :   }</a>
<a name="904"><span class="lineNum">     904 </span><span class="lineCov">         60 :   inferredReturnShapes.emplace_back(aRankedType.getShape(),</span></a>
<a name="905"><span class="lineNum">     905 </span><span class="lineCov">         30 :                                     aRankedType.getElementType());</span></a>
<a name="906"><span class="lineNum">     906 </span><span class="lineCov">         30 :   return success();</span></a>
<a name="907"><span class="lineNum">     907 </span><span class="lineCov">         34 : }</span></a>
<a name="908"><span class="lineNum">     908 </span>            : </a>
<a name="909"><span class="lineNum">     909 </span><span class="lineCov">         50 : LogicalResult inferClampOp(</span></a>
<a name="910"><span class="lineNum">     910 </span>            :     Optional&lt;Location&gt; location, Value min, Value operand, Value max,</a>
<a name="911"><span class="lineNum">     911 </span><span class="lineCov">         50 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="912"><span class="lineNum">     912 </span><span class="lineCov">         50 :   auto operandType = operand.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="913"><span class="lineNum">     913 </span><span class="lineCov">         50 :   auto operandShape = operandType.getShape();</span></a>
<a name="914"><span class="lineNum">     914 </span><span class="lineCov">         50 :   auto minType = min.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="915"><span class="lineNum">     915 </span>            : </a>
<a name="916"><span class="lineNum">     916 </span><span class="lineCov">         50 :   auto minShape = minType.getShape();</span></a>
<a name="917"><span class="lineNum">     917 </span><span class="lineCov">         50 :   if (failed(verifyCompatibleShape(minType, operandType)) &amp;&amp;</span></a>
<a name="918"><span class="lineNum">     918 </span><span class="lineCov">         14 :       minType.getRank() != 0) {</span></a>
<a name="919"><span class="lineNum">     919 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="920"><span class="lineNum">     920 </span><span class="lineCov">          2 :         location, &quot;min shape [&quot;,</span></a>
<a name="921"><span class="lineNum">     921 </span><span class="lineCov">          2 :         llvm::make_range(minShape.begin(), minShape.end()),</span></a>
<a name="922"><span class="lineNum">     922 </span>            :         &quot;] is not scalar and is not compatible to operand shape [&quot;,</a>
<a name="923"><span class="lineNum">     923 </span><span class="lineCov">          2 :         llvm::make_range(operandShape.begin(), operandShape.end()), &quot;]&quot;);</span></a>
<a name="924"><span class="lineNum">     924 </span>            :   }</a>
<a name="925"><span class="lineNum">     925 </span>            : </a>
<a name="926"><span class="lineNum">     926 </span><span class="lineCov">         48 :   auto maxType = max.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="927"><span class="lineNum">     927 </span><span class="lineCov">         48 :   auto maxShape = maxType.getShape();</span></a>
<a name="928"><span class="lineNum">     928 </span><span class="lineCov">         48 :   if (failed(verifyCompatibleShape(maxType, operandType)) &amp;&amp;</span></a>
<a name="929"><span class="lineNum">     929 </span><span class="lineCov">          6 :       maxType.getRank() != 0) {</span></a>
<a name="930"><span class="lineNum">     930 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="931"><span class="lineNum">     931 </span><span class="lineCov">          2 :         location, &quot;max shape [&quot;,</span></a>
<a name="932"><span class="lineNum">     932 </span><span class="lineCov">          2 :         llvm::make_range(maxShape.begin(), maxShape.end()),</span></a>
<a name="933"><span class="lineNum">     933 </span>            :         &quot;] is not scalar and is not compatible to operand shape [&quot;,</a>
<a name="934"><span class="lineNum">     934 </span><span class="lineCov">          2 :         llvm::make_range(operandShape.begin(), operandShape.end()), &quot;]&quot;);</span></a>
<a name="935"><span class="lineNum">     935 </span>            :   }</a>
<a name="936"><span class="lineNum">     936 </span>            : </a>
<a name="937"><span class="lineNum">     937 </span><span class="lineCov">         46 :   inferredReturnShapes.emplace_back(operandType.cast&lt;ShapedType&gt;());</span></a>
<a name="938"><span class="lineNum">     938 </span><span class="lineCov">         46 :   return success();</span></a>
<a name="939"><span class="lineNum">     939 </span><span class="lineCov">         50 : }</span></a>
<a name="940"><span class="lineNum">     940 </span>            : </a>
<a name="941"><span class="lineNum">     941 </span><span class="lineCov">         38 : LogicalResult inferComplexOp(Optional&lt;Location&gt; location, Value lhs,</span></a>
<a name="942"><span class="lineNum">     942 </span><span class="lineCov">         38 :                              SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="943"><span class="lineNum">     943 </span><span class="lineCov">         38 :   TensorType operandType = lhs.getType().cast&lt;TensorType&gt;();</span></a>
<a name="944"><span class="lineNum">     944 </span><span class="lineCov">         38 :   ComplexType elementTy = ComplexType::get(operandType.getElementType());</span></a>
<a name="945"><span class="lineNum">     945 </span><span class="lineCov">         76 :   inferredReturnTypes.push_back(</span></a>
<a name="946"><span class="lineNum">     946 </span><span class="lineCov">         38 :       hlo::getSameShapeTensorType(operandType, elementTy));</span></a>
<a name="947"><span class="lineNum">     947 </span><span class="lineCov">         38 :   return success();</span></a>
<a name="948"><span class="lineNum">     948 </span><span class="lineCov">         38 : }</span></a>
<a name="949"><span class="lineNum">     949 </span>            : </a>
<a name="950"><span class="lineNum">     950 </span><span class="lineCov">        141 : LogicalResult inferConcatenateOp(Optional&lt;Location&gt; location, ValueRange inputs,</span></a>
<a name="951"><span class="lineNum">     951 </span>            :                                  int64_t dimension,</a>
<a name="952"><span class="lineNum">     952 </span><span class="lineCov">        141 :                                  SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="953"><span class="lineNum">     953 </span><span class="lineCov">        141 :   if (dimension &lt; 0)</span></a>
<a name="954"><span class="lineNum">     954 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;dimension &quot;, dimension, &quot; is negative&quot;);</span></a>
<a name="955"><span class="lineNum">     955 </span><span class="lineCov">        137 :   RankedTensorType firstRankedType;</span></a>
<a name="956"><span class="lineNum">     956 </span><span class="lineCov">        137 :   int firstRankedIndex = -1;</span></a>
<a name="957"><span class="lineNum">     957 </span><span class="lineCov">        412 :   for (uint64_t i = 0; i &lt; inputs.size(); i++) {</span></a>
<a name="958"><span class="lineNum">     958 </span><span class="lineCov">        275 :     auto secondType = inputs[i].getType().dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="959"><span class="lineNum">     959 </span><span class="lineCov">        275 :     if (!secondType.hasRank()) continue;</span></a>
<a name="960"><span class="lineNum">     960 </span>            : </a>
<a name="961"><span class="lineNum">     961 </span><span class="lineCov">        251 :     if (!firstRankedType) {</span></a>
<a name="962"><span class="lineNum">     962 </span><span class="lineCov">        137 :       firstRankedType = secondType.cast&lt;RankedTensorType&gt;();</span></a>
<a name="963"><span class="lineNum">     963 </span><span class="lineCov">        137 :       firstRankedIndex = i;</span></a>
<a name="964"><span class="lineNum">     964 </span><span class="lineCov">        137 :       if (firstRankedType.getRank() == 0)</span></a>
<a name="965"><span class="lineNum">     965 </span><span class="lineCov">          2 :         return emitOptionalError(location,</span></a>
<a name="966"><span class="lineNum">     966 </span>            :                                  &quot;rank-0 values cannot be concatenated&quot;);</a>
<a name="967"><span class="lineNum">     967 </span><span class="lineCov">        135 :       if (dimension &gt;= firstRankedType.getRank())</span></a>
<a name="968"><span class="lineNum">     968 </span><span class="lineCov">          4 :         return emitOptionalError(location, &quot;dimension &quot;, dimension,</span></a>
<a name="969"><span class="lineNum">     969 </span>            :                                  &quot; is out-of-bounds for input rank &quot;,</a>
<a name="970"><span class="lineNum">     970 </span><span class="lineCov">          2 :                                  firstRankedType.getRank());</span></a>
<a name="971"><span class="lineNum">     971 </span><span class="lineCov">        133 :       continue;</span></a>
<a name="972"><span class="lineNum">     972 </span>            :     }</a>
<a name="973"><span class="lineNum">     973 </span><span class="lineCov">        114 :     if (firstRankedType.getRank() != secondType.getRank())</span></a>
<a name="974"><span class="lineNum">     974 </span><span class="lineCov">          2 :       return emitOptionalError(location, &quot;operands (&quot;, firstRankedIndex,</span></a>
<a name="975"><span class="lineNum">     975 </span>            :                                &quot;) and (&quot;, i, &quot;) do not match rank&quot;);</a>
<a name="976"><span class="lineNum">     976 </span>            : </a>
<a name="977"><span class="lineNum">     977 </span><span class="lineCov">        112 :     auto firstShape = firstRankedType.getShape();</span></a>
<a name="978"><span class="lineNum">     978 </span><span class="lineCov">        112 :     auto secondShape = secondType.getShape();</span></a>
<a name="979"><span class="lineNum">     979 </span><span class="lineCov">        316 :     for (int d = 0; d &lt; firstRankedType.getRank(); ++d) {</span></a>
<a name="980"><span class="lineNum">     980 </span><span class="lineCov">        284 :       if (!isDynamicDimSize(firstShape[d]) &amp;&amp;</span></a>
<a name="981"><span class="lineNum">     981 </span><span class="lineCov">        152 :           !isDynamicDimSize(secondShape[d]) &amp;&amp;</span></a>
<a name="982"><span class="lineNum">     982 </span><span class="lineCov">        136 :           firstShape[d] != secondShape[d] &amp;&amp; d != dimension) {</span></a>
<a name="983"><span class="lineNum">     983 </span><span class="lineCov">          2 :         return emitOptionalError(</span></a>
<a name="984"><span class="lineNum">     984 </span><span class="lineCov">          2 :             location, &quot;shapes of operand (&quot;, firstRankedIndex, &quot;) and (&quot;, i,</span></a>
<a name="985"><span class="lineNum">     985 </span>            :             &quot;) do not match at non-concat &quot;</a>
<a name="986"><span class="lineNum">     986 </span>            :             &quot;index: (&quot;,</a>
<a name="987"><span class="lineNum">     987 </span><span class="lineCov">          2 :             llvm::make_range(firstShape.begin(), firstShape.end()), &quot;) != (&quot;,</span></a>
<a name="988"><span class="lineNum">     988 </span><span class="lineCov">          2 :             llvm::make_range(secondShape.begin(), secondShape.end()),</span></a>
<a name="989"><span class="lineNum">     989 </span>            :             &quot;) at non-concat index &quot;, d);</a>
<a name="990"><span class="lineNum">     990 </span>            :       }</a>
<a name="991"><span class="lineNum">     991 </span><span class="lineCov">        202 :     }</span></a>
<a name="992"><span class="lineNum">     992 </span><span class="lineCov">        275 :   }</span></a>
<a name="993"><span class="lineNum">     993 </span>            : </a>
<a name="994"><span class="lineNum">     994 </span><span class="lineCov">        129 :   auto elementType = inputs[0].getType().cast&lt;ShapedType&gt;().getElementType();</span></a>
<a name="995"><span class="lineNum">     995 </span><span class="lineCov">        129 :   if (!firstRankedType) {</span></a>
<a name="996"><span class="lineNum">     996 </span><span class="lineNoCov">          0 :     inferredReturnTypes.push_back(UnrankedTensorType::get(elementType));</span></a>
<a name="997"><span class="lineNum">     997 </span><span class="lineNoCov">          0 :     return success();</span></a>
<a name="998"><span class="lineNum">     998 </span>            :   }</a>
<a name="999"><span class="lineNum">     999 </span>            : </a>
<a name="1000"><span class="lineNum">    1000 </span>            :   // Infer the most specific (size, bound) of all dimensions of the return type</a>
<a name="1001"><span class="lineNum">    1001 </span><span class="lineCov">        129 :   auto rank = firstRankedType.getRank();</span></a>
<a name="1002"><span class="lineNum">    1002 </span><span class="lineCov">        129 :   SmallVector&lt;int64_t&gt; inferredSizes(rank, ShapedType::kDynamic);</span></a>
<a name="1003"><span class="lineNum">    1003 </span><span class="lineCov">        129 :   SmallVector&lt;int64_t&gt; inferredBounds(rank, ShapedType::kDynamic);</span></a>
<a name="1004"><span class="lineNum">    1004 </span>            :   // Note: for the concatenate dimension, 0 should be the identity element:</a>
<a name="1005"><span class="lineNum">    1005 </span>            :   // Any dim size can keep unchanged when concatenated with 0</a>
<a name="1006"><span class="lineNum">    1006 </span><span class="lineCov">        129 :   inferredSizes[dimension] = 0;</span></a>
<a name="1007"><span class="lineNum">    1007 </span><span class="lineCov">        129 :   bool anyInputHaveBounds = false;</span></a>
<a name="1008"><span class="lineNum">    1008 </span>            : </a>
<a name="1009"><span class="lineNum">    1009 </span>            :   // Note: unranked input types can't be ignored, consider these input types:</a>
<a name="1010"><span class="lineNum">    1010 </span>            :   // c0: (&lt;5x?xf32&gt;, &lt;*xf32&gt;) with concat dim 0 should infer &lt;?x?xf32&gt;</a>
<a name="1011"><span class="lineNum">    1011 </span>            :   // c1: (&lt;5x?xf32&gt;, &lt;*xf32&gt;) with concat dim 1 should infer &lt;5x?xf32&gt;</a>
<a name="1012"><span class="lineNum">    1012 </span>            :   // Instead, they should be replaced with dynamic tensors: tensor&lt;?x...?x&gt;</a>
<a name="1013"><span class="lineNum">    1013 </span><span class="lineCov">        392 :   for (const auto&amp; it : llvm::enumerate(inputs.getTypes())) {</span></a>
<a name="1014"><span class="lineNum">    1014 </span><span class="lineCov">        263 :     RankedTensorType rankedType = it.value().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1015"><span class="lineNum">    1015 </span><span class="lineCov">        263 :     SmallVector&lt;int64_t&gt; bounds;</span></a>
<a name="1016"><span class="lineNum">    1016 </span><span class="lineCov">        263 :     if (rankedType)</span></a>
<a name="1017"><span class="lineNum">    1017 </span><span class="lineCov">        239 :       bounds = to_vector(encodingToBounds(rankedType.getEncoding()));</span></a>
<a name="1018"><span class="lineNum">    1018 </span><span class="lineCov">        263 :     if (!bounds.empty()) anyInputHaveBounds = true;</span></a>
<a name="1019"><span class="lineNum">    1019 </span>            : </a>
<a name="1020"><span class="lineNum">    1020 </span><span class="lineCov">        733 :     for (int dim = 0; dim &lt; rank; ++dim) {</span></a>
<a name="1021"><span class="lineNum">    1021 </span><span class="lineCov">        470 :       std::pair&lt;int64_t, int64_t&gt; inferredDimAndBound;</span></a>
<a name="1022"><span class="lineNum">    1022 </span>            : </a>
<a name="1023"><span class="lineNum">    1023 </span><span class="lineCov">        470 :       int64_t leftSize = inferredSizes[dim];</span></a>
<a name="1024"><span class="lineNum">    1024 </span><span class="lineCov">        940 :       int64_t rightSize =</span></a>
<a name="1025"><span class="lineNum">    1025 </span><span class="lineCov">        470 :           rankedType ? rankedType.getShape()[dim] : ShapedType::kDynamic;</span></a>
<a name="1026"><span class="lineNum">    1026 </span><span class="lineCov">        470 :       int64_t leftBound = inferredBounds[dim];</span></a>
<a name="1027"><span class="lineNum">    1027 </span><span class="lineCov">        470 :       int64_t rightBound = bounds.empty() ? ShapedType::kDynamic : bounds[dim];</span></a>
<a name="1028"><span class="lineNum">    1028 </span><span class="lineCov">        470 :       if (dim == dimension) {</span></a>
<a name="1029"><span class="lineNum">    1029 </span><span class="lineCov">        526 :         inferredDimAndBound = inferConcatenatedDimAndBound(</span></a>
<a name="1030"><span class="lineNum">    1030 </span><span class="lineCov">        263 :             leftSize, rightSize, leftBound, rightBound);</span></a>
<a name="1031"><span class="lineNum">    1031 </span><span class="lineCov">        263 :       } else {</span></a>
<a name="1032"><span class="lineNum">    1032 </span><span class="lineCov">        414 :         auto inferredDimAndBoundOrErr = inferMergedDimAndBound(</span></a>
<a name="1033"><span class="lineNum">    1033 </span><span class="lineCov">        207 :             location, dim, leftSize, rightSize, leftBound, rightBound);</span></a>
<a name="1034"><span class="lineNum">    1034 </span><span class="lineCov">        207 :         if (failed(inferredDimAndBoundOrErr)) return failure();</span></a>
<a name="1035"><span class="lineNum">    1035 </span><span class="lineCov">        207 :         inferredDimAndBound = *inferredDimAndBoundOrErr;</span></a>
<a name="1036"><span class="lineNum">    1036 </span><span class="lineCov">        207 :       }</span></a>
<a name="1037"><span class="lineNum">    1037 </span><span class="lineCov">        470 :       inferredSizes[dim] = inferredDimAndBound.first;</span></a>
<a name="1038"><span class="lineNum">    1038 </span><span class="lineCov">        470 :       inferredBounds[dim] = inferredDimAndBound.second;</span></a>
<a name="1039"><span class="lineNum">    1039 </span><span class="lineCov">        470 :     }</span></a>
<a name="1040"><span class="lineNum">    1040 </span><span class="lineCov">        263 :   }</span></a>
<a name="1041"><span class="lineNum">    1041 </span>            : </a>
<a name="1042"><span class="lineNum">    1042 </span><span class="lineCov">        258 :   inferredReturnTypes.push_back(RankedTensorType::get(</span></a>
<a name="1043"><span class="lineNum">    1043 </span><span class="lineCov">        129 :       inferredSizes, elementType,</span></a>
<a name="1044"><span class="lineNum">    1044 </span><span class="lineCov">        129 :       boundsToEncoding(</span></a>
<a name="1045"><span class="lineNum">    1045 </span><span class="lineCov">        129 :           firstRankedType.getEncoding(),</span></a>
<a name="1046"><span class="lineNum">    1046 </span>            :           // Empty array as argument is an indicator to boundsToEncoding() that</a>
<a name="1047"><span class="lineNum">    1047 </span>            :           // there are no bounds at all in inputs, thus sparsity attributes will</a>
<a name="1048"><span class="lineNum">    1048 </span>            :           // be included in the return type</a>
<a name="1049"><span class="lineNum">    1049 </span><span class="lineCov">        129 :           anyInputHaveBounds ? inferredBounds : llvm::ArrayRef&lt;int64_t&gt;({}))));</span></a>
<a name="1050"><span class="lineNum">    1050 </span><span class="lineCov">        129 :   return success();</span></a>
<a name="1051"><span class="lineNum">    1051 </span><span class="lineCov">        141 : }</span></a>
<a name="1052"><span class="lineNum">    1052 </span>            : </a>
<a name="1053"><span class="lineNum">    1053 </span><span class="lineCov">       1545 : LogicalResult inferConstantOp(Optional&lt;Location&gt;, ElementsAttr value,</span></a>
<a name="1054"><span class="lineNum">    1054 </span><span class="lineCov">       1545 :                               SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1055"><span class="lineNum">    1055 </span><span class="lineCov">       1545 :   inferredReturnTypes.push_back(value.getType());</span></a>
<a name="1056"><span class="lineNum">    1056 </span><span class="lineCov">       1545 :   return success();</span></a>
<a name="1057"><span class="lineNum">    1057 </span>            : }</a>
<a name="1058"><span class="lineNum">    1058 </span>            : </a>
<a name="1059"><span class="lineNum">    1059 </span><span class="lineCov">         32 : LogicalResult inferCreateTokenOp(Dialect* dialect, Optional&lt;Location&gt; location,</span></a>
<a name="1060"><span class="lineNum">    1060 </span><span class="lineCov">         32 :                                  SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1061"><span class="lineNum">    1061 </span><span class="lineCov">         32 :   auto hloDialect = cast&lt;HloDialectInterface&gt;(dialect);</span></a>
<a name="1062"><span class="lineNum">    1062 </span><span class="lineCov">         32 :   inferredReturnTypes.push_back(hloDialect-&gt;createTokenType());</span></a>
<a name="1063"><span class="lineNum">    1063 </span><span class="lineCov">         32 :   return success();</span></a>
<a name="1064"><span class="lineNum">    1064 </span><span class="lineCov">         32 : }</span></a>
<a name="1065"><span class="lineNum">    1065 </span>            : </a>
<a name="1066"><span class="lineNum">    1066 </span><span class="lineCov">        103 : LogicalResult inferDotGeneralOp(</span></a>
<a name="1067"><span class="lineNum">    1067 </span>            :     Optional&lt;Location&gt; location, Value lhs, Value rhs,</a>
<a name="1068"><span class="lineNum">    1068 </span>            :     ArrayRef&lt;int64_t&gt; lhsBatchingDimensions,</a>
<a name="1069"><span class="lineNum">    1069 </span>            :     ArrayRef&lt;int64_t&gt; rhsBatchingDimensions,</a>
<a name="1070"><span class="lineNum">    1070 </span>            :     ArrayRef&lt;int64_t&gt; lhsContractingDimensions,</a>
<a name="1071"><span class="lineNum">    1071 </span>            :     ArrayRef&lt;int64_t&gt; rhsContractingDimensions,</a>
<a name="1072"><span class="lineNum">    1072 </span><span class="lineCov">        103 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1073"><span class="lineNum">    1073 </span><span class="lineCov">        103 :   if (lhsBatchingDimensions.size() != rhsBatchingDimensions.size())</span></a>
<a name="1074"><span class="lineNum">    1074 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="1075"><span class="lineNum">    1075 </span>            :                              &quot;lhs and rhs should have the same &quot;</a>
<a name="1076"><span class="lineNum">    1076 </span>            :                              &quot;number of batching dimensions&quot;);</a>
<a name="1077"><span class="lineNum">    1077 </span><span class="lineCov">         99 :   if (lhsContractingDimensions.size() != rhsContractingDimensions.size())</span></a>
<a name="1078"><span class="lineNum">    1078 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="1079"><span class="lineNum">    1079 </span>            :                              &quot;lhs and rhs should have the same &quot;</a>
<a name="1080"><span class="lineNum">    1080 </span>            :                              &quot;number of contracting dimensions&quot;);</a>
<a name="1081"><span class="lineNum">    1081 </span>            : </a>
<a name="1082"><span class="lineNum">    1082 </span><span class="lineCov">         95 :   llvm::SmallDenseSet&lt;int64_t&gt; dimSet;</span></a>
<a name="1083"><span class="lineNum">    1083 </span><span class="lineCov">         95 :   auto checkDimsDistinct =</span></a>
<a name="1084"><span class="lineNum">    1084 </span><span class="lineCov">        273 :       [&amp;](ArrayRef&lt;int64_t&gt; batchingDims, ArrayRef&lt;int64_t&gt; contractingDims,</span></a>
<a name="1085"><span class="lineNum">    1085 </span>            :           llvm::SmallDenseSet&lt;int64_t&gt;&amp; dimSet, llvm::StringRef lhs,</a>
<a name="1086"><span class="lineNum">    1086 </span><span class="lineCov">        178 :           llvm::StringRef rhs) -&gt; LogicalResult {</span></a>
<a name="1087"><span class="lineNum">    1087 </span><span class="lineCov">        178 :     auto dims = llvm::concat&lt;const int64_t&gt;(batchingDims, contractingDims);</span></a>
<a name="1088"><span class="lineNum">    1088 </span><span class="lineCov">        530 :     for (auto dim : dims) {</span></a>
<a name="1089"><span class="lineNum">    1089 </span><span class="lineCov">        352 :       auto [_, wasInserted] = dimSet.insert(dim);</span></a>
<a name="1090"><span class="lineNum">    1090 </span><span class="lineCov">        352 :       if (!wasInserted)</span></a>
<a name="1091"><span class="lineNum">    1091 </span><span class="lineCov">         16 :         return emitOptionalError(location, &quot;has duplicated dimension from &quot;,</span></a>
<a name="1092"><span class="lineNum">    1092 </span>            :                                  lhs, &quot; and &quot;, rhs, &quot;: &quot;, dim);</a>
<a name="1093"><span class="lineNum">    1093 </span><span class="lineCov">        352 :     }</span></a>
<a name="1094"><span class="lineNum">    1094 </span><span class="lineCov">        162 :     return success();</span></a>
<a name="1095"><span class="lineNum">    1095 </span><span class="lineCov">        178 :   };</span></a>
<a name="1096"><span class="lineNum">    1096 </span>            : </a>
<a name="1097"><span class="lineNum">    1097 </span><span class="lineCov">        190 :   if (failed(checkDimsDistinct(lhsBatchingDimensions, lhsContractingDimensions,</span></a>
<a name="1098"><span class="lineNum">    1098 </span><span class="lineCov">         95 :                                dimSet, &quot;lhs_batching_dimensions&quot;,</span></a>
<a name="1099"><span class="lineNum">    1099 </span><span class="lineCov">         95 :                                &quot;lhs_contracting_dimensions&quot;)))</span></a>
<a name="1100"><span class="lineNum">    1100 </span><span class="lineCov">         12 :     return failure();</span></a>
<a name="1101"><span class="lineNum">    1101 </span>            : </a>
<a name="1102"><span class="lineNum">    1102 </span><span class="lineCov">         83 :   dimSet.clear();</span></a>
<a name="1103"><span class="lineNum">    1103 </span>            : </a>
<a name="1104"><span class="lineNum">    1104 </span><span class="lineCov">        166 :   if (failed(checkDimsDistinct(rhsBatchingDimensions, rhsContractingDimensions,</span></a>
<a name="1105"><span class="lineNum">    1105 </span><span class="lineCov">         83 :                                dimSet, &quot;rhs_batching_dimensions&quot;,</span></a>
<a name="1106"><span class="lineNum">    1106 </span><span class="lineCov">         83 :                                &quot;rhs_contracting_dimensions&quot;)))</span></a>
<a name="1107"><span class="lineNum">    1107 </span><span class="lineCov">          4 :     return failure();</span></a>
<a name="1108"><span class="lineNum">    1108 </span>            : </a>
<a name="1109"><span class="lineNum">    1109 </span><span class="lineCov">        338 :   auto checkDimsInRange = [&amp;](int64_t rank, ArrayRef&lt;int64_t&gt; dims,</span></a>
<a name="1110"><span class="lineNum">    1110 </span><span class="lineCov">        259 :                               llvm::StringRef dimName) -&gt; LogicalResult {</span></a>
<a name="1111"><span class="lineNum">    1111 </span><span class="lineCov">        511 :     auto inRange = [&amp;](int64_t i) -&gt; bool { return 0 &lt;= i &amp;&amp; i &lt; rank; };</span></a>
<a name="1112"><span class="lineNum">    1112 </span><span class="lineCov">        518 :     const auto* dimsNotInRange =</span></a>
<a name="1113"><span class="lineNum">    1113 </span><span class="lineCov">        259 :         std::find_if_not(dims.begin(), dims.end(), inRange);</span></a>
<a name="1114"><span class="lineNum">    1114 </span><span class="lineCov">        259 :     if (dimsNotInRange != dims.end())</span></a>
<a name="1115"><span class="lineNum">    1115 </span><span class="lineCov">         16 :       return emitOptionalError(location, dimName, &quot; value: &quot;, *dimsNotInRange,</span></a>
<a name="1116"><span class="lineNum">    1116 </span>            :                                &quot; is out of range: &quot;, &quot;[0, &quot;, rank, &quot;)&quot;);</a>
<a name="1117"><span class="lineNum">    1117 </span><span class="lineCov">        243 :     return success();</span></a>
<a name="1118"><span class="lineNum">    1118 </span><span class="lineCov">        259 :   };</span></a>
<a name="1119"><span class="lineNum">    1119 </span><span class="lineCov">         79 :   auto lhsRankedType = lhs.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1120"><span class="lineNum">    1120 </span><span class="lineCov">         79 :   auto rhsRankedType = rhs.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1121"><span class="lineNum">    1121 </span>            : </a>
<a name="1122"><span class="lineNum">    1122 </span><span class="lineCov">         79 :   if (lhsRankedType) {</span></a>
<a name="1123"><span class="lineNum">    1123 </span><span class="lineCov">        150 :     if (failed(checkDimsInRange(lhsRankedType.getRank(), lhsBatchingDimensions,</span></a>
<a name="1124"><span class="lineNum">    1124 </span><span class="lineCov">        150 :                                 &quot;lhs_batching_dimensions&quot;)) ||</span></a>
<a name="1125"><span class="lineNum">    1125 </span><span class="lineCov">        142 :         failed(checkDimsInRange(lhsRankedType.getRank(),</span></a>
<a name="1126"><span class="lineNum">    1126 </span><span class="lineCov">         71 :                                 lhsContractingDimensions,</span></a>
<a name="1127"><span class="lineNum">    1127 </span><span class="lineCov">         71 :                                 &quot;lhs_contracting_dimensions&quot;)))</span></a>
<a name="1128"><span class="lineNum">    1128 </span><span class="lineCov">          8 :       return failure();</span></a>
<a name="1129"><span class="lineNum">    1129 </span><span class="lineCov">         67 :   }</span></a>
<a name="1130"><span class="lineNum">    1130 </span><span class="lineCov">         71 :   if (rhsRankedType) {</span></a>
<a name="1131"><span class="lineNum">    1131 </span><span class="lineCov">        118 :     if (failed(checkDimsInRange(rhsRankedType.getRank(), rhsBatchingDimensions,</span></a>
<a name="1132"><span class="lineNum">    1132 </span><span class="lineCov">        118 :                                 &quot;rhs_batching_dimensions&quot;)) ||</span></a>
<a name="1133"><span class="lineNum">    1133 </span><span class="lineCov">        110 :         failed(checkDimsInRange(rhsRankedType.getRank(),</span></a>
<a name="1134"><span class="lineNum">    1134 </span><span class="lineCov">         55 :                                 rhsContractingDimensions,</span></a>
<a name="1135"><span class="lineNum">    1135 </span><span class="lineCov">         55 :                                 &quot;rhs_contracting_dimensions&quot;)))</span></a>
<a name="1136"><span class="lineNum">    1136 </span><span class="lineCov">          8 :       return failure();</span></a>
<a name="1137"><span class="lineNum">    1137 </span><span class="lineCov">         51 :   }</span></a>
<a name="1138"><span class="lineNum">    1138 </span><span class="lineCov">         63 :   if (lhsRankedType &amp;&amp; rhsRankedType) {</span></a>
<a name="1139"><span class="lineNum">    1139 </span>            :     // Dimension sizes must be compatible for lhs/rhs.</a>
<a name="1140"><span class="lineNum">    1140 </span><span class="lineCov">         50 :     auto lhsShape = lhsRankedType.getShape();</span></a>
<a name="1141"><span class="lineNum">    1141 </span><span class="lineCov">         50 :     auto rhsShape = rhsRankedType.getShape();</span></a>
<a name="1142"><span class="lineNum">    1142 </span>            : </a>
<a name="1143"><span class="lineNum">    1143 </span><span class="lineCov">         93 :     for (auto [lhs, rhs] :</span></a>
<a name="1144"><span class="lineNum">    1144 </span><span class="lineCov">         50 :          llvm::zip(lhsBatchingDimensions, rhsBatchingDimensions)) {</span></a>
<a name="1145"><span class="lineNum">    1145 </span><span class="lineCov">         43 :       if (hlo::isDynamicDimSize(lhsShape[lhs])) continue;</span></a>
<a name="1146"><span class="lineNum">    1146 </span><span class="lineCov">         36 :       if (hlo::isDynamicDimSize(rhsShape[rhs])) continue;</span></a>
<a name="1147"><span class="lineNum">    1147 </span><span class="lineCov">         64 :       if (lhsShape[lhs] != rhsShape[rhs])</span></a>
<a name="1148"><span class="lineNum">    1148 </span><span class="lineCov">          2 :         return emitOptionalError(location,</span></a>
<a name="1149"><span class="lineNum">    1149 </span>            :                                  &quot;batching dimension sizes must &quot;</a>
<a name="1150"><span class="lineNum">    1150 </span>            :                                  &quot;match for lhs/rhs&quot;);</a>
<a name="1151"><span class="lineNum">    1151 </span><span class="lineCov">         43 :     }</span></a>
<a name="1152"><span class="lineNum">    1152 </span>            : </a>
<a name="1153"><span class="lineNum">    1153 </span><span class="lineCov">        101 :     for (auto [lhs, rhs] :</span></a>
<a name="1154"><span class="lineNum">    1154 </span><span class="lineCov">         49 :          llvm::zip(lhsContractingDimensions, rhsContractingDimensions)) {</span></a>
<a name="1155"><span class="lineNum">    1155 </span><span class="lineCov">         52 :       if (hlo::isDynamicDimSize(lhsShape[lhs])) continue;</span></a>
<a name="1156"><span class="lineNum">    1156 </span><span class="lineCov">         47 :       if (hlo::isDynamicDimSize(rhsShape[rhs])) continue;</span></a>
<a name="1157"><span class="lineNum">    1157 </span><span class="lineCov">         86 :       if (lhsShape[lhs] != rhsShape[rhs])</span></a>
<a name="1158"><span class="lineNum">    1158 </span><span class="lineCov">          2 :         return emitOptionalError(location,</span></a>
<a name="1159"><span class="lineNum">    1159 </span>            :                                  &quot;contracting dimension sizes must &quot;</a>
<a name="1160"><span class="lineNum">    1160 </span>            :                                  &quot;match for lhs/rhs&quot;);</a>
<a name="1161"><span class="lineNum">    1161 </span><span class="lineCov">         52 :     }</span></a>
<a name="1162"><span class="lineNum">    1162 </span><span class="lineCov">         50 :   }</span></a>
<a name="1163"><span class="lineNum">    1163 </span>            : </a>
<a name="1164"><span class="lineNum">    1164 </span><span class="lineCov">         59 :   auto lhsType = lhs.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1165"><span class="lineNum">    1165 </span><span class="lineCov">         59 :   auto rhsType = rhs.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1166"><span class="lineNum">    1166 </span><span class="lineCov">         59 :   auto elementType = lhsType.getElementType();</span></a>
<a name="1167"><span class="lineNum">    1167 </span>            : </a>
<a name="1168"><span class="lineNum">    1168 </span><span class="lineCov">         59 :   if (!lhsType.hasRank() || !rhsType.hasRank()) {</span></a>
<a name="1169"><span class="lineNum">    1169 </span><span class="lineCov">         12 :     inferredReturnShapes.emplace_back(elementType);</span></a>
<a name="1170"><span class="lineNum">    1170 </span><span class="lineCov">         12 :     return success();</span></a>
<a name="1171"><span class="lineNum">    1171 </span>            :   }</a>
<a name="1172"><span class="lineNum">    1172 </span>            : </a>
<a name="1173"><span class="lineNum">    1173 </span><span class="lineCov">         47 :   auto lhsShape = lhsType.getShape();</span></a>
<a name="1174"><span class="lineNum">    1174 </span><span class="lineCov">         47 :   auto rhsShape = rhsType.getShape();</span></a>
<a name="1175"><span class="lineNum">    1175 </span>            : </a>
<a name="1176"><span class="lineNum">    1176 </span>            :   // Infer the output dimensions of the operation.</a>
<a name="1177"><span class="lineNum">    1177 </span><span class="lineCov">         47 :   SmallVector&lt;int64_t&gt; dimensions;</span></a>
<a name="1178"><span class="lineNum">    1178 </span><span class="lineCov">         86 :   for (const int64_t lhsBatchingDim : lhsBatchingDimensions)</span></a>
<a name="1179"><span class="lineNum">    1179 </span><span class="lineCov">         39 :     dimensions.push_back(lhsShape[lhsBatchingDim]);</span></a>
<a name="1180"><span class="lineNum">    1180 </span><span class="lineCov">        168 :   for (int64_t i = 0; i &lt; lhsType.getRank(); i++)</span></a>
<a name="1181"><span class="lineNum">    1181 </span><span class="lineCov">        121 :     if (!llvm::is_contained(lhsBatchingDimensions, i) &amp;&amp;</span></a>
<a name="1182"><span class="lineNum">    1182 </span><span class="lineCov">        152 :         !llvm::is_contained(lhsContractingDimensions, i))</span></a>
<a name="1183"><span class="lineNum">    1183 </span><span class="lineCov">         31 :       dimensions.push_back(lhsShape[i]);</span></a>
<a name="1184"><span class="lineNum">    1184 </span><span class="lineCov">        172 :   for (int64_t i = 0; i &lt; rhsType.getRank(); i++)</span></a>
<a name="1185"><span class="lineNum">    1185 </span><span class="lineCov">        125 :     if (!llvm::is_contained(rhsBatchingDimensions, i) &amp;&amp;</span></a>
<a name="1186"><span class="lineNum">    1186 </span><span class="lineCov">        160 :         !llvm::is_contained(rhsContractingDimensions, i))</span></a>
<a name="1187"><span class="lineNum">    1187 </span><span class="lineCov">         35 :       dimensions.push_back(rhsShape[i]);</span></a>
<a name="1188"><span class="lineNum">    1188 </span>            : </a>
<a name="1189"><span class="lineNum">    1189 </span><span class="lineCov">         47 :   inferredReturnShapes.emplace_back(dimensions, elementType);</span></a>
<a name="1190"><span class="lineNum">    1190 </span><span class="lineCov">         47 :   return success();</span></a>
<a name="1191"><span class="lineNum">    1191 </span><span class="lineCov">        103 : }</span></a>
<a name="1192"><span class="lineNum">    1192 </span>            : </a>
<a name="1193"><span class="lineNum">    1193 </span><span class="lineCov">         46 : LogicalResult inferDynamicSliceOp(</span></a>
<a name="1194"><span class="lineNum">    1194 </span>            :     Optional&lt;Location&gt; location, Value operand, ValueRange startIndices,</a>
<a name="1195"><span class="lineNum">    1195 </span>            :     DenseIntElementsAttr sliceSizes,</a>
<a name="1196"><span class="lineNum">    1196 </span><span class="lineCov">         46 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1197"><span class="lineNum">    1197 </span><span class="lineCov">         46 :   int numSliceSizes = sliceSizes.getNumElements();</span></a>
<a name="1198"><span class="lineNum">    1198 </span><span class="lineCov">         46 :   int numStartIndices = startIndices.size();</span></a>
<a name="1199"><span class="lineNum">    1199 </span><span class="lineCov">         46 :   if (numStartIndices != numSliceSizes)</span></a>
<a name="1200"><span class="lineNum">    1200 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;has mismatched number of slice sizes (&quot;,</span></a>
<a name="1201"><span class="lineNum">    1201 </span>            :                              numSliceSizes, &quot;) and number of start indices (&quot;,</a>
<a name="1202"><span class="lineNum">    1202 </span>            :                              numStartIndices, &quot;)&quot;);</a>
<a name="1203"><span class="lineNum">    1203 </span><span class="lineCov">         44 :   auto operandType = operand.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1204"><span class="lineNum">    1204 </span><span class="lineCov">         44 :   if (!operandType) return failure();</span></a>
<a name="1205"><span class="lineNum">    1205 </span>            : </a>
<a name="1206"><span class="lineNum">    1206 </span><span class="lineCov">         44 :   if (operandType.getRank() != numStartIndices)</span></a>
<a name="1207"><span class="lineNum">    1207 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1208"><span class="lineNum">    1208 </span><span class="lineCov">          2 :         location, &quot;has mismatched number of start indices (&quot;, numStartIndices,</span></a>
<a name="1209"><span class="lineNum">    1209 </span><span class="lineCov">          2 :         &quot;) and the rank of operand (&quot;, operandType.getRank(), &quot;)&quot;);</span></a>
<a name="1210"><span class="lineNum">    1210 </span>            : </a>
<a name="1211"><span class="lineNum">    1211 </span><span class="lineCov">        116 :   for (int i = 0; i &lt; numSliceSizes; ++i) {</span></a>
<a name="1212"><span class="lineNum">    1212 </span><span class="lineCov">         74 :     int64_t sliceSize = sliceSizes.getValues&lt;int64_t&gt;()[i];</span></a>
<a name="1213"><span class="lineNum">    1213 </span><span class="lineCov">         74 :     if (sliceSize &lt; 0)</span></a>
<a name="1214"><span class="lineNum">    1214 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="1215"><span class="lineNum">    1215 </span><span class="lineCov">          2 :           location, &quot;has negative size index to dynamic slice: &quot;, sliceSize);</span></a>
<a name="1216"><span class="lineNum">    1216 </span><span class="lineCov">         72 :     if (!operandType.isDynamicDim(i)) {</span></a>
<a name="1217"><span class="lineNum">    1217 </span><span class="lineCov">         68 :       int64_t dimSize = operandType.getDimSize(i);</span></a>
<a name="1218"><span class="lineNum">    1218 </span><span class="lineCov">         68 :       if (sliceSize &gt; dimSize)</span></a>
<a name="1219"><span class="lineNum">    1219 </span><span class="lineCov">          2 :         return emitOptionalError(location, &quot;has slice size &quot;, sliceSize,</span></a>
<a name="1220"><span class="lineNum">    1220 </span>            :                                  &quot; greater than dimension size &quot;, dimSize,</a>
<a name="1221"><span class="lineNum">    1221 </span>            :                                  &quot; in dimension &quot;, i, &quot; of operand&quot;);</a>
<a name="1222"><span class="lineNum">    1222 </span><span class="lineCov">         68 :     }</span></a>
<a name="1223"><span class="lineNum">    1223 </span><span class="lineCov">         74 :   }</span></a>
<a name="1224"><span class="lineNum">    1224 </span>            : </a>
<a name="1225"><span class="lineNum">    1225 </span><span class="lineCov">         76 :   inferredReturnShapes.emplace_back(sliceSizes.getValues&lt;int64_t&gt;(),</span></a>
<a name="1226"><span class="lineNum">    1226 </span><span class="lineCov">         38 :                                     operandType.getElementType());</span></a>
<a name="1227"><span class="lineNum">    1227 </span><span class="lineCov">         38 :   return success();</span></a>
<a name="1228"><span class="lineNum">    1228 </span><span class="lineCov">         46 : }</span></a>
<a name="1229"><span class="lineNum">    1229 </span>            : </a>
<a name="1230"><span class="lineNum">    1230 </span><span class="lineCov">         40 : LogicalResult inferDynamicUpdateSliceOp(</span></a>
<a name="1231"><span class="lineNum">    1231 </span>            :     Optional&lt;Location&gt; location, Value operand, Value update,</a>
<a name="1232"><span class="lineNum">    1232 </span>            :     ValueRange startIndices,</a>
<a name="1233"><span class="lineNum">    1233 </span><span class="lineCov">         40 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1234"><span class="lineNum">    1234 </span><span class="lineCov">         40 :   auto operandType = operand.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1235"><span class="lineNum">    1235 </span><span class="lineCov">         40 :   auto updateType = update.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1236"><span class="lineNum">    1236 </span>            : </a>
<a name="1237"><span class="lineNum">    1237 </span>            :   // (C3)</a>
<a name="1238"><span class="lineNum">    1238 </span><span class="lineCov">         40 :   if (updateType.hasRank() &amp;&amp; operandType.hasRank() &amp;&amp;</span></a>
<a name="1239"><span class="lineNum">    1239 </span><span class="lineCov">         32 :       updateType.getRank() != operandType.getRank())</span></a>
<a name="1240"><span class="lineNum">    1240 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1241"><span class="lineNum">    1241 </span><span class="lineCov">          2 :         location,</span></a>
<a name="1242"><span class="lineNum">    1242 </span><span class="lineCov">          2 :         &quot;update rank does not match operand rank: &quot;, updateType.getRank(),</span></a>
<a name="1243"><span class="lineNum">    1243 </span><span class="lineCov">          2 :         &quot; vs &quot;, operandType.getRank(), &quot;.&quot;);</span></a>
<a name="1244"><span class="lineNum">    1244 </span>            : </a>
<a name="1245"><span class="lineNum">    1245 </span>            :   // (C4)</a>
<a name="1246"><span class="lineNum">    1246 </span><span class="lineCov">         38 :   if (operandType.hasRank() &amp;&amp;</span></a>
<a name="1247"><span class="lineNum">    1247 </span><span class="lineCov">         34 :       (int64_t)startIndices.size() != operandType.getRank())</span></a>
<a name="1248"><span class="lineNum">    1248 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1249"><span class="lineNum">    1249 </span><span class="lineCov">          2 :         location, &quot;expects number of start_indices to match operand rank: &quot;,</span></a>
<a name="1250"><span class="lineNum">    1250 </span><span class="lineCov">          2 :         startIndices.size(), &quot; vs &quot;, operandType.getRank(), &quot;.&quot;);</span></a>
<a name="1251"><span class="lineNum">    1251 </span>            : </a>
<a name="1252"><span class="lineNum">    1252 </span>            :   // (C5)</a>
<a name="1253"><span class="lineNum">    1253 </span><span class="lineCov">         36 :   if (!startIndices.empty()) {</span></a>
<a name="1254"><span class="lineNum">    1254 </span><span class="lineCov">         36 :     auto firstIndexType = startIndices[0].getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1255"><span class="lineNum">    1255 </span><span class="lineCov">         36 :     Type firstIndexElement = firstIndexType.getElementType();</span></a>
<a name="1256"><span class="lineNum">    1256 </span><span class="lineCov">         64 :     for (auto otherIndex : llvm::drop_begin(startIndices, 1)) {</span></a>
<a name="1257"><span class="lineNum">    1257 </span><span class="lineCov">         28 :       auto otherIndexType = otherIndex.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1258"><span class="lineNum">    1258 </span><span class="lineCov">         28 :       Type otherIndexElement = otherIndexType.getElementType();</span></a>
<a name="1259"><span class="lineNum">    1259 </span><span class="lineCov">         28 :       if (firstIndexElement != otherIndexElement)</span></a>
<a name="1260"><span class="lineNum">    1260 </span><span class="lineCov">          2 :         return emitOptionalError(</span></a>
<a name="1261"><span class="lineNum">    1261 </span><span class="lineCov">          2 :             location,</span></a>
<a name="1262"><span class="lineNum">    1262 </span>            :             &quot;start indices must have same element type (encountered mismatch: &quot;,</a>
<a name="1263"><span class="lineNum">    1263 </span>            :             firstIndexElement, &quot; vs &quot;, otherIndexElement, &quot;)&quot;);</a>
<a name="1264"><span class="lineNum">    1264 </span><span class="lineCov">         28 :     }</span></a>
<a name="1265"><span class="lineNum">    1265 </span><span class="lineCov">         36 :   }</span></a>
<a name="1266"><span class="lineNum">    1266 </span>            : </a>
<a name="1267"><span class="lineNum">    1267 </span>            :   // (C6)</a>
<a name="1268"><span class="lineNum">    1268 </span><span class="lineCov">         34 :   if (operandType.hasRank() &amp;&amp; updateType.hasRank())</span></a>
<a name="1269"><span class="lineNum">    1269 </span><span class="lineCov">         98 :     for (auto [index, dims] : llvm::enumerate(</span></a>
<a name="1270"><span class="lineNum">    1270 </span><span class="lineCov">         26 :              llvm::zip(operandType.getShape(), updateType.getShape()))) {</span></a>
<a name="1271"><span class="lineNum">    1271 </span><span class="lineCov">         88 :       auto [operandDim, updateDim] = dims;</span></a>
<a name="1272"><span class="lineNum">    1272 </span><span class="lineCov">         44 :       if (hlo::isDynamicDimSize(updateDim)) continue;</span></a>
<a name="1273"><span class="lineNum">    1273 </span><span class="lineCov">         40 :       if (hlo::isStaticDimSize(operandDim)) {</span></a>
<a name="1274"><span class="lineNum">    1274 </span><span class="lineCov">         36 :         if (updateDim &lt; 0 || updateDim &gt; operandDim)</span></a>
<a name="1275"><span class="lineNum">    1275 </span><span class="lineCov">          4 :           return emitOptionalError(location, &quot;expects size at dimension &quot;,</span></a>
<a name="1276"><span class="lineNum">    1276 </span>            :                                    index, &quot; of update to be in range [0, &quot;,</a>
<a name="1277"><span class="lineNum">    1277 </span>            :                                    operandDim, &quot;]. Got: &quot;, updateDim, &quot;.&quot;);</a>
<a name="1278"><span class="lineNum">    1278 </span><span class="lineCov">         34 :       } else {</span></a>
<a name="1279"><span class="lineNum">    1279 </span><span class="lineCov">          4 :         if (updateDim &lt; 0)</span></a>
<a name="1280"><span class="lineNum">    1280 </span><span class="lineNoCov">          0 :           return emitOptionalError(</span></a>
<a name="1281"><span class="lineNum">    1281 </span><span class="lineNoCov">          0 :               location, &quot;expects size at dimension &quot;, index,</span></a>
<a name="1282"><span class="lineNum">    1282 </span>            :               &quot; of update to be non-negative. Got: &quot;, updateDim, &quot;.&quot;);</a>
<a name="1283"><span class="lineNum">    1283 </span>            :       }</a>
<a name="1284"><span class="lineNum">    1284 </span><span class="lineCov">         68 :     }</span></a>
<a name="1285"><span class="lineNum">    1285 </span>            : </a>
<a name="1286"><span class="lineNum">    1286 </span>            :   // (C1)</a>
<a name="1287"><span class="lineNum">    1287 </span><span class="lineCov">         32 :   if (operandType.hasRank()) {</span></a>
<a name="1288"><span class="lineNum">    1288 </span><span class="lineCov">         56 :     inferredReturnShapes.emplace_back(operandType.getShape(),</span></a>
<a name="1289"><span class="lineNum">    1289 </span><span class="lineCov">         28 :                                       operandType.getElementType());</span></a>
<a name="1290"><span class="lineNum">    1290 </span><span class="lineCov">         28 :   } else {</span></a>
<a name="1291"><span class="lineNum">    1291 </span><span class="lineCov">          4 :     inferredReturnShapes.emplace_back(operandType.getElementType());</span></a>
<a name="1292"><span class="lineNum">    1292 </span>            :   }</a>
<a name="1293"><span class="lineNum">    1293 </span><span class="lineCov">         32 :   return success();</span></a>
<a name="1294"><span class="lineNum">    1294 </span><span class="lineCov">         40 : }</span></a>
<a name="1295"><span class="lineNum">    1295 </span>            : </a>
<a name="1296"><span class="lineNum">    1296 </span><span class="lineCov">         36 : LogicalResult inferGetTupleElementOp(</span></a>
<a name="1297"><span class="lineNum">    1297 </span>            :     Optional&lt;Location&gt; location, Value operand, int32_t index,</a>
<a name="1298"><span class="lineNum">    1298 </span><span class="lineCov">         36 :     SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1299"><span class="lineNum">    1299 </span><span class="lineCov">         36 :   auto operandType = operand.getType().dyn_cast&lt;TupleType&gt;();</span></a>
<a name="1300"><span class="lineNum">    1300 </span><span class="lineCov">         36 :   if (!operandType) return failure();</span></a>
<a name="1301"><span class="lineNum">    1301 </span><span class="lineCov">         36 :   if (index &lt; 0 || index &gt;= static_cast&lt;int64_t&gt;(operandType.size()))</span></a>
<a name="1302"><span class="lineNum">    1302 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;index &quot;, index,</span></a>
<a name="1303"><span class="lineNum">    1303 </span>            :                              &quot; is out of bounds of operand with size &quot;,</a>
<a name="1304"><span class="lineNum">    1304 </span><span class="lineCov">          2 :                              operandType.size());</span></a>
<a name="1305"><span class="lineNum">    1305 </span>            : </a>
<a name="1306"><span class="lineNum">    1306 </span><span class="lineCov">         34 :   inferredReturnTypes.push_back(operandType.getType(index));</span></a>
<a name="1307"><span class="lineNum">    1307 </span><span class="lineCov">         34 :   return success();</span></a>
<a name="1308"><span class="lineNum">    1308 </span><span class="lineCov">         36 : }</span></a>
<a name="1309"><span class="lineNum">    1309 </span>            : </a>
<a name="1310"><span class="lineNum">    1310 </span><span class="lineCov">         20 : LogicalResult inferIsFiniteOp(MLIRContext* context, Optional&lt;Location&gt;, Value x,</span></a>
<a name="1311"><span class="lineNum">    1311 </span><span class="lineCov">         20 :                               SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1312"><span class="lineNum">    1312 </span><span class="lineCov">         20 :   auto argTy = x.getType().cast&lt;TensorType&gt;();</span></a>
<a name="1313"><span class="lineNum">    1313 </span><span class="lineCov">         20 :   Builder b(context);</span></a>
<a name="1314"><span class="lineNum">    1314 </span><span class="lineCov">         40 :   inferredReturnTypes.push_back(</span></a>
<a name="1315"><span class="lineNum">    1315 </span><span class="lineCov">         20 :       hlo::getSameShapeTensorType(argTy, b.getI1Type()));</span></a>
<a name="1316"><span class="lineNum">    1316 </span><span class="lineCov">         20 :   return success();</span></a>
<a name="1317"><span class="lineNum">    1317 </span><span class="lineCov">         20 : }</span></a>
<a name="1318"><span class="lineNum">    1318 </span>            : </a>
<a name="1319"><span class="lineNum">    1319 </span><span class="lineCov">         32 : LogicalResult inferGetDimensionSizeOp(</span></a>
<a name="1320"><span class="lineNum">    1320 </span>            :     MLIRContext* context, Optional&lt;Location&gt; location,</a>
<a name="1321"><span class="lineNum">    1321 </span><span class="lineCov">         32 :     SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1322"><span class="lineNum">    1322 </span><span class="lineCov">         64 :   inferredReturnTypes.push_back(</span></a>
<a name="1323"><span class="lineNum">    1323 </span><span class="lineCov">         32 :       RankedTensorType::get({}, IntegerType::get(context, 32)));</span></a>
<a name="1324"><span class="lineNum">    1324 </span><span class="lineCov">         32 :   return success();</span></a>
<a name="1325"><span class="lineNum">    1325 </span>            : }</a>
<a name="1326"><span class="lineNum">    1326 </span>            : </a>
<a name="1327"><span class="lineNum">    1327 </span><span class="lineCov">         48 : LogicalResult inferIfOp(Optional&lt;Location&gt; location, RegionRange branches,</span></a>
<a name="1328"><span class="lineNum">    1328 </span><span class="lineCov">         48 :                         SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1329"><span class="lineNum">    1329 </span><span class="lineCov">         48 :   return inferConditionalOp(location, branches, inferredReturnTypes);</span></a>
<a name="1330"><span class="lineNum">    1330 </span>            : }</a>
<a name="1331"><span class="lineNum">    1331 </span>            : </a>
<a name="1332"><span class="lineNum">    1332 </span><span class="lineCov">         56 : LogicalResult inferMapOp(</span></a>
<a name="1333"><span class="lineNum">    1333 </span>            :     Optional&lt;Location&gt; location, ValueRange inputs,</a>
<a name="1334"><span class="lineNum">    1334 </span>            :     DenseIntElementsAttr dimensions, Region&amp; computation,</a>
<a name="1335"><span class="lineNum">    1335 </span><span class="lineCov">         56 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1336"><span class="lineNum">    1336 </span><span class="lineCov">         56 :   if (failed(verifyRegionNotEmpty(location, computation))) return failure();</span></a>
<a name="1337"><span class="lineNum">    1337 </span>            : </a>
<a name="1338"><span class="lineNum">    1338 </span>            :   // Checks if the number of `operands` match the arity of the map `computation`</a>
<a name="1339"><span class="lineNum">    1339 </span>            :   // region.</a>
<a name="1340"><span class="lineNum">    1340 </span><span class="lineCov">         56 :   auto&amp; computationBlock = computation.front();</span></a>
<a name="1341"><span class="lineNum">    1341 </span><span class="lineCov">         56 :   auto computationArgs = computationBlock.getArguments();</span></a>
<a name="1342"><span class="lineNum">    1342 </span><span class="lineCov">         56 :   if (inputs.size() != computationArgs.size())</span></a>
<a name="1343"><span class="lineNum">    1343 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="1344"><span class="lineNum">    1344 </span>            :                              &quot;expects number of operands to match the arity of &quot;</a>
<a name="1345"><span class="lineNum">    1345 </span>            :                              &quot;map computation, but got: &quot;,</a>
<a name="1346"><span class="lineNum">    1346 </span><span class="lineCov">          2 :                              inputs.size(), &quot; and &quot;, computationArgs.size());</span></a>
<a name="1347"><span class="lineNum">    1347 </span>            : </a>
<a name="1348"><span class="lineNum">    1348 </span>            :   // The parameters of computation should all be scalars and match the element</a>
<a name="1349"><span class="lineNum">    1349 </span>            :   // type of operands.</a>
<a name="1350"><span class="lineNum">    1350 </span><span class="lineCov">        152 :   for (const auto&amp; indexedArg : llvm::enumerate(computationArgs)) {</span></a>
<a name="1351"><span class="lineNum">    1351 </span><span class="lineCov">         98 :     auto argType = indexedArg.value().getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1352"><span class="lineNum">    1352 </span><span class="lineCov">         98 :     if (!argType || argType.getRank() != 0)</span></a>
<a name="1353"><span class="lineNum">    1353 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="1354"><span class="lineNum">    1354 </span><span class="lineCov">          2 :           location,</span></a>
<a name="1355"><span class="lineNum">    1355 </span>            :           &quot;computation arguments must be 0-rank tensor, but got: arg #&quot;,</a>
<a name="1356"><span class="lineNum">    1356 </span><span class="lineCov">          2 :           indexedArg.index(), &quot; of type &quot;, indexedArg.value().getType());</span></a>
<a name="1357"><span class="lineNum">    1357 </span><span class="lineCov">        192 :     auto operandElemTy = inputs[indexedArg.index()]</span></a>
<a name="1358"><span class="lineNum">    1358 </span><span class="lineCov">         96 :                              .getType()</span></a>
<a name="1359"><span class="lineNum">    1359 </span><span class="lineCov">         96 :                              .cast&lt;TensorType&gt;()</span></a>
<a name="1360"><span class="lineNum">    1360 </span><span class="lineCov">         96 :                              .getElementType();</span></a>
<a name="1361"><span class="lineNum">    1361 </span><span class="lineCov">         96 :     if (argType.getElementType() != operandElemTy) {</span></a>
<a name="1362"><span class="lineNum">    1362 </span><span class="lineCov">          4 :       return emitOptionalError(location,</span></a>
<a name="1363"><span class="lineNum">    1363 </span>            :                                &quot;element type of operands and computation &quot;</a>
<a name="1364"><span class="lineNum">    1364 </span>            :                                &quot;arguments must match, but got: &quot;,</a>
<a name="1365"><span class="lineNum">    1365 </span>            :                                operandElemTy, &quot; and &quot;,</a>
<a name="1366"><span class="lineNum">    1366 </span><span class="lineCov">          2 :                                argType.getElementType());</span></a>
<a name="1367"><span class="lineNum">    1367 </span>            :     }</a>
<a name="1368"><span class="lineNum">    1368 </span><span class="lineCov">         98 :   }</span></a>
<a name="1369"><span class="lineNum">    1369 </span>            : </a>
<a name="1370"><span class="lineNum">    1370 </span>            :   // Mapped computation must return single output</a>
<a name="1371"><span class="lineNum">    1371 </span><span class="lineCov">         50 :   auto computationOutputs = computationBlock.getTerminator()-&gt;getOperands();</span></a>
<a name="1372"><span class="lineNum">    1372 </span><span class="lineCov">         50 :   if (computationOutputs.size() != 1)</span></a>
<a name="1373"><span class="lineNum">    1373 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="1374"><span class="lineNum">    1374 </span>            :                              &quot;computation must return single output, but got: &quot;,</a>
<a name="1375"><span class="lineNum">    1375 </span><span class="lineCov">          2 :                              computationOutputs.size());</span></a>
<a name="1376"><span class="lineNum">    1376 </span>            : </a>
<a name="1377"><span class="lineNum">    1377 </span>            :   // The output of computation must be scalar and have the same element type</a>
<a name="1378"><span class="lineNum">    1378 </span>            :   // as op result.</a>
<a name="1379"><span class="lineNum">    1379 </span><span class="lineCov">         48 :   auto computationOutputType =</span></a>
<a name="1380"><span class="lineNum">    1380 </span><span class="lineCov">         48 :       computationOutputs[0].getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1381"><span class="lineNum">    1381 </span><span class="lineCov">         48 :   if (!computationOutputType || computationOutputType.getRank() != 0)</span></a>
<a name="1382"><span class="lineNum">    1382 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="1383"><span class="lineNum">    1383 </span>            :                              &quot;computation must return 0-rank tensor, but got: &quot;,</a>
<a name="1384"><span class="lineNum">    1384 </span><span class="lineCov">          2 :                              computationOutputs[0].getType());</span></a>
<a name="1385"><span class="lineNum">    1385 </span>            : </a>
<a name="1386"><span class="lineNum">    1386 </span>            :   // Checks that the requested map dimension numbers are monotonically</a>
<a name="1387"><span class="lineNum">    1387 </span>            :   // increasing.</a>
<a name="1388"><span class="lineNum">    1388 </span><span class="lineCov">        106 :   for (const auto&amp; indexedValue :</span></a>
<a name="1389"><span class="lineNum">    1389 </span><span class="lineCov">         46 :        llvm::enumerate(dimensions.getValues&lt;int64_t&gt;())) {</span></a>
<a name="1390"><span class="lineNum">    1390 </span><span class="lineCov">         60 :     if (indexedValue.value() != static_cast&lt;int64_t&gt;(indexedValue.index()))</span></a>
<a name="1391"><span class="lineNum">    1391 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="1392"><span class="lineNum">    1392 </span><span class="lineCov">          2 :           location,</span></a>
<a name="1393"><span class="lineNum">    1393 </span>            :           &quot;requires monotonically increasing dimension numbers, but got: &quot;,</a>
<a name="1394"><span class="lineNum">    1394 </span>            :           dimensions);</a>
<a name="1395"><span class="lineNum">    1395 </span><span class="lineCov">         60 :   }</span></a>
<a name="1396"><span class="lineNum">    1396 </span>            : </a>
<a name="1397"><span class="lineNum">    1397 </span>            :   // Checks that number of dimensions of operands matches the size of</a>
<a name="1398"><span class="lineNum">    1398 </span>            :   // `dimensions` since we currently only support mapping across all</a>
<a name="1399"><span class="lineNum">    1399 </span>            :   // dimensions: i.e., scalar map functions.</a>
<a name="1400"><span class="lineNum">    1400 </span><span class="lineCov">         44 :   ArrayRef&lt;int64_t&gt; resultShape;</span></a>
<a name="1401"><span class="lineNum">    1401 </span><span class="lineCov">         44 :   bool allInputsUnranked = true;</span></a>
<a name="1402"><span class="lineNum">    1402 </span><span class="lineCov">        122 :   for (auto operand : inputs) {</span></a>
<a name="1403"><span class="lineNum">    1403 </span><span class="lineCov">         78 :     auto operandType = operand.getType().cast&lt;TensorType&gt;();</span></a>
<a name="1404"><span class="lineNum">    1404 </span><span class="lineCov">         78 :     if (operandType.hasRank()) {</span></a>
<a name="1405"><span class="lineNum">    1405 </span><span class="lineCov">        140 :       if (dimensions.size() !=</span></a>
<a name="1406"><span class="lineNum">    1406 </span><span class="lineCov">         70 :           static_cast&lt;int64_t&gt;(operandType.getShape().size()))</span></a>
<a name="1407"><span class="lineNum">    1407 </span><span class="lineCov">          2 :         return emitOptionalError(</span></a>
<a name="1408"><span class="lineNum">    1408 </span><span class="lineCov">          2 :             location,</span></a>
<a name="1409"><span class="lineNum">    1409 </span>            :             &quot;applied to a subset of dimensions currently not supported: &quot;</a>
<a name="1410"><span class="lineNum">    1410 </span>            :             &quot;operand dimensions = &quot;,</a>
<a name="1411"><span class="lineNum">    1411 </span><span class="lineCov">          2 :             operandType.getShape().size(),</span></a>
<a name="1412"><span class="lineNum">    1412 </span><span class="lineCov">          2 :             &quot;, requested map dimensions size = &quot;, dimensions.size());</span></a>
<a name="1413"><span class="lineNum">    1413 </span><span class="lineCov">         68 :       resultShape = operandType.getShape();</span></a>
<a name="1414"><span class="lineNum">    1414 </span><span class="lineCov">         68 :       allInputsUnranked = false;</span></a>
<a name="1415"><span class="lineNum">    1415 </span><span class="lineCov">         68 :     }</span></a>
<a name="1416"><span class="lineNum">    1416 </span><span class="lineCov">         78 :   }</span></a>
<a name="1417"><span class="lineNum">    1417 </span>            : </a>
<a name="1418"><span class="lineNum">    1418 </span><span class="lineCov">         42 :   if (allInputsUnranked)</span></a>
<a name="1419"><span class="lineNum">    1419 </span><span class="lineCov">          4 :     inferredReturnShapes.emplace_back(computationOutputType.getElementType());</span></a>
<a name="1420"><span class="lineNum">    1420 </span>            :   else</a>
<a name="1421"><span class="lineNum">    1421 </span><span class="lineCov">         76 :     inferredReturnShapes.emplace_back(resultShape,</span></a>
<a name="1422"><span class="lineNum">    1422 </span><span class="lineCov">         38 :                                       computationOutputType.getElementType());</span></a>
<a name="1423"><span class="lineNum">    1423 </span><span class="lineCov">         42 :   return success();</span></a>
<a name="1424"><span class="lineNum">    1424 </span><span class="lineCov">         56 : }</span></a>
<a name="1425"><span class="lineNum">    1425 </span>            : </a>
<a name="1426"><span class="lineNum">    1426 </span><span class="lineCov">         61 : LogicalResult inferPadOp(Optional&lt;Location&gt; location, Value operand,</span></a>
<a name="1427"><span class="lineNum">    1427 </span>            :                          Value paddingValue,</a>
<a name="1428"><span class="lineNum">    1428 </span>            :                          DenseIntElementsAttr edgePaddingLow,</a>
<a name="1429"><span class="lineNum">    1429 </span>            :                          DenseIntElementsAttr edgePaddingHigh,</a>
<a name="1430"><span class="lineNum">    1430 </span>            :                          DenseIntElementsAttr interiorPadding,</a>
<a name="1431"><span class="lineNum">    1431 </span><span class="lineCov">         61 :                          SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1432"><span class="lineNum">    1432 </span><span class="lineCov">         61 :   auto inputType = operand.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="1433"><span class="lineNum">    1433 </span><span class="lineCov">         61 :   auto padType = paddingValue.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="1434"><span class="lineNum">    1434 </span>            : </a>
<a name="1435"><span class="lineNum">    1435 </span><span class="lineCov">         61 :   if (padType.getRank() != 0)</span></a>
<a name="1436"><span class="lineNum">    1436 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="1437"><span class="lineNum">    1437 </span>            :                              &quot;padding value type should be a rank-0 &quot;</a>
<a name="1438"><span class="lineNum">    1438 </span>            :                              &quot;tensor, is rank &quot;,</a>
<a name="1439"><span class="lineNum">    1439 </span><span class="lineCov">          2 :                              padType.getRank());</span></a>
<a name="1440"><span class="lineNum">    1440 </span>            : </a>
<a name="1441"><span class="lineNum">    1441 </span><span class="lineCov">         59 :   int64_t rank = inputType.getRank();</span></a>
<a name="1442"><span class="lineNum">    1442 </span><span class="lineCov">         59 :   if (edgePaddingLow.getType().getNumElements() != rank)</span></a>
<a name="1443"><span class="lineNum">    1443 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;edge_padding_low length (&quot;,</span></a>
<a name="1444"><span class="lineNum">    1444 </span><span class="lineCov">          2 :                              edgePaddingLow.getType().getNumElements(),</span></a>
<a name="1445"><span class="lineNum">    1445 </span>            :                              &quot;) must match operand rank (&quot;, rank, &quot;)&quot;);</a>
<a name="1446"><span class="lineNum">    1446 </span>            : </a>
<a name="1447"><span class="lineNum">    1447 </span><span class="lineCov">         57 :   if (edgePaddingHigh.getType().getNumElements() != rank)</span></a>
<a name="1448"><span class="lineNum">    1448 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;edge_padding_high length (&quot;,</span></a>
<a name="1449"><span class="lineNum">    1449 </span><span class="lineCov">          2 :                              edgePaddingHigh.getType().getNumElements(),</span></a>
<a name="1450"><span class="lineNum">    1450 </span>            :                              &quot;) must match operand rank (&quot;, rank, &quot;)&quot;);</a>
<a name="1451"><span class="lineNum">    1451 </span>            : </a>
<a name="1452"><span class="lineNum">    1452 </span><span class="lineCov">         55 :   if (interiorPadding.getType().getNumElements() != rank)</span></a>
<a name="1453"><span class="lineNum">    1453 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;interior_padding length (&quot;,</span></a>
<a name="1454"><span class="lineNum">    1454 </span><span class="lineCov">          2 :                              interiorPadding.getType().getNumElements(),</span></a>
<a name="1455"><span class="lineNum">    1455 </span>            :                              &quot;) must match operand rank (&quot;, rank, &quot;)&quot;);</a>
<a name="1456"><span class="lineNum">    1456 </span>            : </a>
<a name="1457"><span class="lineNum">    1457 </span><span class="lineCov">         53 :   auto inputShape = inputType.getShape();</span></a>
<a name="1458"><span class="lineNum">    1458 </span><span class="lineCov">         53 :   SmallVector&lt;int64_t&gt; resultShape(rank, ShapedType::kDynamic);</span></a>
<a name="1459"><span class="lineNum">    1459 </span><span class="lineCov">         53 :   ArrayRef&lt;int64_t&gt; inputBounds = encodingToBounds(inputType.getEncoding());</span></a>
<a name="1460"><span class="lineNum">    1460 </span><span class="lineCov">         53 :   SmallVector&lt;int64_t&gt; resultBounds(inputBounds.size(), ShapedType::kDynamic);</span></a>
<a name="1461"><span class="lineNum">    1461 </span>            : </a>
<a name="1462"><span class="lineNum">    1462 </span><span class="lineCov">        179 :   for (int i = 0, e = inputShape.size(); i &lt; e; i++) {</span></a>
<a name="1463"><span class="lineNum">    1463 </span><span class="lineCov">        126 :     int64_t paddingLowVal = edgePaddingLow.getValues&lt;APInt&gt;()[i].getSExtValue();</span></a>
<a name="1464"><span class="lineNum">    1464 </span><span class="lineCov">        252 :     int64_t paddingHighVal =</span></a>
<a name="1465"><span class="lineNum">    1465 </span><span class="lineCov">        126 :         edgePaddingHigh.getValues&lt;APInt&gt;()[i].getSExtValue();</span></a>
<a name="1466"><span class="lineNum">    1466 </span><span class="lineCov">        252 :     int64_t paddingInteriorVal =</span></a>
<a name="1467"><span class="lineNum">    1467 </span><span class="lineCov">        126 :         interiorPadding.getValues&lt;APInt&gt;()[i].getSExtValue();</span></a>
<a name="1468"><span class="lineNum">    1468 </span><span class="lineCov">        126 :     if (paddingInteriorVal &lt; 0)</span></a>
<a name="1469"><span class="lineNum">    1469 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="1470"><span class="lineNum">    1470 </span><span class="lineCov">          2 :           location,</span></a>
<a name="1471"><span class="lineNum">    1471 </span>            :           &quot;Interior padding cannot be negative: &quot;, paddingInteriorVal);</a>
<a name="1472"><span class="lineNum">    1472 </span>            : </a>
<a name="1473"><span class="lineNum">    1473 </span><span class="lineCov">        124 :     bool isStaticDim = !hlo::isDynamicDimSize(inputShape[i]);</span></a>
<a name="1474"><span class="lineNum">    1474 </span><span class="lineCov">        152 :     bool isStaticBound =</span></a>
<a name="1475"><span class="lineNum">    1475 </span><span class="lineCov">        124 :         !inputBounds.empty() &amp;&amp; !hlo::isDynamicDimSize(inputBounds[i]);</span></a>
<a name="1476"><span class="lineNum">    1476 </span><span class="lineCov">        124 :     if (isStaticDim || isStaticBound) {</span></a>
<a name="1477"><span class="lineNum">    1477 </span><span class="lineCov">        111 :       int64_t operandSizeOrBound = isStaticDim ? inputShape[i] : inputBounds[i];</span></a>
<a name="1478"><span class="lineNum">    1478 </span><span class="lineCov">        222 :       int64_t resultSizeOrBound =</span></a>
<a name="1479"><span class="lineNum">    1479 </span><span class="lineCov">        222 :           operandSizeOrBound + paddingLowVal + paddingHighVal +</span></a>
<a name="1480"><span class="lineNum">    1480 </span><span class="lineCov">        111 :           std::max&lt;int64_t&gt;(operandSizeOrBound - 1, 0LL) * paddingInteriorVal;</span></a>
<a name="1481"><span class="lineNum">    1481 </span>            : </a>
<a name="1482"><span class="lineNum">    1482 </span><span class="lineCov">        111 :       if (resultSizeOrBound &lt; 0) {</span></a>
<a name="1483"><span class="lineNum">    1483 </span><span class="lineCov">          4 :         auto sizeOrBound = isStaticDim ? &quot;size&quot; : &quot;bound&quot;;</span></a>
<a name="1484"><span class="lineNum">    1484 </span><span class="lineCov">          4 :         return emitOptionalError(location, &quot;Padding result in negative &quot;,</span></a>
<a name="1485"><span class="lineNum">    1485 </span>            :                                  sizeOrBound, &quot; for dimension &quot;, i);</a>
<a name="1486"><span class="lineNum">    1486 </span><span class="lineCov">          4 :       }</span></a>
<a name="1487"><span class="lineNum">    1487 </span><span class="lineCov">        107 :       (isStaticDim ? resultShape : resultBounds)[i] = resultSizeOrBound;</span></a>
<a name="1488"><span class="lineNum">    1488 </span><span class="lineCov">        111 :     }</span></a>
<a name="1489"><span class="lineNum">    1489 </span><span class="lineCov">        126 :   }</span></a>
<a name="1490"><span class="lineNum">    1490 </span><span class="lineCov">         94 :   inferredReturnTypes.push_back(RankedTensorType::get(</span></a>
<a name="1491"><span class="lineNum">    1491 </span><span class="lineCov">         47 :       resultShape, inputType.getElementType(),</span></a>
<a name="1492"><span class="lineNum">    1492 </span><span class="lineCov">         47 :       boundsToEncoding(inputType.getEncoding(), resultBounds)));</span></a>
<a name="1493"><span class="lineNum">    1493 </span>            : </a>
<a name="1494"><span class="lineNum">    1494 </span><span class="lineCov">         47 :   return success();</span></a>
<a name="1495"><span class="lineNum">    1495 </span><span class="lineCov">         61 : }</span></a>
<a name="1496"><span class="lineNum">    1496 </span>            : </a>
<a name="1497"><span class="lineNum">    1497 </span><span class="lineCov">         36 : LogicalResult inferOptimizationBarrierOp(</span></a>
<a name="1498"><span class="lineNum">    1498 </span>            :     Optional&lt;Location&gt; location, ValueRange operand,</a>
<a name="1499"><span class="lineNum">    1499 </span><span class="lineCov">         36 :     SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1500"><span class="lineNum">    1500 </span><span class="lineCov">         76 :   for (auto inputArgType : operand.getTypes()) {</span></a>
<a name="1501"><span class="lineNum">    1501 </span><span class="lineCov">         40 :     inferredReturnTypes.emplace_back(inputArgType);</span></a>
<a name="1502"><span class="lineNum">    1502 </span><span class="lineCov">         40 :   }</span></a>
<a name="1503"><span class="lineNum">    1503 </span>            : </a>
<a name="1504"><span class="lineNum">    1504 </span><span class="lineCov">         36 :   return success();</span></a>
<a name="1505"><span class="lineNum">    1505 </span>            : }</a>
<a name="1506"><span class="lineNum">    1506 </span>            : </a>
<a name="1507"><span class="lineNum">    1507 </span><span class="lineCov">         32 : LogicalResult inferOutfeedOp(Dialect* dialect, Optional&lt;Location&gt; location,</span></a>
<a name="1508"><span class="lineNum">    1508 </span><span class="lineCov">         32 :                              SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1509"><span class="lineNum">    1509 </span><span class="lineCov">         32 :   auto hloDialect = cast&lt;HloDialectInterface&gt;(dialect);</span></a>
<a name="1510"><span class="lineNum">    1510 </span><span class="lineCov">         32 :   inferredReturnTypes.push_back(hloDialect-&gt;createTokenType());</span></a>
<a name="1511"><span class="lineNum">    1511 </span><span class="lineCov">         32 :   return success();</span></a>
<a name="1512"><span class="lineNum">    1512 </span><span class="lineCov">         32 : }</span></a>
<a name="1513"><span class="lineNum">    1513 </span>            : </a>
<a name="1514"><span class="lineNum">    1514 </span><span class="lineCov">         34 : LogicalResult inferRealOp(Optional&lt;Location&gt;, Value operand,</span></a>
<a name="1515"><span class="lineNum">    1515 </span><span class="lineCov">         34 :                           SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1516"><span class="lineNum">    1516 </span><span class="lineCov">         68 :   inferredReturnTypes.push_back(</span></a>
<a name="1517"><span class="lineNum">    1517 </span><span class="lineCov">         34 :       createRealType(operand.getType().cast&lt;TensorType&gt;()));</span></a>
<a name="1518"><span class="lineNum">    1518 </span><span class="lineCov">         34 :   return success();</span></a>
<a name="1519"><span class="lineNum">    1519 </span>            : }</a>
<a name="1520"><span class="lineNum">    1520 </span>            : </a>
<a name="1521"><span class="lineNum">    1521 </span><span class="lineCov">        150 : LogicalResult inferReduceOp(</span></a>
<a name="1522"><span class="lineNum">    1522 </span>            :     Optional&lt;Location&gt; location, ValueRange inputs, ValueRange initValues,</a>
<a name="1523"><span class="lineNum">    1523 </span>            :     DenseIntElementsAttr dimensions,</a>
<a name="1524"><span class="lineNum">    1524 </span><span class="lineCov">        150 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1525"><span class="lineNum">    1525 </span><span class="lineCov">        300 :   SmallVector&lt;TensorType&gt; inputArgTypes{llvm::map_range(</span></a>
<a name="1526"><span class="lineNum">    1526 </span><span class="lineCov">        150 :       inputs.getTypes(),</span></a>
<a name="1527"><span class="lineNum">    1527 </span><span class="lineCov">        183 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="1528"><span class="lineNum">    1528 </span><span class="lineCov">        300 :   SmallVector&lt;TensorType&gt; initValueTypes{llvm::map_range(</span></a>
<a name="1529"><span class="lineNum">    1529 </span><span class="lineCov">        150 :       initValues.getTypes(),</span></a>
<a name="1530"><span class="lineNum">    1530 </span><span class="lineCov">        183 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="1531"><span class="lineNum">    1531 </span>            : </a>
<a name="1532"><span class="lineNum">    1532 </span><span class="lineCov">        150 :   SmallVector&lt;int64_t&gt; newDimensions;</span></a>
<a name="1533"><span class="lineNum">    1533 </span><span class="lineCov">        150 :   Attribute encoding;</span></a>
<a name="1534"><span class="lineNum">    1534 </span><span class="lineCov">        300 :   if (failed(verifyReduceOpInputsAndInferShape(location, inputArgTypes,</span></a>
<a name="1535"><span class="lineNum">    1535 </span><span class="lineCov">        150 :                                                initValueTypes, dimensions,</span></a>
<a name="1536"><span class="lineNum">    1536 </span>            :                                                newDimensions, encoding)))</a>
<a name="1537"><span class="lineNum">    1537 </span><span class="lineNoCov">          0 :     return failure();</span></a>
<a name="1538"><span class="lineNum">    1538 </span>            : </a>
<a name="1539"><span class="lineNum">    1539 </span><span class="lineCov">        333 :   for (uint64_t inputIdx = 0; inputIdx &lt; inputs.size(); ++inputIdx) {</span></a>
<a name="1540"><span class="lineNum">    1540 </span><span class="lineCov">        183 :     TensorType inputType = inputArgTypes[inputIdx];</span></a>
<a name="1541"><span class="lineNum">    1541 </span><span class="lineCov">        183 :     Type elementType = inputType.getElementType();</span></a>
<a name="1542"><span class="lineNum">    1542 </span><span class="lineCov">        183 :     if (inputType.hasRank())</span></a>
<a name="1543"><span class="lineNum">    1543 </span><span class="lineCov">        167 :       inferredReturnShapes.emplace_back(newDimensions, elementType, encoding);</span></a>
<a name="1544"><span class="lineNum">    1544 </span>            :     else</a>
<a name="1545"><span class="lineNum">    1545 </span><span class="lineCov">         16 :       inferredReturnShapes.emplace_back(elementType);</span></a>
<a name="1546"><span class="lineNum">    1546 </span><span class="lineCov">        183 :   }</span></a>
<a name="1547"><span class="lineNum">    1547 </span>            : </a>
<a name="1548"><span class="lineNum">    1548 </span><span class="lineCov">        150 :   return success();</span></a>
<a name="1549"><span class="lineNum">    1549 </span><span class="lineCov">        150 : }</span></a>
<a name="1550"><span class="lineNum">    1550 </span>            : </a>
<a name="1551"><span class="lineNum">    1551 </span><span class="lineCov">         52 : LogicalResult inferReduceWindowOp(</span></a>
<a name="1552"><span class="lineNum">    1552 </span>            :     Optional&lt;Location&gt; location, ValueRange inputs, ValueRange initValues,</a>
<a name="1553"><span class="lineNum">    1553 </span>            :     DenseIntElementsAttr windowDimensions,</a>
<a name="1554"><span class="lineNum">    1554 </span>            :     Optional&lt;DenseIntElementsAttr&gt; windowStrides,</a>
<a name="1555"><span class="lineNum">    1555 </span>            :     Optional&lt;DenseIntElementsAttr&gt; baseDilations,</a>
<a name="1556"><span class="lineNum">    1556 </span>            :     Optional&lt;DenseIntElementsAttr&gt; windowDilations,</a>
<a name="1557"><span class="lineNum">    1557 </span>            :     Optional&lt;DenseIntElementsAttr&gt; padding,</a>
<a name="1558"><span class="lineNum">    1558 </span><span class="lineCov">         52 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1559"><span class="lineNum">    1559 </span><span class="lineCov">        104 :   SmallVector&lt;TensorType&gt; inputArgTypes{llvm::map_range(</span></a>
<a name="1560"><span class="lineNum">    1560 </span><span class="lineCov">         52 :       inputs.getTypes(),</span></a>
<a name="1561"><span class="lineNum">    1561 </span><span class="lineCov">         80 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="1562"><span class="lineNum">    1562 </span><span class="lineCov">        104 :   SmallVector&lt;TensorType&gt; initValueTypes{llvm::map_range(</span></a>
<a name="1563"><span class="lineNum">    1563 </span><span class="lineCov">         52 :       initValues.getTypes(),</span></a>
<a name="1564"><span class="lineNum">    1564 </span><span class="lineCov">         80 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="1565"><span class="lineNum">    1565 </span>            : </a>
<a name="1566"><span class="lineNum">    1566 </span><span class="lineCov">         52 :   SmallVector&lt;int64_t&gt; windowDims;</span></a>
<a name="1567"><span class="lineNum">    1567 </span><span class="lineCov">         52 :   SmallVector&lt;WindowDimension&gt; inferredWindow;</span></a>
<a name="1568"><span class="lineNum">    1568 </span><span class="lineCov">         52 :   if (failed(verifyReduceWindowOpInputsAndInferWindow(</span></a>
<a name="1569"><span class="lineNum">    1569 </span><span class="lineCov">         52 :           location, inputArgTypes, initValueTypes, windowDimensions,</span></a>
<a name="1570"><span class="lineNum">    1570 </span><span class="lineCov">         52 :           windowStrides, baseDilations, windowDilations, padding,</span></a>
<a name="1571"><span class="lineNum">    1571 </span><span class="lineCov">         52 :           /*windowReversal=*/std::nullopt, windowDims, inferredWindow)))</span></a>
<a name="1572"><span class="lineNum">    1572 </span><span class="lineNoCov">          0 :     return failure();</span></a>
<a name="1573"><span class="lineNum">    1573 </span>            : </a>
<a name="1574"><span class="lineNum">    1574 </span><span class="lineCov">        132 :   for (size_t i = 0; i &lt; inputArgTypes.size(); ++i) {</span></a>
<a name="1575"><span class="lineNum">    1575 </span><span class="lineCov">         80 :     if (!inputArgTypes[i].hasRank())</span></a>
<a name="1576"><span class="lineNum">    1576 </span><span class="lineCov">          4 :       inferredReturnShapes.emplace_back(inputArgTypes[i].getElementType());</span></a>
<a name="1577"><span class="lineNum">    1577 </span>            :     else</a>
<a name="1578"><span class="lineNum">    1578 </span><span class="lineCov">        152 :       inferredReturnShapes.emplace_back(</span></a>
<a name="1579"><span class="lineNum">    1579 </span><span class="lineCov">         76 :           inferWindowOutputShape(inputArgTypes[i].getShape(), inferredWindow),</span></a>
<a name="1580"><span class="lineNum">    1580 </span><span class="lineCov">         76 :           inputArgTypes[i].getElementType());</span></a>
<a name="1581"><span class="lineNum">    1581 </span><span class="lineCov">         80 :   }</span></a>
<a name="1582"><span class="lineNum">    1582 </span>            : </a>
<a name="1583"><span class="lineNum">    1583 </span><span class="lineCov">         52 :   return success();</span></a>
<a name="1584"><span class="lineNum">    1584 </span><span class="lineCov">         52 : }</span></a>
<a name="1585"><span class="lineNum">    1585 </span>            : </a>
<a name="1586"><span class="lineNum">    1586 </span><span class="lineCov">        797 : LogicalResult inferReturnOp(Optional&lt;Location&gt;, SmallVectorImpl&lt;Type&gt;&amp;) {</span></a>
<a name="1587"><span class="lineNum">    1587 </span><span class="lineCov">        797 :   return success();</span></a>
<a name="1588"><span class="lineNum">    1588 </span>            : }</a>
<a name="1589"><span class="lineNum">    1589 </span>            : </a>
<a name="1590"><span class="lineNum">    1590 </span><span class="lineCov">         42 : LogicalResult inferScatterOp(Optional&lt;Location&gt;, ValueRange inputs,</span></a>
<a name="1591"><span class="lineNum">    1591 </span><span class="lineCov">         42 :                              SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1592"><span class="lineNum">    1592 </span><span class="lineCov">         42 :   llvm::append_range(inferredReturnTypes, inputs.getTypes());</span></a>
<a name="1593"><span class="lineNum">    1593 </span><span class="lineCov">         42 :   return success();</span></a>
<a name="1594"><span class="lineNum">    1594 </span>            : }</a>
<a name="1595"><span class="lineNum">    1595 </span>            : </a>
<a name="1596"><span class="lineNum">    1596 </span><span class="lineCov">         84 : LogicalResult inferSelectOp(</span></a>
<a name="1597"><span class="lineNum">    1597 </span>            :     Optional&lt;Location&gt; location, Value pred, Value onTrue, Value onFalse,</a>
<a name="1598"><span class="lineNum">    1598 </span><span class="lineCov">         84 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1599"><span class="lineNum">    1599 </span><span class="lineCov">         84 :   auto predType = pred.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1600"><span class="lineNum">    1600 </span><span class="lineCov">         84 :   auto trueType = onTrue.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1601"><span class="lineNum">    1601 </span><span class="lineCov">         84 :   auto falseType = onFalse.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="1602"><span class="lineNum">    1602 </span>            : </a>
<a name="1603"><span class="lineNum">    1603 </span>            :   // The operands `onTrue` and `onFalse` should have compatible types, i.e.,</a>
<a name="1604"><span class="lineNum">    1604 </span>            :   //   (a) have the same element type, and</a>
<a name="1605"><span class="lineNum">    1605 </span>            :   //   (b) have compatible shapes (i.e. the same shape and/or at least one</a>
<a name="1606"><span class="lineNum">    1606 </span>            :   //       dynamic shape)</a>
<a name="1607"><span class="lineNum">    1607 </span><span class="lineCov">         84 :   if (!hlo::compatibleShapeAndElementType(trueType, falseType))</span></a>
<a name="1608"><span class="lineNum">    1608 </span><span class="lineCov">          6 :     return emitOptionalError(</span></a>
<a name="1609"><span class="lineNum">    1609 </span><span class="lineCov">          6 :         location, &quot;requires compatible types for non-predicate operands&quot;);</span></a>
<a name="1610"><span class="lineNum">    1610 </span>            : </a>
<a name="1611"><span class="lineNum">    1611 </span>            :   // The predicate, if not-scalar, should have the same shape as the remaining</a>
<a name="1612"><span class="lineNum">    1612 </span>            :   // operands.</a>
<a name="1613"><span class="lineNum">    1613 </span><span class="lineCov">         78 :   bool predCannotBeScalar = predType.hasRank() &amp;&amp; predType.getRank() != 0;</span></a>
<a name="1614"><span class="lineNum">    1614 </span><span class="lineCov">         78 :   if (predCannotBeScalar)</span></a>
<a name="1615"><span class="lineNum">    1615 </span><span class="lineCov">         26 :     if (failed(verifyCompatibleShape(predType, trueType)))</span></a>
<a name="1616"><span class="lineNum">    1616 </span><span class="lineCov">          2 :       return emitOptionalError(location,</span></a>
<a name="1617"><span class="lineNum">    1617 </span>            :                                &quot;requires the same shape for all operands&quot;);</a>
<a name="1618"><span class="lineNum">    1618 </span>            : </a>
<a name="1619"><span class="lineNum">    1619 </span>            :   // The output shape should be derived from the most specific parts of the</a>
<a name="1620"><span class="lineNum">    1620 </span>            :   // `onTrue` and `onFalse` (see documentation for details).</a>
<a name="1621"><span class="lineNum">    1621 </span><span class="lineCov">         76 :   SmallVector&lt;Type&gt; inferredReturnTypes;</span></a>
<a name="1622"><span class="lineNum">    1622 </span><span class="lineCov">        152 :   return hlo::inferMostSpecificTypeComponents(location, {trueType, falseType},</span></a>
<a name="1623"><span class="lineNum">    1623 </span><span class="lineCov">         76 :                                               inferredReturnShapes);</span></a>
<a name="1624"><span class="lineNum">    1624 </span><span class="lineCov">         84 : }</span></a>
<a name="1625"><span class="lineNum">    1625 </span>            : </a>
<a name="1626"><span class="lineNum">    1626 </span><span class="lineCov">         32 : LogicalResult inferSelectAndScatterOp(</span></a>
<a name="1627"><span class="lineNum">    1627 </span><span class="lineCov">         32 :     Value operand, SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1628"><span class="lineNum">    1628 </span><span class="lineCov">         32 :   inferredReturnTypes.push_back(operand.getType());</span></a>
<a name="1629"><span class="lineNum">    1629 </span><span class="lineCov">         32 :   return success();</span></a>
<a name="1630"><span class="lineNum">    1630 </span>            : }</a>
<a name="1631"><span class="lineNum">    1631 </span>            : </a>
<a name="1632"><span class="lineNum">    1632 </span><span class="lineCov">         28 : LogicalResult inferSendOp(Dialect* dialect, Optional&lt;Location&gt; location,</span></a>
<a name="1633"><span class="lineNum">    1633 </span><span class="lineCov">         28 :                           SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1634"><span class="lineNum">    1634 </span><span class="lineCov">         28 :   auto hloDialect = cast&lt;HloDialectInterface&gt;(dialect);</span></a>
<a name="1635"><span class="lineNum">    1635 </span><span class="lineCov">         28 :   inferredReturnTypes.push_back(hloDialect-&gt;createTokenType());</span></a>
<a name="1636"><span class="lineNum">    1636 </span><span class="lineCov">         28 :   return success();</span></a>
<a name="1637"><span class="lineNum">    1637 </span><span class="lineCov">         28 : }</span></a>
<a name="1638"><span class="lineNum">    1638 </span>            : </a>
<a name="1639"><span class="lineNum">    1639 </span>            : // The following properties are already enforced by the ODS:</a>
<a name="1640"><span class="lineNum">    1640 </span>            : //  type(start_indices) == type(limit_indices) == type(strides).</a>
<a name="1641"><span class="lineNum">    1641 </span>            : // Verify the following properties:</a>
<a name="1642"><span class="lineNum">    1642 </span>            : //  P1. Verify rank(start_indices) == 1.</a>
<a name="1643"><span class="lineNum">    1643 </span>            : //  P2. Verify size(start_indices) == rank(operand).</a>
<a name="1644"><span class="lineNum">    1644 </span>            : //  P3~5. Verify 0 &lt;= start_indices[i] &lt;= limit_indices[i] &lt;= shape(operand)[i].</a>
<a name="1645"><span class="lineNum">    1645 </span>            : //  P6. Verify stride[i] &gt; 0.</a>
<a name="1646"><span class="lineNum">    1646 </span>            : // Note: for P4, use the bound size than dim size for bounded dynamism case.</a>
<a name="1647"><span class="lineNum">    1647 </span><span class="lineCov">         68 : LogicalResult inferSliceOp(Optional&lt;Location&gt; location, Value operand,</span></a>
<a name="1648"><span class="lineNum">    1648 </span>            :                            DenseIntElementsAttr startIndices,</a>
<a name="1649"><span class="lineNum">    1649 </span>            :                            DenseIntElementsAttr limitIndices,</a>
<a name="1650"><span class="lineNum">    1650 </span>            :                            DenseIntElementsAttr strides,</a>
<a name="1651"><span class="lineNum">    1651 </span><span class="lineCov">         68 :                            SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1652"><span class="lineNum">    1652 </span><span class="lineCov">         68 :   Type ty = operand.getType();</span></a>
<a name="1653"><span class="lineNum">    1653 </span><span class="lineCov">         68 :   RankedTensorType rankedTy = ty.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1654"><span class="lineNum">    1654 </span><span class="lineCov">         68 :   if (!rankedTy) {</span></a>
<a name="1655"><span class="lineNum">    1655 </span>            :     // The operand type is unranked, so the best we can infer for the result</a>
<a name="1656"><span class="lineNum">    1656 </span>            :     // type is an unranked tensor with the same element type as the operand</a>
<a name="1657"><span class="lineNum">    1657 </span>            :     // type.</a>
<a name="1658"><span class="lineNum">    1658 </span><span class="lineCov">          4 :     inferredReturnTypes.assign({ty});</span></a>
<a name="1659"><span class="lineNum">    1659 </span><span class="lineCov">          4 :     return success();</span></a>
<a name="1660"><span class="lineNum">    1660 </span>            :   }</a>
<a name="1661"><span class="lineNum">    1661 </span>            : </a>
<a name="1662"><span class="lineNum">    1662 </span><span class="lineCov">         64 :   ShapedType attrTy = startIndices.getType();</span></a>
<a name="1663"><span class="lineNum">    1663 </span>            :   // P1.</a>
<a name="1664"><span class="lineNum">    1664 </span>            :   // Note: ODS has type(start_indices) == type(limit_indices) == type(strides)</a>
<a name="1665"><span class="lineNum">    1665 </span>            :   // So this implies rank(limit_indices) == rank(strides) == 1 also.</a>
<a name="1666"><span class="lineNum">    1666 </span><span class="lineCov">         64 :   if (attrTy.getRank() != 1) {</span></a>
<a name="1667"><span class="lineNum">    1667 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;start_indices has rank &quot;,</span></a>
<a name="1668"><span class="lineNum">    1668 </span><span class="lineCov">          2 :                              attrTy.getRank(), &quot; instead of required rank 1&quot;);</span></a>
<a name="1669"><span class="lineNum">    1669 </span>            :   }</a>
<a name="1670"><span class="lineNum">    1670 </span>            : </a>
<a name="1671"><span class="lineNum">    1671 </span>            :   // P2.</a>
<a name="1672"><span class="lineNum">    1672 </span><span class="lineCov">         62 :   int64_t rank = rankedTy.getRank();</span></a>
<a name="1673"><span class="lineNum">    1673 </span><span class="lineCov">         62 :   if (attrTy.getNumElements() != rank) {</span></a>
<a name="1674"><span class="lineNum">    1674 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1675"><span class="lineNum">    1675 </span><span class="lineCov">          2 :         location, &quot;the number of elements in start_indices (&quot;,</span></a>
<a name="1676"><span class="lineNum">    1676 </span><span class="lineCov">          2 :         attrTy.getNumElements(), &quot;) does not match the rank of the operand (&quot;,</span></a>
<a name="1677"><span class="lineNum">    1677 </span>            :         rank, &quot;)&quot;);</a>
<a name="1678"><span class="lineNum">    1678 </span>            :   }</a>
<a name="1679"><span class="lineNum">    1679 </span>            : </a>
<a name="1680"><span class="lineNum">    1680 </span><span class="lineCov">         60 :   SmallVector&lt;int64_t, 4&gt; start(startIndices.getValues&lt;int64_t&gt;());</span></a>
<a name="1681"><span class="lineNum">    1681 </span><span class="lineCov">         60 :   SmallVector&lt;int64_t, 4&gt; limit(limitIndices.getValues&lt;int64_t&gt;());</span></a>
<a name="1682"><span class="lineNum">    1682 </span><span class="lineCov">         60 :   SmallVector&lt;int64_t, 4&gt; strideVals(strides.getValues&lt;int64_t&gt;());</span></a>
<a name="1683"><span class="lineNum">    1683 </span>            : </a>
<a name="1684"><span class="lineNum">    1684 </span><span class="lineCov">         60 :   ArrayRef&lt;int64_t&gt; inputBounds = encodingToBounds(rankedTy.getEncoding());</span></a>
<a name="1685"><span class="lineNum">    1685 </span><span class="lineCov">         60 :   SmallVector&lt;int64_t&gt; shape(rank, ShapedType::kDynamic);</span></a>
<a name="1686"><span class="lineNum">    1686 </span><span class="lineCov">         60 :   SmallVector&lt;int64_t&gt; resultBounds(inputBounds.size(), ShapedType::kDynamic);</span></a>
<a name="1687"><span class="lineNum">    1687 </span>            : </a>
<a name="1688"><span class="lineNum">    1688 </span><span class="lineCov">        162 :   for (int64_t i = 0, e = rank; i != e; i++) {</span></a>
<a name="1689"><span class="lineNum">    1689 </span>            :     // P3.</a>
<a name="1690"><span class="lineNum">    1690 </span><span class="lineCov">        102 :     if (start[i] &lt; 0)</span></a>
<a name="1691"><span class="lineNum">    1691 </span><span class="lineCov">          4 :       return emitOptionalError(location, &quot;negative start index &quot;, start[i],</span></a>
<a name="1692"><span class="lineNum">    1692 </span>            :                                &quot; in dimension &quot;, i);</a>
<a name="1693"><span class="lineNum">    1693 </span>            : </a>
<a name="1694"><span class="lineNum">    1694 </span>            :     // P4.</a>
<a name="1695"><span class="lineNum">    1695 </span><span class="lineCov">         98 :     bool isStaticDim = !hlo::isDynamicDimSize(rankedTy.getDimSize(i));</span></a>
<a name="1696"><span class="lineNum">    1696 </span><span class="lineCov">        126 :     bool isStaticBound =</span></a>
<a name="1697"><span class="lineNum">    1697 </span><span class="lineCov">         98 :         !inputBounds.empty() &amp;&amp; !hlo::isDynamicDimSize(inputBounds[i]);</span></a>
<a name="1698"><span class="lineNum">    1698 </span><span class="lineCov">         98 :     if (isStaticDim || isStaticBound) {</span></a>
<a name="1699"><span class="lineNum">    1699 </span><span class="lineCov">        172 :       int64_t operandSizeOrBound =</span></a>
<a name="1700"><span class="lineNum">    1700 </span><span class="lineCov">         86 :           isStaticDim ? rankedTy.getDimSize(i) : inputBounds[i];</span></a>
<a name="1701"><span class="lineNum">    1701 </span><span class="lineCov">         86 :       StringRef sizeOrBound = isStaticDim ? &quot;size&quot; : &quot;bound&quot;;</span></a>
<a name="1702"><span class="lineNum">    1702 </span><span class="lineCov">         86 :       if (limit[i] &gt; operandSizeOrBound)</span></a>
<a name="1703"><span class="lineNum">    1703 </span><span class="lineCov">          4 :         return emitOptionalError(location, &quot;limit index &quot;, limit[i],</span></a>
<a name="1704"><span class="lineNum">    1704 </span>            :                                  &quot; is larger than dimension &quot;, sizeOrBound, &quot; &quot;,</a>
<a name="1705"><span class="lineNum">    1705 </span>            :                                  operandSizeOrBound, &quot; in dimension &quot;, i);</a>
<a name="1706"><span class="lineNum">    1706 </span><span class="lineCov">         86 :     }</span></a>
<a name="1707"><span class="lineNum">    1707 </span>            : </a>
<a name="1708"><span class="lineNum">    1708 </span>            :     // P5.</a>
<a name="1709"><span class="lineNum">    1709 </span><span class="lineCov">         94 :     if (start[i] &gt; limit[i])</span></a>
<a name="1710"><span class="lineNum">    1710 </span><span class="lineCov">          4 :       return emitOptionalError(location, &quot;start index &quot;, start[i],</span></a>
<a name="1711"><span class="lineNum">    1711 </span><span class="lineCov">          2 :                                &quot; is larger than limit index &quot;, limit[i],</span></a>
<a name="1712"><span class="lineNum">    1712 </span>            :                                &quot; in dimension &quot;, i);</a>
<a name="1713"><span class="lineNum">    1713 </span>            :     // P6.</a>
<a name="1714"><span class="lineNum">    1714 </span><span class="lineCov">         92 :     if (strideVals[i] &lt;= 0)</span></a>
<a name="1715"><span class="lineNum">    1715 </span><span class="lineCov">          4 :       return emitOptionalError(location, &quot;stride must be positive but got &quot;,</span></a>
<a name="1716"><span class="lineNum">    1716 </span><span class="lineCov">          2 :                                strideVals[i], &quot; in dimension &quot;, i);</span></a>
<a name="1717"><span class="lineNum">    1717 </span>            : </a>
<a name="1718"><span class="lineNum">    1718 </span><span class="lineCov">         90 :     shape[i] = static_cast&lt;int64_t&gt;(</span></a>
<a name="1719"><span class="lineNum">    1719 </span><span class="lineCov">         90 :         llvm::divideCeil(limit[i] - start[i], strideVals[i]));</span></a>
<a name="1720"><span class="lineNum">    1720 </span><span class="lineCov">         98 :   }</span></a>
<a name="1721"><span class="lineNum">    1721 </span>            : </a>
<a name="1722"><span class="lineNum">    1722 </span><span class="lineCov">         96 :   inferredReturnTypes.push_back(RankedTensorType::get(</span></a>
<a name="1723"><span class="lineNum">    1723 </span><span class="lineCov">         48 :       shape, rankedTy.getElementType(),</span></a>
<a name="1724"><span class="lineNum">    1724 </span><span class="lineCov">         48 :       boundsToEncoding(rankedTy.getEncoding(), resultBounds)));</span></a>
<a name="1725"><span class="lineNum">    1725 </span><span class="lineCov">         48 :   return success();</span></a>
<a name="1726"><span class="lineNum">    1726 </span><span class="lineCov">         68 : }</span></a>
<a name="1727"><span class="lineNum">    1727 </span>            : </a>
<a name="1728"><span class="lineNum">    1728 </span><span class="lineCov">         42 : LogicalResult inferSortOp(</span></a>
<a name="1729"><span class="lineNum">    1729 </span>            :     Optional&lt;Location&gt;, ValueRange inputs,</a>
<a name="1730"><span class="lineNum">    1730 </span><span class="lineCov">         42 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1731"><span class="lineNum">    1731 </span><span class="lineCov">        114 :   for (auto resultType : inputs.getTypes())</span></a>
<a name="1732"><span class="lineNum">    1732 </span><span class="lineCov">         72 :     inferredReturnShapes.emplace_back(resultType.cast&lt;ShapedType&gt;());</span></a>
<a name="1733"><span class="lineNum">    1733 </span><span class="lineCov">         42 :   return success();</span></a>
<a name="1734"><span class="lineNum">    1734 </span>            : }</a>
<a name="1735"><span class="lineNum">    1735 </span>            : </a>
<a name="1736"><span class="lineNum">    1736 </span><span class="lineCov">         79 : LogicalResult inferTransposeOp(Optional&lt;Location&gt; loc, Value operand,</span></a>
<a name="1737"><span class="lineNum">    1737 </span>            :                                DenseIntElementsAttr permutation,</a>
<a name="1738"><span class="lineNum">    1738 </span><span class="lineCov">         79 :                                SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1739"><span class="lineNum">    1739 </span><span class="lineCov">         79 :   auto type = operand.getType();</span></a>
<a name="1740"><span class="lineNum">    1740 </span><span class="lineCov">         79 :   auto rankedTy = type.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1741"><span class="lineNum">    1741 </span><span class="lineCov">         79 :   if (!rankedTy) {</span></a>
<a name="1742"><span class="lineNum">    1742 </span><span class="lineCov">          4 :     inferredReturnTypes.emplace_back(type);</span></a>
<a name="1743"><span class="lineNum">    1743 </span><span class="lineCov">          4 :     return success();</span></a>
<a name="1744"><span class="lineNum">    1744 </span>            :   }</a>
<a name="1745"><span class="lineNum">    1745 </span><span class="lineCov">         75 :   int64_t rank = rankedTy.getRank();</span></a>
<a name="1746"><span class="lineNum">    1746 </span><span class="lineCov">         75 :   if (permutation.getType().getRank() != 1)</span></a>
<a name="1747"><span class="lineNum">    1747 </span><span class="lineCov">          4 :     return emitOptionalError(loc, &quot;TransposeOp permutation has rank &quot;,</span></a>
<a name="1748"><span class="lineNum">    1748 </span><span class="lineCov">          2 :                              permutation.getType().getRank(),</span></a>
<a name="1749"><span class="lineNum">    1749 </span>            :                              &quot; instead of rank 1&quot;);</a>
<a name="1750"><span class="lineNum">    1750 </span>            : </a>
<a name="1751"><span class="lineNum">    1751 </span><span class="lineCov">         73 :   if (permutation.size() != rank)</span></a>
<a name="1752"><span class="lineNum">    1752 </span><span class="lineCov">          4 :     return emitOptionalError(loc, &quot;TransposeOp operand rank &quot;, rank,</span></a>
<a name="1753"><span class="lineNum">    1753 </span>            :                              &quot; does not match permutation size &quot;,</a>
<a name="1754"><span class="lineNum">    1754 </span><span class="lineCov">          2 :                              permutation.size());</span></a>
<a name="1755"><span class="lineNum">    1755 </span>            : </a>
<a name="1756"><span class="lineNum">    1756 </span><span class="lineCov">         71 :   std::vector&lt;int64_t&gt; range(rank);</span></a>
<a name="1757"><span class="lineNum">    1757 </span><span class="lineCov">         71 :   std::iota(range.begin(), range.end(), 0);</span></a>
<a name="1758"><span class="lineNum">    1758 </span><span class="lineCov">         71 :   if (!std::is_permutation(range.begin(), range.end(), permutation.begin()))</span></a>
<a name="1759"><span class="lineNum">    1759 </span><span class="lineCov">          2 :     return emitOptionalError(loc,</span></a>
<a name="1760"><span class="lineNum">    1760 </span>            :                              &quot;attribute permutation must be a permutation&quot;</a>
<a name="1761"><span class="lineNum">    1761 </span>            :                              &quot; of [&quot;,</a>
<a name="1762"><span class="lineNum">    1762 </span>            :                              range, &quot;] but got &quot;, permutation);</a>
<a name="1763"><span class="lineNum">    1763 </span>            : </a>
<a name="1764"><span class="lineNum">    1764 </span><span class="lineCov">         69 :   ArrayRef&lt;int64_t&gt; inputBounds = encodingToBounds(rankedTy.getEncoding());</span></a>
<a name="1765"><span class="lineNum">    1765 </span><span class="lineCov">         69 :   SmallVector&lt;int64_t&gt; resultShape;</span></a>
<a name="1766"><span class="lineNum">    1766 </span><span class="lineCov">         69 :   SmallVector&lt;int64_t&gt; resultBounds;</span></a>
<a name="1767"><span class="lineNum">    1767 </span><span class="lineCov">         69 :   ArrayRef&lt;int64_t&gt; inputShape = rankedTy.getShape();</span></a>
<a name="1768"><span class="lineNum">    1768 </span><span class="lineCov">        289 :   for (int64_t dim : permutation.getValues&lt;int64_t&gt;()) {</span></a>
<a name="1769"><span class="lineNum">    1769 </span><span class="lineCov">        220 :     resultShape.push_back(inputShape[dim]);</span></a>
<a name="1770"><span class="lineNum">    1770 </span><span class="lineCov">        220 :     if (!inputBounds.empty()) {</span></a>
<a name="1771"><span class="lineNum">    1771 </span><span class="lineCov">         32 :       resultBounds.push_back(inputBounds[dim]);</span></a>
<a name="1772"><span class="lineNum">    1772 </span><span class="lineCov">         32 :     }</span></a>
<a name="1773"><span class="lineNum">    1773 </span><span class="lineCov">        220 :   }</span></a>
<a name="1774"><span class="lineNum">    1774 </span>            : </a>
<a name="1775"><span class="lineNum">    1775 </span><span class="lineCov">        138 :   inferredReturnTypes.push_back(RankedTensorType::get(</span></a>
<a name="1776"><span class="lineNum">    1776 </span><span class="lineCov">         69 :       resultShape, rankedTy.getElementType(),</span></a>
<a name="1777"><span class="lineNum">    1777 </span><span class="lineCov">         69 :       boundsToEncoding(rankedTy.getEncoding(), resultBounds)));</span></a>
<a name="1778"><span class="lineNum">    1778 </span><span class="lineCov">         69 :   return success();</span></a>
<a name="1779"><span class="lineNum">    1779 </span><span class="lineCov">         79 : }</span></a>
<a name="1780"><span class="lineNum">    1780 </span>            : </a>
<a name="1781"><span class="lineNum">    1781 </span><span class="lineCov">         77 : LogicalResult inferTriangularSolveOp(</span></a>
<a name="1782"><span class="lineNum">    1782 </span>            :     Optional&lt;Location&gt; location, Value a, Value b, bool leftSide,</a>
<a name="1783"><span class="lineNum">    1783 </span>            :     bool isTransposeAInvalid,</a>
<a name="1784"><span class="lineNum">    1784 </span><span class="lineCov">         77 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="1785"><span class="lineNum">    1785 </span>            :   // ODS enforces that a and b are of same element type: float or complex.</a>
<a name="1786"><span class="lineNum">    1786 </span><span class="lineCov">         77 :   auto elementType = a.getType().cast&lt;ShapedType&gt;().getElementType();</span></a>
<a name="1787"><span class="lineNum">    1787 </span><span class="lineCov">         77 :   auto aType = a.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1788"><span class="lineNum">    1788 </span><span class="lineCov">         77 :   if (!aType) {</span></a>
<a name="1789"><span class="lineNum">    1789 </span><span class="lineCov">          8 :     inferredReturnShapes.emplace_back(elementType);</span></a>
<a name="1790"><span class="lineNum">    1790 </span><span class="lineCov">          8 :     return success();</span></a>
<a name="1791"><span class="lineNum">    1791 </span>            :   }</a>
<a name="1792"><span class="lineNum">    1792 </span>            : </a>
<a name="1793"><span class="lineNum">    1793 </span><span class="lineCov">         69 :   auto aRank = aType.getRank();</span></a>
<a name="1794"><span class="lineNum">    1794 </span><span class="lineCov">         69 :   if (aRank &lt; 2)</span></a>
<a name="1795"><span class="lineNum">    1795 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1796"><span class="lineNum">    1796 </span><span class="lineCov">          2 :         location, &quot;operand 'a' must have rank &gt;= 2, but got &quot;, aType);</span></a>
<a name="1797"><span class="lineNum">    1797 </span>            : </a>
<a name="1798"><span class="lineNum">    1798 </span><span class="lineCov">         67 :   if (aType.getDimSize(aRank - 2) != aType.getDimSize(aRank - 1))</span></a>
<a name="1799"><span class="lineNum">    1799 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="1800"><span class="lineNum">    1800 </span>            :                              &quot;two minor dimensions of operand 'a' must have &quot;</a>
<a name="1801"><span class="lineNum">    1801 </span>            :                              &quot;equal size, but got &quot;,</a>
<a name="1802"><span class="lineNum">    1802 </span>            :                              aType);</a>
<a name="1803"><span class="lineNum">    1803 </span>            : </a>
<a name="1804"><span class="lineNum">    1804 </span><span class="lineCov">         65 :   auto bType = b.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1805"><span class="lineNum">    1805 </span><span class="lineCov">         65 :   if (!bType) {</span></a>
<a name="1806"><span class="lineNum">    1806 </span><span class="lineCov">          4 :     inferredReturnShapes.emplace_back(elementType);</span></a>
<a name="1807"><span class="lineNum">    1807 </span><span class="lineCov">          4 :     return success();</span></a>
<a name="1808"><span class="lineNum">    1808 </span>            :   }</a>
<a name="1809"><span class="lineNum">    1809 </span>            : </a>
<a name="1810"><span class="lineNum">    1810 </span><span class="lineCov">         61 :   auto bRank = bType.getRank();</span></a>
<a name="1811"><span class="lineNum">    1811 </span><span class="lineCov">         61 :   if (aRank != bRank)</span></a>
<a name="1812"><span class="lineNum">    1812 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="1813"><span class="lineNum">    1813 </span>            :                              &quot;operands must have equal rank, but got &quot;, aType,</a>
<a name="1814"><span class="lineNum">    1814 </span>            :                              &quot; and &quot;, bType);</a>
<a name="1815"><span class="lineNum">    1815 </span>            : </a>
<a name="1816"><span class="lineNum">    1816 </span>            :   // The shared dimension of a and b should match.</a>
<a name="1817"><span class="lineNum">    1817 </span><span class="lineCov">        118 :   if (aType.getDimSize(aRank - 1) !=</span></a>
<a name="1818"><span class="lineNum">    1818 </span><span class="lineCov">         59 :       bType.getDimSize(bRank - (leftSide ? 2 : 1)))</span></a>
<a name="1819"><span class="lineNum">    1819 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="1820"><span class="lineNum">    1820 </span>            :                              &quot;shared dimension of operands 'a' and 'b' does &quot;</a>
<a name="1821"><span class="lineNum">    1821 </span>            :                              &quot;not match, but got &quot;,</a>
<a name="1822"><span class="lineNum">    1822 </span>            :                              aType, &quot; and &quot;, bType);</a>
<a name="1823"><span class="lineNum">    1823 </span>            : </a>
<a name="1824"><span class="lineNum">    1824 </span>            :   // The leading batch dimensions of a and b must be equal.</a>
<a name="1825"><span class="lineNum">    1825 </span><span class="lineCov">         57 :   auto aBatchDims = aType.getShape().drop_back(2);</span></a>
<a name="1826"><span class="lineNum">    1826 </span><span class="lineCov">         57 :   auto bBatchDims = bType.getShape().drop_back(2);</span></a>
<a name="1827"><span class="lineNum">    1827 </span><span class="lineCov">         57 :   if (aBatchDims != bBatchDims)</span></a>
<a name="1828"><span class="lineNum">    1828 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1829"><span class="lineNum">    1829 </span><span class="lineCov">          2 :         location,</span></a>
<a name="1830"><span class="lineNum">    1830 </span>            :         &quot;leading batch dimensions of the operands must be same, but got &quot;,</a>
<a name="1831"><span class="lineNum">    1831 </span>            :         aType, &quot; and &quot;, bType);</a>
<a name="1832"><span class="lineNum">    1832 </span>            : </a>
<a name="1833"><span class="lineNum">    1833 </span><span class="lineCov">         55 :   if (isTransposeAInvalid)</span></a>
<a name="1834"><span class="lineNum">    1834 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1835"><span class="lineNum">    1835 </span><span class="lineCov">          2 :         location, &quot;Invalid transpose option value for triangular solve&quot;);</span></a>
<a name="1836"><span class="lineNum">    1836 </span>            : </a>
<a name="1837"><span class="lineNum">    1837 </span><span class="lineCov">         53 :   inferredReturnShapes.emplace_back(bType.cast&lt;ShapedType&gt;());</span></a>
<a name="1838"><span class="lineNum">    1838 </span><span class="lineCov">         53 :   return success();</span></a>
<a name="1839"><span class="lineNum">    1839 </span><span class="lineCov">         77 : }</span></a>
<a name="1840"><span class="lineNum">    1840 </span>            : </a>
<a name="1841"><span class="lineNum">    1841 </span><span class="lineCov">         92 : LogicalResult inferTupleOp(MLIRContext* context, Optional&lt;Location&gt;,</span></a>
<a name="1842"><span class="lineNum">    1842 </span>            :                            ValueRange val,</a>
<a name="1843"><span class="lineNum">    1843 </span><span class="lineCov">         92 :                            SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1844"><span class="lineNum">    1844 </span><span class="lineCov">         92 :   inferredReturnTypes.push_back(TupleType::get(context, val.getTypes()));</span></a>
<a name="1845"><span class="lineNum">    1845 </span><span class="lineCov">         92 :   return success();</span></a>
<a name="1846"><span class="lineNum">    1846 </span>            : }</a>
<a name="1847"><span class="lineNum">    1847 </span>            : </a>
<a name="1848"><span class="lineNum">    1848 </span><span class="lineCov">         32 : LogicalResult inferWhileOp(Optional&lt;Location&gt;, ValueRange operand,</span></a>
<a name="1849"><span class="lineNum">    1849 </span><span class="lineCov">         32 :                            SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="1850"><span class="lineNum">    1850 </span><span class="lineCov">        126 :   for (const auto&amp; resultType : operand.getType())</span></a>
<a name="1851"><span class="lineNum">    1851 </span><span class="lineCov">         94 :     inferredReturnTypes.push_back(resultType);</span></a>
<a name="1852"><span class="lineNum">    1852 </span><span class="lineCov">         32 :   return success();</span></a>
<a name="1853"><span class="lineNum">    1853 </span>            : }</a>
<a name="1854"><span class="lineNum">    1854 </span>            : </a>
<a name="1855"><span class="lineNum">    1855 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="1856"><span class="lineNum">    1856 </span>            : // Verifiers for ops.</a>
<a name="1857"><span class="lineNum">    1857 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="1858"><span class="lineNum">    1858 </span>            : </a>
<a name="1859"><span class="lineNum">    1859 </span><span class="lineCov">         48 : LogicalResult verifyAllReduceOp(Optional&lt;Location&gt; location, Value operand,</span></a>
<a name="1860"><span class="lineNum">    1860 </span>            :                                 DenseIntElementsAttr replicaGroups,</a>
<a name="1861"><span class="lineNum">    1861 </span><span class="lineCov">         48 :                                 bool useGlobalDeviceIds, Region&amp; computation) {</span></a>
<a name="1862"><span class="lineNum">    1862 </span><span class="lineCov">         96 :   if (failed(hlo::verifyReplicaGroups(location, replicaGroups,</span></a>
<a name="1863"><span class="lineNum">    1863 </span>            :                                       /*allGroupsMustHaveSameSize=*/false,</a>
<a name="1864"><span class="lineNum">    1864 </span><span class="lineCov">         48 :                                       useGlobalDeviceIds,</span></a>
<a name="1865"><span class="lineNum">    1865 </span><span class="lineCov">         48 :                                       /*expectedGroupSize=*/std::nullopt)))</span></a>
<a name="1866"><span class="lineNum">    1866 </span><span class="lineCov">          8 :     return failure();</span></a>
<a name="1867"><span class="lineNum">    1867 </span>            : </a>
<a name="1868"><span class="lineNum">    1868 </span><span class="lineCov">         40 :   auto operandType = operand.getType().cast&lt;TensorType&gt;();</span></a>
<a name="1869"><span class="lineNum">    1869 </span><span class="lineCov">         40 :   bool operandTypeRanked = operandType.isa&lt;RankedTensorType&gt;();</span></a>
<a name="1870"><span class="lineNum">    1870 </span><span class="lineCov">         40 :   Block&amp; block = computation.front();</span></a>
<a name="1871"><span class="lineNum">    1871 </span><span class="lineCov">         40 :   if (failed(hlo::verifyReducerShape(</span></a>
<a name="1872"><span class="lineNum">    1872 </span><span class="lineCov">         40 :           location, block, {operandType},</span></a>
<a name="1873"><span class="lineNum">    1873 </span><span class="lineCov">         40 :           {RankedTensorType::get({}, operandType.getElementType())},</span></a>
<a name="1874"><span class="lineNum">    1874 </span><span class="lineCov">         40 :           /*numInputs=*/1, /*allowedDimensions=*/{},</span></a>
<a name="1875"><span class="lineNum">    1875 </span><span class="lineCov">         40 :           /*allInputsUnranked=*/!operandTypeRanked)))</span></a>
<a name="1876"><span class="lineNum">    1876 </span><span class="lineCov">         16 :     return failure();</span></a>
<a name="1877"><span class="lineNum">    1877 </span>            : </a>
<a name="1878"><span class="lineNum">    1878 </span><span class="lineCov">         24 :   return success();</span></a>
<a name="1879"><span class="lineNum">    1879 </span><span class="lineCov">         48 : }</span></a>
<a name="1880"><span class="lineNum">    1880 </span>            : </a>
<a name="1881"><span class="lineNum">    1881 </span>            : /*</a>
<a name="1882"><span class="lineNum">    1882 </span>            :  * We intend to verify the following properties</a>
<a name="1883"><span class="lineNum">    1883 </span>            :  * P1. We cannot convert between complex and real types (cf xla)</a>
<a name="1884"><span class="lineNum">    1884 </span>            :  * P3. The dimensions of the operand and the target</a>
<a name="1885"><span class="lineNum">    1885 </span>            :  * shape must match, except that the shape with the smaller element bitwidth has</a>
<a name="1886"><span class="lineNum">    1886 </span>            :  * an appropriately-sized additional innermost dimension, e.g.</a>
<a name="1887"><span class="lineNum">    1887 </span>            :  * ... x f32 =&gt; [bitcast_convert] =&gt; ... x 4 x i8</a>
<a name="1888"><span class="lineNum">    1888 </span>            :  * ... x 4 x i8 =&gt; [bitcast_convert] =&gt; ... x f32</a>
<a name="1889"><span class="lineNum">    1889 </span>            :  */</a>
<a name="1890"><span class="lineNum">    1890 </span><span class="lineCov">         56 : LogicalResult verifyBitcastConvertOp(Optional&lt;Location&gt; location, Value operand,</span></a>
<a name="1891"><span class="lineNum">    1891 </span><span class="lineCov">         56 :                                      Value result) {</span></a>
<a name="1892"><span class="lineNum">    1892 </span><span class="lineCov">         56 :   auto operandTensorType = operand.getType().cast&lt;TensorType&gt;();</span></a>
<a name="1893"><span class="lineNum">    1893 </span><span class="lineCov">         56 :   auto targetTensorType = result.getType().cast&lt;TensorType&gt;();</span></a>
<a name="1894"><span class="lineNum">    1894 </span>            : </a>
<a name="1895"><span class="lineNum">    1895 </span>            :   // P1.</a>
<a name="1896"><span class="lineNum">    1896 </span><span class="lineCov">         56 :   auto targetElt = targetTensorType.getElementType();</span></a>
<a name="1897"><span class="lineNum">    1897 </span><span class="lineCov">         56 :   auto operandElt = operandTensorType.getElementType();</span></a>
<a name="1898"><span class="lineNum">    1898 </span><span class="lineCov">         56 :   if (targetElt.isa&lt;ComplexType&gt;() != operandElt.isa&lt;ComplexType&gt;()) {</span></a>
<a name="1899"><span class="lineNum">    1899 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="1900"><span class="lineNum">    1900 </span><span class="lineCov">          2 :         location, &quot;cannot convert between real and complex types, but got: &quot;,</span></a>
<a name="1901"><span class="lineNum">    1901 </span>            :         operandTensorType, &quot; and &quot;, targetTensorType);</a>
<a name="1902"><span class="lineNum">    1902 </span>            :   }</a>
<a name="1903"><span class="lineNum">    1903 </span>            : </a>
<a name="1904"><span class="lineNum">    1904 </span><span class="lineCov">         54 :   auto targetEltBitwidth = hlo::potentiallyComplexBitwidth(targetElt);</span></a>
<a name="1905"><span class="lineNum">    1905 </span><span class="lineCov">         54 :   auto operandEltBitwidth = hlo::potentiallyComplexBitwidth(operandElt);</span></a>
<a name="1906"><span class="lineNum">    1906 </span>            : </a>
<a name="1907"><span class="lineNum">    1907 </span>            :   // P2.</a>
<a name="1908"><span class="lineNum">    1908 </span><span class="lineCov">         54 :   auto operandType = operandTensorType.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1909"><span class="lineNum">    1909 </span><span class="lineCov">         54 :   auto targetType = targetTensorType.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1910"><span class="lineNum">    1910 </span><span class="lineCov">         54 :   if (!operandType || !targetType) return success();</span></a>
<a name="1911"><span class="lineNum">    1911 </span>            : </a>
<a name="1912"><span class="lineNum">    1912 </span><span class="lineCov">         50 :   auto targetShape = targetType.getShape();</span></a>
<a name="1913"><span class="lineNum">    1913 </span><span class="lineCov">         50 :   auto operandShape = operandType.getShape();</span></a>
<a name="1914"><span class="lineNum">    1914 </span><span class="lineCov">         50 :   ArrayRef&lt;int64_t&gt; smallerEltShape, biggerEltShape;</span></a>
<a name="1915"><span class="lineNum">    1915 </span><span class="lineCov">         50 :   Type smallerElt, biggerElt;</span></a>
<a name="1916"><span class="lineNum">    1916 </span><span class="lineCov">         50 :   if (operandEltBitwidth &lt; targetEltBitwidth) {</span></a>
<a name="1917"><span class="lineNum">    1917 </span><span class="lineCov">         10 :     smallerEltShape = operandShape;</span></a>
<a name="1918"><span class="lineNum">    1918 </span><span class="lineCov">         10 :     smallerElt = operandElt;</span></a>
<a name="1919"><span class="lineNum">    1919 </span><span class="lineCov">         10 :     biggerEltShape = targetShape;</span></a>
<a name="1920"><span class="lineNum">    1920 </span><span class="lineCov">         10 :     biggerElt = targetElt;</span></a>
<a name="1921"><span class="lineNum">    1921 </span><span class="lineCov">         10 :   } else {</span></a>
<a name="1922"><span class="lineNum">    1922 </span><span class="lineCov">         40 :     smallerEltShape = targetShape;</span></a>
<a name="1923"><span class="lineNum">    1923 </span><span class="lineCov">         40 :     smallerElt = targetElt;</span></a>
<a name="1924"><span class="lineNum">    1924 </span><span class="lineCov">         40 :     biggerEltShape = operandShape;</span></a>
<a name="1925"><span class="lineNum">    1925 </span><span class="lineCov">         40 :     biggerElt = operandElt;</span></a>
<a name="1926"><span class="lineNum">    1926 </span>            :   }</a>
<a name="1927"><span class="lineNum">    1927 </span>            : </a>
<a name="1928"><span class="lineNum">    1928 </span><span class="lineCov">         50 :   ArrayRef&lt;int64_t&gt; smallerEltPrefix;</span></a>
<a name="1929"><span class="lineNum">    1929 </span><span class="lineCov">         50 :   auto smallerEltBitwidth = std::min(targetEltBitwidth, operandEltBitwidth);</span></a>
<a name="1930"><span class="lineNum">    1930 </span><span class="lineCov">         50 :   auto biggerEltBitwidth = std::max(targetEltBitwidth, operandEltBitwidth);</span></a>
<a name="1931"><span class="lineNum">    1931 </span><span class="lineCov">         50 :   if (operandEltBitwidth != targetEltBitwidth) {</span></a>
<a name="1932"><span class="lineNum">    1932 </span><span class="lineCov">         24 :     if (smallerEltShape.empty()) {</span></a>
<a name="1933"><span class="lineNum">    1933 </span><span class="lineCov">          8 :       return emitOptionalError(location,</span></a>
<a name="1934"><span class="lineNum">    1934 </span>            :                                &quot;does not allow the smaller element type to be &quot;</a>
<a name="1935"><span class="lineNum">    1935 </span>            :                                &quot;part of a 0d tensor, but got: &quot;,</a>
<a name="1936"><span class="lineNum">    1936 </span>            :                                operandType, &quot; and &quot;, targetType, &quot;.&quot;);</a>
<a name="1937"><span class="lineNum">    1937 </span>            :     }</a>
<a name="1938"><span class="lineNum">    1938 </span><span class="lineCov">         16 :     smallerEltPrefix = smallerEltShape.drop_back();</span></a>
<a name="1939"><span class="lineNum">    1939 </span><span class="lineCov">         16 :     if (!hlo::isDynamicDimSize(smallerEltShape.back()) &amp;&amp;</span></a>
<a name="1940"><span class="lineNum">    1940 </span><span class="lineCov">         16 :         smallerEltShape.back() * smallerEltBitwidth != biggerEltBitwidth) {</span></a>
<a name="1941"><span class="lineNum">    1941 </span><span class="lineCov">          4 :       return emitOptionalError(</span></a>
<a name="1942"><span class="lineNum">    1942 </span><span class="lineCov">          4 :           location, &quot;requires compatible bitwidths. &quot;, &quot;Got: &quot;, operandType,</span></a>
<a name="1943"><span class="lineNum">    1943 </span>            :           &quot; and &quot;, targetType, &quot;, but &quot;, smallerEltBitwidth, &quot; * &quot;,</a>
<a name="1944"><span class="lineNum">    1944 </span><span class="lineCov">          4 :           smallerEltShape.back(), &quot; != &quot;, biggerEltBitwidth, &quot;.&quot;);</span></a>
<a name="1945"><span class="lineNum">    1945 </span>            :     }</a>
<a name="1946"><span class="lineNum">    1946 </span><span class="lineCov">         12 :   } else {</span></a>
<a name="1947"><span class="lineNum">    1947 </span><span class="lineCov">         26 :     smallerEltPrefix = smallerEltShape;</span></a>
<a name="1948"><span class="lineNum">    1948 </span>            :   }</a>
<a name="1949"><span class="lineNum">    1949 </span>            : </a>
<a name="1950"><span class="lineNum">    1950 </span><span class="lineCov">         60 :   for (auto it : llvm::zip(smallerEltPrefix, biggerEltShape)) {</span></a>
<a name="1951"><span class="lineNum">    1951 </span><span class="lineCov">         22 :     auto targetDim = std::get&lt;0&gt;(it);</span></a>
<a name="1952"><span class="lineNum">    1952 </span><span class="lineCov">         22 :     auto operandDim = std::get&lt;1&gt;(it);</span></a>
<a name="1953"><span class="lineNum">    1953 </span><span class="lineCov">         22 :     if (!hlo::isDynamicDimSize(targetDim) &amp;&amp;</span></a>
<a name="1954"><span class="lineNum">    1954 </span><span class="lineCov">         22 :         !hlo::isDynamicDimSize(operandDim)) {</span></a>
<a name="1955"><span class="lineNum">    1955 </span><span class="lineCov">         22 :       if (targetDim != operandDim) {</span></a>
<a name="1956"><span class="lineNum">    1956 </span><span class="lineCov">          2 :         return emitOptionalError(</span></a>
<a name="1957"><span class="lineNum">    1957 </span><span class="lineCov">          2 :             location,</span></a>
<a name="1958"><span class="lineNum">    1958 </span>            :             &quot;operand and result shapes must match except &quot;</a>
<a name="1959"><span class="lineNum">    1959 </span>            :             &quot;for the innermost dimension of the shape with &quot;</a>
<a name="1960"><span class="lineNum">    1960 </span>            :             &quot;the smaller element type. Got: &quot;,</a>
<a name="1961"><span class="lineNum">    1961 </span>            :             operandType, &quot; and &quot;, targetType, &quot;.&quot;);</a>
<a name="1962"><span class="lineNum">    1962 </span>            :       }</a>
<a name="1963"><span class="lineNum">    1963 </span><span class="lineCov">         20 :     }</span></a>
<a name="1964"><span class="lineNum">    1964 </span><span class="lineCov">         22 :   }</span></a>
<a name="1965"><span class="lineNum">    1965 </span>            : </a>
<a name="1966"><span class="lineNum">    1966 </span><span class="lineCov">         36 :   return success();</span></a>
<a name="1967"><span class="lineNum">    1967 </span><span class="lineCov">         56 : }</span></a>
<a name="1968"><span class="lineNum">    1968 </span>            : </a>
<a name="1969"><span class="lineNum">    1969 </span><span class="lineCov">         62 : LogicalResult verifyBroadcastInDimOp(Optional&lt;Location&gt; location, Value operand,</span></a>
<a name="1970"><span class="lineNum">    1970 </span>            :                                      DenseIntElementsAttr broadcastDimensions,</a>
<a name="1971"><span class="lineNum">    1971 </span><span class="lineCov">         62 :                                      Value result) {</span></a>
<a name="1972"><span class="lineNum">    1972 </span><span class="lineCov">         62 :   auto operandType = operand.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="1973"><span class="lineNum">    1973 </span><span class="lineCov">         62 :   if (!operandType) {</span></a>
<a name="1974"><span class="lineNum">    1974 </span>            :     // The following verification checks all depend on knowing the rank of</a>
<a name="1975"><span class="lineNum">    1975 </span>            :     // the operand. Bail out now if we don't know the rank of the operand.</a>
<a name="1976"><span class="lineNum">    1976 </span><span class="lineCov">          4 :     return success();</span></a>
<a name="1977"><span class="lineNum">    1977 </span>            :   }</a>
<a name="1978"><span class="lineNum">    1978 </span>            : </a>
<a name="1979"><span class="lineNum">    1979 </span><span class="lineCov">         58 :   auto operandRank = operandType.getRank();</span></a>
<a name="1980"><span class="lineNum">    1980 </span><span class="lineCov">         58 :   if (!broadcastDimensions) {</span></a>
<a name="1981"><span class="lineNum">    1981 </span><span class="lineNoCov">          0 :     if (operandRank == 0) return success();</span></a>
<a name="1982"><span class="lineNum">    1982 </span><span class="lineNoCov">          0 :     return emitOptionalError(location,</span></a>
<a name="1983"><span class="lineNum">    1983 </span>            :                              &quot;broadcast_dimensions is absent, but required &quot;</a>
<a name="1984"><span class="lineNum">    1984 </span>            :                              &quot;because operand has non-zero rank (&quot;,</a>
<a name="1985"><span class="lineNum">    1985 </span>            :                              operandRank, &quot;)&quot;);</a>
<a name="1986"><span class="lineNum">    1986 </span>            :   }</a>
<a name="1987"><span class="lineNum">    1987 </span>            : </a>
<a name="1988"><span class="lineNum">    1988 </span><span class="lineCov">         58 :   auto dimensionsType = broadcastDimensions.getType();</span></a>
<a name="1989"><span class="lineNum">    1989 </span><span class="lineCov">         58 :   auto dimensionsRank = dimensionsType.getRank();</span></a>
<a name="1990"><span class="lineNum">    1990 </span><span class="lineCov">         58 :   if (dimensionsRank != 1)</span></a>
<a name="1991"><span class="lineNum">    1991 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;broadcast_dimensions has rank &quot;,</span></a>
<a name="1992"><span class="lineNum">    1992 </span>            :                              dimensionsRank, &quot; instead of rank 1&quot;);</a>
<a name="1993"><span class="lineNum">    1993 </span>            : </a>
<a name="1994"><span class="lineNum">    1994 </span><span class="lineCov">         56 :   auto dimensionsSize = dimensionsType.getNumElements();</span></a>
<a name="1995"><span class="lineNum">    1995 </span><span class="lineCov">         56 :   if (dimensionsSize != operandRank)</span></a>
<a name="1996"><span class="lineNum">    1996 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;broadcast_dimensions size (&quot;,</span></a>
<a name="1997"><span class="lineNum">    1997 </span>            :                              dimensionsSize, &quot;) does not match operand rank (&quot;,</a>
<a name="1998"><span class="lineNum">    1998 </span>            :                              operandRank, &quot;)&quot;);</a>
<a name="1999"><span class="lineNum">    1999 </span>            : </a>
<a name="2000"><span class="lineNum">    2000 </span><span class="lineCov">         54 :   auto dimensions = llvm::to_vector(broadcastDimensions.getValues&lt;int64_t&gt;());</span></a>
<a name="2001"><span class="lineNum">    2001 </span><span class="lineCov">         54 :   if (hasDuplicates(dimensions))</span></a>
<a name="2002"><span class="lineNum">    2002 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="2003"><span class="lineNum">    2003 </span>            :                              &quot;broadcast_dimensions should not have duplicates&quot;);</a>
<a name="2004"><span class="lineNum">    2004 </span>            : </a>
<a name="2005"><span class="lineNum">    2005 </span><span class="lineCov">         52 :   auto resultType = result.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="2006"><span class="lineNum">    2006 </span><span class="lineCov">         52 :   auto resultRank = resultType.getRank();</span></a>
<a name="2007"><span class="lineNum">    2007 </span><span class="lineCov">        114 :   for (int i = 0; i != dimensionsSize; ++i) {</span></a>
<a name="2008"><span class="lineNum">    2008 </span><span class="lineCov">         62 :     auto dimIndex = dimensions[i];</span></a>
<a name="2009"><span class="lineNum">    2009 </span><span class="lineCov">         62 :     if (dimIndex &gt;= resultRank)</span></a>
<a name="2010"><span class="lineNum">    2010 </span><span class="lineCov">          4 :       return emitOptionalError(location,</span></a>
<a name="2011"><span class="lineNum">    2011 </span>            :                                &quot;broadcast_dimensions contains invalid value &quot;,</a>
<a name="2012"><span class="lineNum">    2012 </span>            :                                dimIndex, &quot; for result with rank &quot;, resultRank);</a>
<a name="2013"><span class="lineNum">    2013 </span>            : </a>
<a name="2014"><span class="lineNum">    2014 </span><span class="lineCov">         58 :     if (!operandType.isDynamicDim(i)) {</span></a>
<a name="2015"><span class="lineNum">    2015 </span><span class="lineCov">         54 :       auto dimSize = operandType.getDimSize(i);</span></a>
<a name="2016"><span class="lineNum">    2016 </span><span class="lineCov">         54 :       auto resultDimSize = resultType.getDimSize(dimIndex);</span></a>
<a name="2017"><span class="lineNum">    2017 </span><span class="lineCov">         54 :       if (dimSize != 1 &amp;&amp; dimSize != resultDimSize)</span></a>
<a name="2018"><span class="lineNum">    2018 </span><span class="lineCov">          2 :         return emitOptionalError(</span></a>
<a name="2019"><span class="lineNum">    2019 </span><span class="lineCov">          2 :             location, &quot;size of operand dimension &quot;, i, &quot; (&quot;, dimSize,</span></a>
<a name="2020"><span class="lineNum">    2020 </span>            :             &quot;) is not equal to 1 or size of result dimension &quot;, dimIndex, &quot; (&quot;,</a>
<a name="2021"><span class="lineNum">    2021 </span>            :             resultDimSize, &quot;)&quot;);</a>
<a name="2022"><span class="lineNum">    2022 </span><span class="lineCov">         54 :     }</span></a>
<a name="2023"><span class="lineNum">    2023 </span><span class="lineCov">         62 :   }</span></a>
<a name="2024"><span class="lineNum">    2024 </span>            : </a>
<a name="2025"><span class="lineNum">    2025 </span><span class="lineCov">         46 :   return success();</span></a>
<a name="2026"><span class="lineNum">    2026 </span><span class="lineCov">         62 : }</span></a>
<a name="2027"><span class="lineNum">    2027 </span>            : </a>
<a name="2028"><span class="lineNum">    2028 </span><span class="lineCov">         33 : LogicalResult verifyCollectivePermuteOp(</span></a>
<a name="2029"><span class="lineNum">    2029 </span><span class="lineCov">         33 :     Optional&lt;Location&gt; location, DenseIntElementsAttr sourceTargetPairs) {</span></a>
<a name="2030"><span class="lineNum">    2030 </span>            :   // Verifies the source target pairs attached to collective permute.</a>
<a name="2031"><span class="lineNum">    2031 </span><span class="lineCov">         33 :   auto type = sourceTargetPairs.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="2032"><span class="lineNum">    2032 </span><span class="lineCov">         33 :   if (type.getRank() != 2)</span></a>
<a name="2033"><span class="lineNum">    2033 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="2034"><span class="lineNum">    2034 </span>            :                              &quot;expect source_target_pairs attribute to be of &quot;</a>
<a name="2035"><span class="lineNum">    2035 </span>            :                              &quot;rank 2, but got rank &quot;,</a>
<a name="2036"><span class="lineNum">    2036 </span><span class="lineCov">          2 :                              type.getRank());</span></a>
<a name="2037"><span class="lineNum">    2037 </span><span class="lineCov">         31 :   if (type.getShape()[1] != 2)</span></a>
<a name="2038"><span class="lineNum">    2038 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="2039"><span class="lineNum">    2039 </span><span class="lineCov">          2 :         location,</span></a>
<a name="2040"><span class="lineNum">    2040 </span>            :         &quot;expect source_target_pairs attribute of shape (N, 2), but got (&quot;,</a>
<a name="2041"><span class="lineNum">    2041 </span><span class="lineCov">          2 :         type.getShape(), &quot;)&quot;);</span></a>
<a name="2042"><span class="lineNum">    2042 </span>            :   // Check source target pairs for duplicate sources or targets.</a>
<a name="2043"><span class="lineNum">    2043 </span><span class="lineCov">         29 :   llvm::DenseSet&lt;int64_t&gt; sources;</span></a>
<a name="2044"><span class="lineNum">    2044 </span><span class="lineCov">         29 :   llvm::DenseSet&lt;int64_t&gt; targets;</span></a>
<a name="2045"><span class="lineNum">    2045 </span><span class="lineCov">        196 :   for (auto i = sourceTargetPairs.begin(), e = sourceTargetPairs.end(); i != e;</span></a>
<a name="2046"><span class="lineNum">    2046 </span><span class="lineCov">        162 :        ++i) {</span></a>
<a name="2047"><span class="lineNum">    2047 </span><span class="lineCov">        167 :     auto val = (*i).getSExtValue();</span></a>
<a name="2048"><span class="lineNum">    2048 </span><span class="lineCov">        167 :     if (val &lt; 0)</span></a>
<a name="2049"><span class="lineNum">    2049 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="2050"><span class="lineNum">    2050 </span><span class="lineCov">          2 :           location, &quot;replica ids in source_target_pairs must be &gt;= 0.&quot;);</span></a>
<a name="2051"><span class="lineNum">    2051 </span>            : </a>
<a name="2052"><span class="lineNum">    2052 </span><span class="lineCov">        165 :     if (i.getIndex() % 2 == 0) {</span></a>
<a name="2053"><span class="lineNum">    2053 </span><span class="lineCov">         84 :       bool isUnique = sources.insert(val).second;</span></a>
<a name="2054"><span class="lineNum">    2054 </span><span class="lineCov">         84 :       if (!isUnique)</span></a>
<a name="2055"><span class="lineNum">    2055 </span><span class="lineCov">          2 :         return emitOptionalError(location, &quot;duplicate sources not allowed.&quot;);</span></a>
<a name="2056"><span class="lineNum">    2056 </span><span class="lineCov">         84 :     } else {</span></a>
<a name="2057"><span class="lineNum">    2057 </span><span class="lineCov">         81 :       bool isUnique = targets.insert(val).second;</span></a>
<a name="2058"><span class="lineNum">    2058 </span><span class="lineCov">         81 :       if (!isUnique)</span></a>
<a name="2059"><span class="lineNum">    2059 </span><span class="lineCov">          2 :         return emitOptionalError(location, &quot;duplicate targets not allowed.&quot;);</span></a>
<a name="2060"><span class="lineNum">    2060 </span><span class="lineCov">         81 :     }</span></a>
<a name="2061"><span class="lineNum">    2061 </span><span class="lineCov">        167 :   }</span></a>
<a name="2062"><span class="lineNum">    2062 </span><span class="lineCov">         24 :   return success();</span></a>
<a name="2063"><span class="lineNum">    2063 </span><span class="lineCov">         33 : }</span></a>
<a name="2064"><span class="lineNum">    2064 </span>            : </a>
<a name="2065"><span class="lineNum">    2065 </span><span class="lineCov">         22 : LogicalResult verifyDynamicBroadcastInDimOp(</span></a>
<a name="2066"><span class="lineNum">    2066 </span>            :     Optional&lt;Location&gt; location, Value operand, Value outputDimensions,</a>
<a name="2067"><span class="lineNum">    2067 </span>            :     DenseIntElementsAttr broadcastDimensions,</a>
<a name="2068"><span class="lineNum">    2068 </span>            :     Optional&lt;DenseIntElementsAttr&gt; knownExpandingDimensions,</a>
<a name="2069"><span class="lineNum">    2069 </span><span class="lineCov">         22 :     Optional&lt;DenseIntElementsAttr&gt; knownNonexpandingDimensions, Value result) {</span></a>
<a name="2070"><span class="lineNum">    2070 </span><span class="lineCov">         22 :   auto operandType = operand.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="2071"><span class="lineNum">    2071 </span><span class="lineCov">         22 :   auto resultType = result.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="2072"><span class="lineNum">    2072 </span>            : </a>
<a name="2073"><span class="lineNum">    2073 </span>            :   // If either the operand or result are unranked, there is very little</a>
<a name="2074"><span class="lineNum">    2074 </span>            :   // to verify statically.</a>
<a name="2075"><span class="lineNum">    2075 </span><span class="lineCov">         22 :   if (!operandType || !resultType) return success();</span></a>
<a name="2076"><span class="lineNum">    2076 </span>            : </a>
<a name="2077"><span class="lineNum">    2077 </span><span class="lineCov">         22 :   auto outputDimensionsType =</span></a>
<a name="2078"><span class="lineNum">    2078 </span><span class="lineCov">         22 :       outputDimensions.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="2079"><span class="lineNum">    2079 </span><span class="lineCov">         22 :   auto outputDimensionsSize = outputDimensionsType.getDimSize(0);</span></a>
<a name="2080"><span class="lineNum">    2080 </span><span class="lineCov">         22 :   auto operandRank = operandType.getRank();</span></a>
<a name="2081"><span class="lineNum">    2081 </span><span class="lineCov">         22 :   auto resultRank = resultType.getRank();</span></a>
<a name="2082"><span class="lineNum">    2082 </span>            : </a>
<a name="2083"><span class="lineNum">    2083 </span>            :   // Verify broadcast_dimensions.</a>
<a name="2084"><span class="lineNum">    2084 </span><span class="lineCov">         22 :   auto bcastDimensions = broadcastDimensions;</span></a>
<a name="2085"><span class="lineNum">    2085 </span><span class="lineCov">         22 :   auto bcastDimensionsType = broadcastDimensions.getType();</span></a>
<a name="2086"><span class="lineNum">    2086 </span><span class="lineCov">         22 :   auto bcastDimensionsRank = bcastDimensionsType.getRank();</span></a>
<a name="2087"><span class="lineNum">    2087 </span>            :   // TODO(laurenzo): Update the BroadcastDimAttr to constrain its rank to 1.</a>
<a name="2088"><span class="lineNum">    2088 </span><span class="lineCov">         22 :   if (bcastDimensionsRank != 1)</span></a>
<a name="2089"><span class="lineNum">    2089 </span><span class="lineNoCov">          0 :     return emitOptionalError(location, &quot;broadcast_dimensions has rank &quot;,</span></a>
<a name="2090"><span class="lineNum">    2090 </span>            :                              bcastDimensionsRank, &quot; instead of rank 1&quot;);</a>
<a name="2091"><span class="lineNum">    2091 </span>            : </a>
<a name="2092"><span class="lineNum">    2092 </span><span class="lineCov">         22 :   auto bcastDimensionsSize = bcastDimensionsType.getNumElements();</span></a>
<a name="2093"><span class="lineNum">    2093 </span><span class="lineCov">         22 :   if (bcastDimensionsSize != operandRank)</span></a>
<a name="2094"><span class="lineNum">    2094 </span><span class="lineNoCov">          0 :     return emitOptionalError(</span></a>
<a name="2095"><span class="lineNum">    2095 </span><span class="lineNoCov">          0 :         location, &quot;broadcast_dimensions size (&quot;, bcastDimensionsSize,</span></a>
<a name="2096"><span class="lineNum">    2096 </span>            :         &quot;) does not match operand rank (&quot;, operandRank, &quot;)&quot;);</a>
<a name="2097"><span class="lineNum">    2097 </span>            : </a>
<a name="2098"><span class="lineNum">    2098 </span><span class="lineCov">         22 :   if (resultRank &lt; operandRank)</span></a>
<a name="2099"><span class="lineNum">    2099 </span><span class="lineNoCov">          0 :     return emitOptionalError(location, &quot;result rank (&quot;, resultRank,</span></a>
<a name="2100"><span class="lineNum">    2100 </span>            :                              &quot;) is less than operand rank (&quot;, operandRank, &quot;)&quot;);</a>
<a name="2101"><span class="lineNum">    2101 </span>            : </a>
<a name="2102"><span class="lineNum">    2102 </span><span class="lineCov">         48 :   for (int i = 0; i != bcastDimensionsSize; ++i) {</span></a>
<a name="2103"><span class="lineNum">    2103 </span><span class="lineCov">         26 :     auto dimIndex = bcastDimensions.getValues&lt;int64_t&gt;()[i];</span></a>
<a name="2104"><span class="lineNum">    2104 </span><span class="lineCov">         26 :     if (dimIndex &gt;= resultRank)</span></a>
<a name="2105"><span class="lineNum">    2105 </span><span class="lineNoCov">          0 :       return emitOptionalError(location,</span></a>
<a name="2106"><span class="lineNum">    2106 </span>            :                                &quot;broadcast_dimensions contains invalid value &quot;,</a>
<a name="2107"><span class="lineNum">    2107 </span>            :                                dimIndex, &quot; for result with rank &quot;, resultRank);</a>
<a name="2108"><span class="lineNum">    2108 </span>            : </a>
<a name="2109"><span class="lineNum">    2109 </span><span class="lineCov">         26 :     auto dimSize = operandType.getDimSize(i);</span></a>
<a name="2110"><span class="lineNum">    2110 </span><span class="lineCov">         26 :     auto resultDimSize = resultType.getDimSize(dimIndex);</span></a>
<a name="2111"><span class="lineNum">    2111 </span>            :     // Note: verifyCompatibleShapes doesn't consider size-1 broadcasting, so</a>
<a name="2112"><span class="lineNum">    2112 </span>            :     // we add a manual check for this.</a>
<a name="2113"><span class="lineNum">    2113 </span><span class="lineCov">         26 :     if (dimSize != 1 &amp;&amp; failed(verifyCompatibleShape(dimSize, resultDimSize)))</span></a>
<a name="2114"><span class="lineNum">    2114 </span><span class="lineCov">          2 :       return emitOptionalError(location, &quot;size of operand dimension &quot;, i, &quot; (&quot;,</span></a>
<a name="2115"><span class="lineNum">    2115 </span>            :                                dimSize,</a>
<a name="2116"><span class="lineNum">    2116 </span>            :                                &quot;) is not compatible &quot;</a>
<a name="2117"><span class="lineNum">    2117 </span>            :                                &quot;with size of result dimension &quot;,</a>
<a name="2118"><span class="lineNum">    2118 </span>            :                                dimIndex, &quot; (&quot;, resultDimSize, &quot;)&quot;);</a>
<a name="2119"><span class="lineNum">    2119 </span><span class="lineCov">         26 :   }</span></a>
<a name="2120"><span class="lineNum">    2120 </span>            : </a>
<a name="2121"><span class="lineNum">    2121 </span><span class="lineCov">         20 :   if (outputDimensionsSize != resultRank)</span></a>
<a name="2122"><span class="lineNum">    2122 </span><span class="lineNoCov">          0 :     return emitOptionalError(location, &quot;result rank (&quot;, resultRank,</span></a>
<a name="2123"><span class="lineNum">    2123 </span>            :                              &quot;) is not equal to number of output dimensions (&quot;,</a>
<a name="2124"><span class="lineNum">    2124 </span>            :                              outputDimensionsSize, &quot;)&quot;);</a>
<a name="2125"><span class="lineNum">    2125 </span>            : </a>
<a name="2126"><span class="lineNum">    2126 </span>            :   // Verify that the known expanding and non-expanding dimensions are a subset</a>
<a name="2127"><span class="lineNum">    2127 </span>            :   // of the operand's dimensions.</a>
<a name="2128"><span class="lineNum">    2128 </span><span class="lineCov">         20 :   int64_t numKnownExpansionBehavior = 0;</span></a>
<a name="2129"><span class="lineNum">    2129 </span><span class="lineCov">         20 :   DenseSet&lt;int64_t&gt; knownExpansionBehavior;</span></a>
<a name="2130"><span class="lineNum">    2130 </span><span class="lineCov">         20 :   auto collectExpansionBehaviorDims =</span></a>
<a name="2131"><span class="lineNum">    2131 </span><span class="lineCov">         60 :       [&amp;](const Optional&lt;DenseIntElementsAttr&gt;&amp; attr) {</span></a>
<a name="2132"><span class="lineNum">    2132 </span><span class="lineCov">         40 :         if (!attr) return;</span></a>
<a name="2133"><span class="lineNum">    2133 </span><span class="lineCov">         24 :         for (const APInt&amp; it : *attr) {</span></a>
<a name="2134"><span class="lineNum">    2134 </span><span class="lineCov">          8 :           numKnownExpansionBehavior++;</span></a>
<a name="2135"><span class="lineNum">    2135 </span><span class="lineCov">          8 :           knownExpansionBehavior.insert(it.getLimitedValue());</span></a>
<a name="2136"><span class="lineNum">    2136 </span><span class="lineCov">          8 :         }</span></a>
<a name="2137"><span class="lineNum">    2137 </span><span class="lineCov">         40 :       };</span></a>
<a name="2138"><span class="lineNum">    2138 </span><span class="lineCov">         20 :   collectExpansionBehaviorDims(knownExpandingDimensions);</span></a>
<a name="2139"><span class="lineNum">    2139 </span><span class="lineCov">         20 :   collectExpansionBehaviorDims(knownNonexpandingDimensions);</span></a>
<a name="2140"><span class="lineNum">    2140 </span><span class="lineCov">         20 :   if (knownExpansionBehavior.size() != numKnownExpansionBehavior)</span></a>
<a name="2141"><span class="lineNum">    2141 </span><span class="lineNoCov">          0 :     return emitOptionalError(</span></a>
<a name="2142"><span class="lineNum">    2142 </span><span class="lineNoCov">          0 :         location,</span></a>
<a name="2143"><span class="lineNum">    2143 </span>            :         &quot;duplicate expansion hint for at least one operand dimension&quot;);</a>
<a name="2144"><span class="lineNum">    2144 </span><span class="lineCov">         28 :   for (int64_t i : knownExpansionBehavior)</span></a>
<a name="2145"><span class="lineNum">    2145 </span><span class="lineCov">          8 :     if (i &lt; 0 || i &gt;= operandRank)</span></a>
<a name="2146"><span class="lineNum">    2146 </span><span class="lineNoCov">          0 :       return emitOptionalError(location, &quot;hint for expanding dimension &quot;, i,</span></a>
<a name="2147"><span class="lineNum">    2147 </span>            :                                &quot; does not refer to a &quot;</a>
<a name="2148"><span class="lineNum">    2148 </span><span class="lineCov">          8 :                                &quot;valid operand dimension&quot;);</span></a>
<a name="2149"><span class="lineNum">    2149 </span>            : </a>
<a name="2150"><span class="lineNum">    2150 </span><span class="lineCov">         20 :   return success();</span></a>
<a name="2151"><span class="lineNum">    2151 </span><span class="lineCov">         22 : }</span></a>
<a name="2152"><span class="lineNum">    2152 </span>            : </a>
<a name="2153"><span class="lineNum">    2153 </span><span class="lineCov">         14 : LogicalResult verifyDynamicReshapeOp(Optional&lt;Location&gt; location,</span></a>
<a name="2154"><span class="lineNum">    2154 </span><span class="lineCov">         14 :                                      Value outputShape, Value result) {</span></a>
<a name="2155"><span class="lineNum">    2155 </span><span class="lineCov">         14 :   auto resultType = result.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="2156"><span class="lineNum">    2156 </span><span class="lineCov">         14 :   auto outputShapeType = outputShape.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="2157"><span class="lineNum">    2157 </span><span class="lineCov">         14 :   if (resultType &amp;&amp; outputShapeType &amp;&amp; outputShapeType.hasStaticShape() &amp;&amp;</span></a>
<a name="2158"><span class="lineNum">    2158 </span><span class="lineCov">          6 :       outputShapeType.getDimSize(0) != resultType.getRank()) {</span></a>
<a name="2159"><span class="lineNum">    2159 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="2160"><span class="lineNum">    2160 </span>            :                              &quot;output should have a rank equal to the number of &quot;</a>
<a name="2161"><span class="lineNum">    2161 </span>            :                              &quot;elements in output_shape&quot;);</a>
<a name="2162"><span class="lineNum">    2162 </span>            :   }</a>
<a name="2163"><span class="lineNum">    2163 </span><span class="lineCov">         12 :   return success();</span></a>
<a name="2164"><span class="lineNum">    2164 </span><span class="lineCov">         14 : }</span></a>
<a name="2165"><span class="lineNum">    2165 </span>            : </a>
<a name="2166"><span class="lineNum">    2166 </span><span class="lineCov">        124 : LogicalResult verifyIotaOp(Optional&lt;Location&gt; location, int64_t iotaDimension,</span></a>
<a name="2167"><span class="lineNum">    2167 </span><span class="lineCov">        124 :                            Value result) {</span></a>
<a name="2168"><span class="lineNum">    2168 </span><span class="lineCov">        124 :   auto shape = result.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="2169"><span class="lineNum">    2169 </span><span class="lineCov">        124 :   if (!shape.hasRank()) return success();</span></a>
<a name="2170"><span class="lineNum">    2170 </span><span class="lineCov">        124 :   if (shape.getRank() == 0)</span></a>
<a name="2171"><span class="lineNum">    2171 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;does not support scalars.&quot;);</span></a>
<a name="2172"><span class="lineNum">    2172 </span>            : </a>
<a name="2173"><span class="lineNum">    2173 </span><span class="lineCov">        122 :   if (iotaDimension &gt;= shape.getRank() || iotaDimension &lt; 0)</span></a>
<a name="2174"><span class="lineNum">    2174 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="2175"><span class="lineNum">    2175 </span><span class="lineCov">          2 :         location,</span></a>
<a name="2176"><span class="lineNum">    2176 </span>            :         &quot;iota dimension cannot go beyond the output rank or be negative.&quot;);</a>
<a name="2177"><span class="lineNum">    2177 </span><span class="lineCov">        120 :   return success();</span></a>
<a name="2178"><span class="lineNum">    2178 </span><span class="lineCov">        124 : }</span></a>
<a name="2179"><span class="lineNum">    2179 </span>            : </a>
<a name="2180"><span class="lineNum">    2180 </span>            : // Verifies that operand rank matches start_indices/limit_indices/strides size</a>
<a name="2181"><span class="lineNum">    2181 </span><span class="lineCov">          9 : LogicalResult verifyRealDynamicSliceOp(Optional&lt;Location&gt; location,</span></a>
<a name="2182"><span class="lineNum">    2182 </span>            :                                        Value operand, Value startIndices,</a>
<a name="2183"><span class="lineNum">    2183 </span><span class="lineCov">          9 :                                        Value limitIndices, Value strides) {</span></a>
<a name="2184"><span class="lineNum">    2184 </span><span class="lineCov">          9 :   auto inputType = operand.getType().dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="2185"><span class="lineNum">    2185 </span>            :   // If operand is unranked, there is very little to verify statically.</a>
<a name="2186"><span class="lineNum">    2186 </span><span class="lineCov">          9 :   if (!inputType) return success();</span></a>
<a name="2187"><span class="lineNum">    2187 </span><span class="lineCov">          9 :   int inputRank = inputType.getRank();</span></a>
<a name="2188"><span class="lineNum">    2188 </span>            : </a>
<a name="2189"><span class="lineNum">    2189 </span><span class="lineCov">          9 :   auto startType = startIndices.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="2190"><span class="lineNum">    2190 </span><span class="lineCov">          9 :   auto limitType = limitIndices.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="2191"><span class="lineNum">    2191 </span><span class="lineCov">          9 :   auto stridesType = strides.getType().cast&lt;RankedTensorType&gt;();</span></a>
<a name="2192"><span class="lineNum">    2192 </span>            : </a>
<a name="2193"><span class="lineNum">    2193 </span><span class="lineCov">          9 :   if (inputRank != startType.getNumElements())</span></a>
<a name="2194"><span class="lineNum">    2194 </span><span class="lineNoCov">          0 :     return emitOptionalError(</span></a>
<a name="2195"><span class="lineNum">    2195 </span><span class="lineNoCov">          0 :         location, &quot;has mismatched number of operand rank (&quot;, inputRank,</span></a>
<a name="2196"><span class="lineNum">    2196 </span><span class="lineNoCov">          0 :         &quot;) and start_indices size (&quot;, startType.getNumElements(), &quot;)&quot;);</span></a>
<a name="2197"><span class="lineNum">    2197 </span>            : </a>
<a name="2198"><span class="lineNum">    2198 </span><span class="lineCov">          9 :   if (inputRank != limitType.getNumElements())</span></a>
<a name="2199"><span class="lineNum">    2199 </span><span class="lineNoCov">          0 :     return emitOptionalError(</span></a>
<a name="2200"><span class="lineNum">    2200 </span><span class="lineNoCov">          0 :         location, &quot;has mismatched number of operand rank (&quot;, inputRank,</span></a>
<a name="2201"><span class="lineNum">    2201 </span><span class="lineNoCov">          0 :         &quot;) and limit_indices size (&quot;, limitType.getNumElements(), &quot;)&quot;);</span></a>
<a name="2202"><span class="lineNum">    2202 </span>            : </a>
<a name="2203"><span class="lineNum">    2203 </span><span class="lineCov">          9 :   if (inputRank != stridesType.getNumElements())</span></a>
<a name="2204"><span class="lineNum">    2204 </span><span class="lineNoCov">          0 :     return emitOptionalError(</span></a>
<a name="2205"><span class="lineNum">    2205 </span><span class="lineNoCov">          0 :         location, &quot;has mismatched number of operand rank (&quot;, inputRank,</span></a>
<a name="2206"><span class="lineNum">    2206 </span><span class="lineNoCov">          0 :         &quot;) and strides size (&quot;, stridesType.getNumElements(), &quot;)&quot;);</span></a>
<a name="2207"><span class="lineNum">    2207 </span><span class="lineCov">          9 :   return success();</span></a>
<a name="2208"><span class="lineNum">    2208 </span><span class="lineCov">          9 : }</span></a>
<a name="2209"><span class="lineNum">    2209 </span>            : </a>
<a name="2210"><span class="lineNum">    2210 </span>            : // We intend to verify the following properties</a>
<a name="2211"><span class="lineNum">    2211 </span>            : //  P1. Verify all `inputs` need to have compatible shapes.</a>
<a name="2212"><span class="lineNum">    2212 </span>            : //  P2. Verify that</a>
<a name="2213"><span class="lineNum">    2213 </span>            : //      1. the dimensions of reduce-op are in-bounds for the given shape.</a>
<a name="2214"><span class="lineNum">    2214 </span>            : //      2. the dimension-attribute have no duplicate entries.</a>
<a name="2215"><span class="lineNum">    2215 </span>            : //  P3. Verify the inner block defining the reducer function.</a>
<a name="2216"><span class="lineNum">    2216 </span><span class="lineCov">        177 : LogicalResult verifyReduceOp(Optional&lt;Location&gt; location, ValueRange inputs,</span></a>
<a name="2217"><span class="lineNum">    2217 </span>            :                              ValueRange initValues,</a>
<a name="2218"><span class="lineNum">    2218 </span><span class="lineCov">        177 :                              DenseIntElementsAttr dimensions, Region&amp; body) {</span></a>
<a name="2219"><span class="lineNum">    2219 </span><span class="lineCov">        354 :   SmallVector&lt;TensorType&gt; inputArgTypes{llvm::map_range(</span></a>
<a name="2220"><span class="lineNum">    2220 </span><span class="lineCov">        177 :       inputs.getTypes(),</span></a>
<a name="2221"><span class="lineNum">    2221 </span><span class="lineCov">        229 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="2222"><span class="lineNum">    2222 </span><span class="lineCov">        354 :   SmallVector&lt;TensorType&gt; initValueTypes{llvm::map_range(</span></a>
<a name="2223"><span class="lineNum">    2223 </span><span class="lineCov">        177 :       initValues.getTypes(),</span></a>
<a name="2224"><span class="lineNum">    2224 </span><span class="lineCov">        228 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="2225"><span class="lineNum">    2225 </span>            : </a>
<a name="2226"><span class="lineNum">    2226 </span>            :   // P1. &amp; P2.</a>
<a name="2227"><span class="lineNum">    2227 </span><span class="lineCov">        177 :   SmallVector&lt;int64_t&gt; newDimensions;</span></a>
<a name="2228"><span class="lineNum">    2228 </span><span class="lineCov">        177 :   Attribute encoding;</span></a>
<a name="2229"><span class="lineNum">    2229 </span><span class="lineCov">        354 :   if (failed(verifyReduceOpInputsAndInferShape(location, inputArgTypes,</span></a>
<a name="2230"><span class="lineNum">    2230 </span><span class="lineCov">        177 :                                                initValueTypes, dimensions,</span></a>
<a name="2231"><span class="lineNum">    2231 </span>            :                                                newDimensions, encoding)))</a>
<a name="2232"><span class="lineNum">    2232 </span><span class="lineCov">          8 :     return failure();</span></a>
<a name="2233"><span class="lineNum">    2233 </span>            : </a>
<a name="2234"><span class="lineNum">    2234 </span>            :   // P3.</a>
<a name="2235"><span class="lineNum">    2235 </span><span class="lineCov">        169 :   uint64_t numInputs = inputs.size();</span></a>
<a name="2236"><span class="lineNum">    2236 </span><span class="lineCov">        169 :   int64_t rankedInputIdx = -1;</span></a>
<a name="2237"><span class="lineNum">    2237 </span><span class="lineCov">        338 :   for (uint64_t inputIdx = 0; inputIdx &lt; numInputs; ++inputIdx) {</span></a>
<a name="2238"><span class="lineNum">    2238 </span><span class="lineCov">        169 :     if (inputArgTypes[inputIdx].hasRank()) {</span></a>
<a name="2239"><span class="lineNum">    2239 </span><span class="lineCov">        159 :       rankedInputIdx = inputIdx;</span></a>
<a name="2240"><span class="lineNum">    2240 </span><span class="lineCov">        159 :       break;</span></a>
<a name="2241"><span class="lineNum">    2241 </span>            :     }</a>
<a name="2242"><span class="lineNum">    2242 </span><span class="lineCov">         10 :   }</span></a>
<a name="2243"><span class="lineNum">    2243 </span><span class="lineCov">        169 :   bool allInputsUnranked = (rankedInputIdx == -1);</span></a>
<a name="2244"><span class="lineNum">    2244 </span>            : </a>
<a name="2245"><span class="lineNum">    2245 </span><span class="lineCov">        169 :   Block&amp; block = body.front();</span></a>
<a name="2246"><span class="lineNum">    2246 </span><span class="lineCov">        338 :   if (failed(verifyReducerShape(location, block, inputArgTypes, initValueTypes,</span></a>
<a name="2247"><span class="lineNum">    2247 </span><span class="lineCov">        169 :                                 numInputs, newDimensions, allInputsUnranked)))</span></a>
<a name="2248"><span class="lineNum">    2248 </span><span class="lineCov">         24 :     return failure();</span></a>
<a name="2249"><span class="lineNum">    2249 </span><span class="lineCov">        145 :   return success();</span></a>
<a name="2250"><span class="lineNum">    2250 </span><span class="lineCov">        177 : }</span></a>
<a name="2251"><span class="lineNum">    2251 </span>            : </a>
<a name="2252"><span class="lineNum">    2252 </span><span class="lineCov">         44 : LogicalResult verifyReduceScatterOp(Optional&lt;Location&gt; location, Value operand,</span></a>
<a name="2253"><span class="lineNum">    2253 </span>            :                                     int64_t scatterDimension,</a>
<a name="2254"><span class="lineNum">    2254 </span>            :                                     DenseIntElementsAttr replicaGroups,</a>
<a name="2255"><span class="lineNum">    2255 </span>            :                                     bool useGlobalDeviceIds,</a>
<a name="2256"><span class="lineNum">    2256 </span><span class="lineCov">         44 :                                     Region&amp; computation, Value result) {</span></a>
<a name="2257"><span class="lineNum">    2257 </span><span class="lineCov">         88 :   if (failed(hlo::verifyReplicaGroups(location, replicaGroups,</span></a>
<a name="2258"><span class="lineNum">    2258 </span>            :                                       /*allGroupsMustHaveSameSize=*/true,</a>
<a name="2259"><span class="lineNum">    2259 </span><span class="lineCov">         44 :                                       useGlobalDeviceIds,</span></a>
<a name="2260"><span class="lineNum">    2260 </span><span class="lineCov">         44 :                                       /*expectedGroupSize=*/std::nullopt)))</span></a>
<a name="2261"><span class="lineNum">    2261 </span><span class="lineCov">          8 :     return failure();</span></a>
<a name="2262"><span class="lineNum">    2262 </span><span class="lineCov">         36 :   auto operandType = operand.getType().cast&lt;TensorType&gt;();</span></a>
<a name="2263"><span class="lineNum">    2263 </span><span class="lineCov">         36 :   bool operandTypeRanked = operandType.isa&lt;RankedTensorType&gt;();</span></a>
<a name="2264"><span class="lineNum">    2264 </span><span class="lineCov">         36 :   Block&amp; block = computation.front();</span></a>
<a name="2265"><span class="lineNum">    2265 </span><span class="lineCov">         36 :   if (failed(hlo::verifyReducerShape(</span></a>
<a name="2266"><span class="lineNum">    2266 </span><span class="lineCov">         36 :           location, block, {operandType},</span></a>
<a name="2267"><span class="lineNum">    2267 </span><span class="lineCov">         36 :           {RankedTensorType::get({}, operandType.getElementType())},</span></a>
<a name="2268"><span class="lineNum">    2268 </span><span class="lineCov">         36 :           /*numInputs=*/1, /*allowedDimensions=*/{},</span></a>
<a name="2269"><span class="lineNum">    2269 </span><span class="lineCov">         36 :           /*allInputsUnranked=*/!operandTypeRanked)))</span></a>
<a name="2270"><span class="lineNum">    2270 </span><span class="lineCov">          2 :     return failure();</span></a>
<a name="2271"><span class="lineNum">    2271 </span>            : </a>
<a name="2272"><span class="lineNum">    2272 </span><span class="lineCov">         34 :   auto resultType = result.getType().cast&lt;ShapedType&gt;();</span></a>
<a name="2273"><span class="lineNum">    2273 </span><span class="lineCov">         34 :   if (!operandType.hasRank() || !resultType.hasRank()) return success();</span></a>
<a name="2274"><span class="lineNum">    2274 </span><span class="lineCov">         34 :   if (operandType.getRank() != resultType.getRank())</span></a>
<a name="2275"><span class="lineNum">    2275 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="2276"><span class="lineNum">    2276 </span>            :                              &quot;operand and result should have same rank&quot;);</a>
<a name="2277"><span class="lineNum">    2277 </span><span class="lineCov">         32 :   if (scatterDimension &lt; 0) {</span></a>
<a name="2278"><span class="lineNum">    2278 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;expects scatter_dimension &gt;= 0&quot;);</span></a>
<a name="2279"><span class="lineNum">    2279 </span>            :   }</a>
<a name="2280"><span class="lineNum">    2280 </span><span class="lineCov">         30 :   if (scatterDimension &gt;= operandType.getRank())</span></a>
<a name="2281"><span class="lineNum">    2281 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="2282"><span class="lineNum">    2282 </span><span class="lineCov">          2 :         location, &quot;scatter dim should be less than operand/result rank&quot;);</span></a>
<a name="2283"><span class="lineNum">    2283 </span><span class="lineCov">         28 :   if (operandType.isDynamicDim(scatterDimension) ||</span></a>
<a name="2284"><span class="lineNum">    2284 </span><span class="lineCov">         28 :       resultType.isDynamicDim(scatterDimension))</span></a>
<a name="2285"><span class="lineNum">    2285 </span><span class="lineNoCov">          0 :     return success();</span></a>
<a name="2286"><span class="lineNum">    2286 </span>            : </a>
<a name="2287"><span class="lineNum">    2287 </span><span class="lineCov">         28 :   if (operandType.getDimSize(scatterDimension) == 0)</span></a>
<a name="2288"><span class="lineNum">    2288 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="2289"><span class="lineNum">    2289 </span>            :                              &quot;operand scatter dimension cannot be zero&quot;);</a>
<a name="2290"><span class="lineNum">    2290 </span><span class="lineCov">         26 :   if (resultType.getDimSize(scatterDimension) == 0)</span></a>
<a name="2291"><span class="lineNum">    2291 </span><span class="lineCov">          2 :     return emitOptionalError(location,</span></a>
<a name="2292"><span class="lineNum">    2292 </span>            :                              &quot;result scatter dimension cannot be zero&quot;);</a>
<a name="2293"><span class="lineNum">    2293 </span>            : </a>
<a name="2294"><span class="lineNum">    2294 </span>            :   // If operand and result are both ranked, then the size of the scatter</a>
<a name="2295"><span class="lineNum">    2295 </span>            :   // dimension in the operand should be a multiple of the size of the scatter</a>
<a name="2296"><span class="lineNum">    2296 </span>            :   // dimension in the result.</a>
<a name="2297"><span class="lineNum">    2297 </span><span class="lineCov">         72 :   if ((operandType.getDimSize(scatterDimension) %</span></a>
<a name="2298"><span class="lineNum">    2298 </span><span class="lineCov">         48 :        resultType.getDimSize(scatterDimension)) != 0)</span></a>
<a name="2299"><span class="lineNum">    2299 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="2300"><span class="lineNum">    2300 </span><span class="lineCov">          2 :         location, &quot;operand scatter dimension has size &quot;,</span></a>
<a name="2301"><span class="lineNum">    2301 </span><span class="lineCov">          2 :         operandType.getDimSize(scatterDimension),</span></a>
<a name="2302"><span class="lineNum">    2302 </span>            :         &quot;, expected to be a multiple of result scatter dimension size &quot;,</a>
<a name="2303"><span class="lineNum">    2303 </span><span class="lineCov">          2 :         resultType.getDimSize(scatterDimension));</span></a>
<a name="2304"><span class="lineNum">    2304 </span>            : </a>
<a name="2305"><span class="lineNum">    2305 </span>            :   // Non scatter dimensions should be equal.</a>
<a name="2306"><span class="lineNum">    2306 </span><span class="lineCov">         48 :   for (uint64_t index : llvm::seq&lt;uint64_t&gt;(0, operandType.getRank())) {</span></a>
<a name="2307"><span class="lineNum">    2307 </span><span class="lineCov">         38 :     if (static_cast&lt;int64_t&gt;(index) == scatterDimension ||</span></a>
<a name="2308"><span class="lineNum">    2308 </span><span class="lineCov">          6 :         operandType.isDynamicDim(index) || resultType.isDynamicDim(index))</span></a>
<a name="2309"><span class="lineNum">    2309 </span><span class="lineCov">         20 :       continue;</span></a>
<a name="2310"><span class="lineNum">    2310 </span><span class="lineCov">          6 :     if (operandType.getDimSize(index) != resultType.getDimSize(index))</span></a>
<a name="2311"><span class="lineNum">    2311 </span><span class="lineCov">          2 :       return emitOptionalError(</span></a>
<a name="2312"><span class="lineNum">    2312 </span><span class="lineCov">          2 :           location, &quot;non scatter dimensions should be same for operand (&quot;,</span></a>
<a name="2313"><span class="lineNum">    2313 </span><span class="lineCov">          2 :           operandType.getDimSize(index), &quot;) and result (&quot;,</span></a>
<a name="2314"><span class="lineNum">    2314 </span><span class="lineCov">          2 :           resultType.getDimSize(index), &quot;)&quot;);</span></a>
<a name="2315"><span class="lineNum">    2315 </span><span class="lineCov">         26 :   }</span></a>
<a name="2316"><span class="lineNum">    2316 </span><span class="lineCov">         20 :   return success();</span></a>
<a name="2317"><span class="lineNum">    2317 </span><span class="lineCov">         44 : }</span></a>
<a name="2318"><span class="lineNum">    2318 </span>            : </a>
<a name="2319"><span class="lineNum">    2319 </span>            : // We intend to verify the following properties</a>
<a name="2320"><span class="lineNum">    2320 </span>            : //  P1. All `inputs` need to have compatible shapes.</a>
<a name="2321"><span class="lineNum">    2321 </span>            : //  P2. size-of(window_dimension) == rank-of(input),</a>
<a name="2322"><span class="lineNum">    2322 </span>            : //        where input is an element of 'inputs'.</a>
<a name="2323"><span class="lineNum">    2323 </span>            : //  P3. Verify and collect the window atributes.</a>
<a name="2324"><span class="lineNum">    2324 </span>            : //  P4. Verify the inner block defining the reducer function.</a>
<a name="2325"><span class="lineNum">    2325 </span><span class="lineCov">        104 : LogicalResult verifyReduceWindowOp(</span></a>
<a name="2326"><span class="lineNum">    2326 </span>            :     Optional&lt;Location&gt; location, ValueRange inputs, ValueRange initValues,</a>
<a name="2327"><span class="lineNum">    2327 </span>            :     DenseIntElementsAttr windowDimensions,</a>
<a name="2328"><span class="lineNum">    2328 </span>            :     Optional&lt;DenseIntElementsAttr&gt; windowStrides,</a>
<a name="2329"><span class="lineNum">    2329 </span>            :     Optional&lt;DenseIntElementsAttr&gt; baseDilations,</a>
<a name="2330"><span class="lineNum">    2330 </span>            :     Optional&lt;DenseIntElementsAttr&gt; windowDilations,</a>
<a name="2331"><span class="lineNum">    2331 </span><span class="lineCov">        104 :     Optional&lt;DenseIntElementsAttr&gt; padding, Region&amp; body) {</span></a>
<a name="2332"><span class="lineNum">    2332 </span><span class="lineCov">        208 :   SmallVector&lt;TensorType&gt; inputArgTypes{llvm::map_range(</span></a>
<a name="2333"><span class="lineNum">    2333 </span><span class="lineCov">        104 :       inputs.getTypes(),</span></a>
<a name="2334"><span class="lineNum">    2334 </span><span class="lineCov">        180 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="2335"><span class="lineNum">    2335 </span><span class="lineCov">        208 :   SmallVector&lt;TensorType&gt; initValueTypes{llvm::map_range(</span></a>
<a name="2336"><span class="lineNum">    2336 </span><span class="lineCov">        104 :       initValues.getTypes(),</span></a>
<a name="2337"><span class="lineNum">    2337 </span><span class="lineCov">        180 :       [](Type t) -&gt; TensorType { return t.cast&lt;TensorType&gt;(); })};</span></a>
<a name="2338"><span class="lineNum">    2338 </span><span class="lineCov">        104 :   uint64_t numInputs = inputs.size();</span></a>
<a name="2339"><span class="lineNum">    2339 </span>            : </a>
<a name="2340"><span class="lineNum">    2340 </span>            :   // P1. ~ P3.</a>
<a name="2341"><span class="lineNum">    2341 </span><span class="lineCov">        104 :   SmallVector&lt;int64_t&gt; windowDims;</span></a>
<a name="2342"><span class="lineNum">    2342 </span><span class="lineCov">        104 :   SmallVector&lt;WindowDimension&gt; inferredWindow;</span></a>
<a name="2343"><span class="lineNum">    2343 </span><span class="lineCov">        104 :   if (failed(verifyReduceWindowOpInputsAndInferWindow(</span></a>
<a name="2344"><span class="lineNum">    2344 </span><span class="lineCov">        104 :           location, inputArgTypes, initValueTypes, windowDimensions,</span></a>
<a name="2345"><span class="lineNum">    2345 </span><span class="lineCov">        104 :           windowStrides, baseDilations, windowDilations, padding,</span></a>
<a name="2346"><span class="lineNum">    2346 </span><span class="lineCov">        104 :           /*windowReversal=*/std::nullopt, windowDims, inferredWindow)))</span></a>
<a name="2347"><span class="lineNum">    2347 </span><span class="lineCov">         32 :     return failure();</span></a>
<a name="2348"><span class="lineNum">    2348 </span>            : </a>
<a name="2349"><span class="lineNum">    2349 </span>            :   // P4.</a>
<a name="2350"><span class="lineNum">    2350 </span>            :   // Check for unranked tensors in input operands.</a>
<a name="2351"><span class="lineNum">    2351 </span><span class="lineCov">         72 :   int64_t rankedInputIdx = -1;</span></a>
<a name="2352"><span class="lineNum">    2352 </span><span class="lineCov">        148 :   for (uint64_t inputIdx = 0; inputIdx &lt; numInputs; ++inputIdx) {</span></a>
<a name="2353"><span class="lineNum">    2353 </span><span class="lineCov">         76 :     if (inputArgTypes[inputIdx].hasRank()) {</span></a>
<a name="2354"><span class="lineNum">    2354 </span><span class="lineCov">         72 :       rankedInputIdx = inputIdx;</span></a>
<a name="2355"><span class="lineNum">    2355 </span><span class="lineCov">         72 :       break;</span></a>
<a name="2356"><span class="lineNum">    2356 </span>            :     }</a>
<a name="2357"><span class="lineNum">    2357 </span><span class="lineCov">          4 :   }</span></a>
<a name="2358"><span class="lineNum">    2358 </span><span class="lineCov">         72 :   bool allInputsUnranked = (rankedInputIdx == -1);</span></a>
<a name="2359"><span class="lineNum">    2359 </span><span class="lineCov">         72 :   Block&amp; block = body.front();</span></a>
<a name="2360"><span class="lineNum">    2360 </span><span class="lineCov">        144 :   if (failed(verifyReducerShape(location, block, inputArgTypes, initValueTypes,</span></a>
<a name="2361"><span class="lineNum">    2361 </span><span class="lineCov">         72 :                                 numInputs, windowDims, allInputsUnranked)))</span></a>
<a name="2362"><span class="lineNum">    2362 </span><span class="lineCov">         24 :     return failure();</span></a>
<a name="2363"><span class="lineNum">    2363 </span>            : </a>
<a name="2364"><span class="lineNum">    2364 </span><span class="lineCov">         48 :   return success();</span></a>
<a name="2365"><span class="lineNum">    2365 </span><span class="lineCov">        104 : }</span></a>
<a name="2366"><span class="lineNum">    2366 </span>            : </a>
<a name="2367"><span class="lineNum">    2367 </span><span class="lineCov">         54 : LogicalResult verifySortOp(Optional&lt;Location&gt; location, ValueRange inputs,</span></a>
<a name="2368"><span class="lineNum">    2368 </span><span class="lineCov">         54 :                            int64_t dimension, Region&amp; comparator) {</span></a>
<a name="2369"><span class="lineNum">    2369 </span><span class="lineCov">         54 :   auto operandTypes = inputs.getTypes();</span></a>
<a name="2370"><span class="lineNum">    2370 </span><span class="lineCov">        114 :   for (auto operandType : operandTypes) {</span></a>
<a name="2371"><span class="lineNum">    2371 </span><span class="lineCov">         60 :     auto operandShapedType = operandType.cast&lt;ShapedType&gt;();</span></a>
<a name="2372"><span class="lineNum">    2372 </span><span class="lineCov">         60 :     if (operandShapedType.hasRank()) {</span></a>
<a name="2373"><span class="lineNum">    2373 </span><span class="lineCov">         54 :       int64_t cmpDim = dimension;</span></a>
<a name="2374"><span class="lineNum">    2374 </span><span class="lineCov">         54 :       int64_t rank = operandShapedType.getRank();</span></a>
<a name="2375"><span class="lineNum">    2375 </span><span class="lineCov">         54 :       if (cmpDim &lt; -rank || cmpDim &gt;= rank)</span></a>
<a name="2376"><span class="lineNum">    2376 </span><span class="lineCov">          4 :         return emitOptionalError(</span></a>
<a name="2377"><span class="lineNum">    2377 </span><span class="lineCov">          4 :             location, &quot;dimension attribute value must be in range [-&quot;, rank,</span></a>
<a name="2378"><span class="lineNum">    2378 </span>            :             &quot;, &quot;, rank, &quot;), but found &quot;, cmpDim);</a>
<a name="2379"><span class="lineNum">    2379 </span>            :       else</a>
<a name="2380"><span class="lineNum">    2380 </span><span class="lineCov">         50 :         break;  // ODS SameOperandsAndResultShape asserts inputs have same shape</span></a>
<a name="2381"><span class="lineNum">    2381 </span><span class="lineCov">         54 :     }</span></a>
<a name="2382"><span class="lineNum">    2382 </span><span class="lineCov">         60 :   }</span></a>
<a name="2383"><span class="lineNum">    2383 </span>            : </a>
<a name="2384"><span class="lineNum">    2384 </span>            :   // Comparator must have 2 * N scalar arguments of same type as the N inputs.</a>
<a name="2385"><span class="lineNum">    2385 </span><span class="lineCov">         50 :   Block&amp; block = comparator.front();</span></a>
<a name="2386"><span class="lineNum">    2386 </span><span class="lineCov">         50 :   size_t numOperands = operandTypes.size();</span></a>
<a name="2387"><span class="lineNum">    2387 </span><span class="lineCov">         50 :   if (block.getNumArguments() != 2 * numOperands)</span></a>
<a name="2388"><span class="lineNum">    2388 </span><span class="lineCov">          4 :     return emitOptionalError(location, &quot;comparator block should have &quot;,</span></a>
<a name="2389"><span class="lineNum">    2389 </span><span class="lineCov">          2 :                              2 * numOperands, &quot; arguments&quot;);</span></a>
<a name="2390"><span class="lineNum">    2390 </span><span class="lineCov">        130 :   for (const auto&amp; indexedOperandType : llvm::enumerate(operandTypes)) {</span></a>
<a name="2391"><span class="lineNum">    2391 </span><span class="lineCov">         82 :     int index = indexedOperandType.index();</span></a>
<a name="2392"><span class="lineNum">    2392 </span><span class="lineCov">         82 :     Type elementType =</span></a>
<a name="2393"><span class="lineNum">    2393 </span><span class="lineCov">         82 :         indexedOperandType.value().cast&lt;ShapedType&gt;().getElementType();</span></a>
<a name="2394"><span class="lineNum">    2394 </span><span class="lineCov">         82 :     Type tensorType = RankedTensorType::get({}, elementType);</span></a>
<a name="2395"><span class="lineNum">    2395 </span><span class="lineCov">        244 :     for (int i : {2 * index, 2 * index + 1}) {</span></a>
<a name="2396"><span class="lineNum">    2396 </span><span class="lineCov">        162 :       Type argType = block.getArgument(i).getType();</span></a>
<a name="2397"><span class="lineNum">    2397 </span><span class="lineCov">        162 :       if (argType != tensorType)</span></a>
<a name="2398"><span class="lineNum">    2398 </span><span class="lineCov">          4 :         return emitOptionalError(location, &quot;comparator block argument #&quot;, i,</span></a>
<a name="2399"><span class="lineNum">    2399 </span>            :                                  &quot; should be of type &quot;, tensorType, &quot; but got &quot;,</a>
<a name="2400"><span class="lineNum">    2400 </span>            :                                  argType);</a>
<a name="2401"><span class="lineNum">    2401 </span><span class="lineCov">        162 :     }</span></a>
<a name="2402"><span class="lineNum">    2402 </span><span class="lineCov">         82 :   }</span></a>
<a name="2403"><span class="lineNum">    2403 </span>            : </a>
<a name="2404"><span class="lineNum">    2404 </span>            :   // Comparator must return single 0-ranked tensor with element-type i1.</a>
<a name="2405"><span class="lineNum">    2405 </span><span class="lineCov">         44 :   auto comparatorResult = block.getTerminator()-&gt;getOperands();</span></a>
<a name="2406"><span class="lineNum">    2406 </span><span class="lineCov">         44 :   if (comparatorResult.size() != 1)</span></a>
<a name="2407"><span class="lineNum">    2407 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="2408"><span class="lineNum">    2408 </span>            :                              &quot;comparator must return single output but got &quot;,</a>
<a name="2409"><span class="lineNum">    2409 </span><span class="lineCov">          2 :                              comparatorResult.size());</span></a>
<a name="2410"><span class="lineNum">    2410 </span><span class="lineCov">         42 :   auto comparatorResultType = comparatorResult[0].getType().cast&lt;TensorType&gt;();</span></a>
<a name="2411"><span class="lineNum">    2411 </span><span class="lineCov">         42 :   if ((comparatorResultType.hasRank() &amp;&amp; comparatorResultType.getRank() != 0) ||</span></a>
<a name="2412"><span class="lineNum">    2412 </span><span class="lineCov">         40 :       !comparatorResultType.getElementType().isInteger(1))</span></a>
<a name="2413"><span class="lineNum">    2413 </span><span class="lineCov">          8 :     return emitOptionalError(location,</span></a>
<a name="2414"><span class="lineNum">    2414 </span>            :                              &quot;comparator must return tensor&lt;i1&gt; but got &quot;,</a>
<a name="2415"><span class="lineNum">    2415 </span><span class="lineCov">          4 :                              comparatorResult[0].getType());</span></a>
<a name="2416"><span class="lineNum">    2416 </span><span class="lineCov">         38 :   return success();</span></a>
<a name="2417"><span class="lineNum">    2417 </span><span class="lineCov">         54 : }</span></a>
<a name="2418"><span class="lineNum">    2418 </span>            : </a>
<a name="2419"><span class="lineNum">    2419 </span><span class="lineCov">         52 : LogicalResult verifyWhileOp(Optional&lt;Location&gt; location, ValueRange operand,</span></a>
<a name="2420"><span class="lineNum">    2420 </span><span class="lineCov">         52 :                             Region&amp; cond, Region&amp; body) {</span></a>
<a name="2421"><span class="lineNum">    2421 </span><span class="lineCov">         52 :   auto operandTypes = operand.getTypes();</span></a>
<a name="2422"><span class="lineNum">    2422 </span><span class="lineCov">         52 :   auto condArgsTypes = cond.front().getArgumentTypes();</span></a>
<a name="2423"><span class="lineNum">    2423 </span><span class="lineCov">         52 :   auto bodyArgsTypes = body.front().getArgumentTypes();</span></a>
<a name="2424"><span class="lineNum">    2424 </span><span class="lineCov">         52 :   if (!hlo::isCompatibleForHloTypeInference(operandTypes, condArgsTypes))</span></a>
<a name="2425"><span class="lineNum">    2425 </span><span class="lineCov">          4 :     return emitOptionalError(location,</span></a>
<a name="2426"><span class="lineNum">    2426 </span>            :                              &quot;expect operands are compatible with condition &quot;</a>
<a name="2427"><span class="lineNum">    2427 </span>            :                              &quot;block arguments but got &quot;,</a>
<a name="2428"><span class="lineNum">    2428 </span>            :                              operandTypes, &quot; vs &quot;, condArgsTypes);</a>
<a name="2429"><span class="lineNum">    2429 </span><span class="lineCov">         48 :   if (!hlo::isCompatibleForHloTypeInference(operandTypes, bodyArgsTypes))</span></a>
<a name="2430"><span class="lineNum">    2430 </span><span class="lineCov">          4 :     return emitOptionalError(</span></a>
<a name="2431"><span class="lineNum">    2431 </span><span class="lineCov">          4 :         location,</span></a>
<a name="2432"><span class="lineNum">    2432 </span>            :         &quot;expect operands are compatible with body block arguments but got &quot;,</a>
<a name="2433"><span class="lineNum">    2433 </span>            :         operandTypes, &quot; vs &quot;, bodyArgsTypes);</a>
<a name="2434"><span class="lineNum">    2434 </span>            : </a>
<a name="2435"><span class="lineNum">    2435 </span><span class="lineCov">         44 :   auto bodyReturnTypes = body.front().getTerminator()-&gt;getOperandTypes();</span></a>
<a name="2436"><span class="lineNum">    2436 </span><span class="lineCov">         44 :   if (!hlo::isCompatibleForHloTypeInference(operandTypes, bodyReturnTypes))</span></a>
<a name="2437"><span class="lineNum">    2437 </span><span class="lineCov">          4 :     return emitOptionalError(</span></a>
<a name="2438"><span class="lineNum">    2438 </span><span class="lineCov">          4 :         location,</span></a>
<a name="2439"><span class="lineNum">    2439 </span>            :         &quot;expect operands are compatible with body block return types but got &quot;,</a>
<a name="2440"><span class="lineNum">    2440 </span>            :         operandTypes, &quot; vs &quot;, bodyReturnTypes);</a>
<a name="2441"><span class="lineNum">    2441 </span>            : </a>
<a name="2442"><span class="lineNum">    2442 </span><span class="lineCov">         40 :   auto condReturnTypes = cond.front().back().getOperandTypes();</span></a>
<a name="2443"><span class="lineNum">    2443 </span><span class="lineCov">         40 :   if (condReturnTypes.size() != 1)</span></a>
<a name="2444"><span class="lineNum">    2444 </span><span class="lineCov">          2 :     return emitOptionalError(</span></a>
<a name="2445"><span class="lineNum">    2445 </span><span class="lineCov">          2 :         location, &quot;expect condition body returns a single value but got &quot;,</span></a>
<a name="2446"><span class="lineNum">    2446 </span><span class="lineCov">          2 :         condReturnTypes.size());</span></a>
<a name="2447"><span class="lineNum">    2447 </span><span class="lineCov">         38 :   auto operandType = condReturnTypes[0].cast&lt;TensorType&gt;();</span></a>
<a name="2448"><span class="lineNum">    2448 </span><span class="lineCov">         38 :   if ((operandType.hasRank() &amp;&amp; operandType.getRank() != 0) ||</span></a>
<a name="2449"><span class="lineNum">    2449 </span><span class="lineCov">         36 :       !operandType.getElementType().isInteger(1))</span></a>
<a name="2450"><span class="lineNum">    2450 </span><span class="lineCov">          6 :     return emitOptionalError(</span></a>
<a name="2451"><span class="lineNum">    2451 </span><span class="lineCov">          6 :         location,</span></a>
<a name="2452"><span class="lineNum">    2452 </span>            :         &quot;expect condition block return a zero-ranked tensor of i1 but got &quot;,</a>
<a name="2453"><span class="lineNum">    2453 </span><span class="lineCov">          6 :         condReturnTypes[0]);</span></a>
<a name="2454"><span class="lineNum">    2454 </span>            : </a>
<a name="2455"><span class="lineNum">    2455 </span><span class="lineCov">         32 :   return success();</span></a>
<a name="2456"><span class="lineNum">    2456 </span><span class="lineCov">         52 : }</span></a>
<a name="2457"><span class="lineNum">    2457 </span>            : </a>
<a name="2458"><span class="lineNum">    2458 </span>            : }  // end namespace hlo</a>
<a name="2459"><span class="lineNum">    2459 </span>            : }  // end namespace mlir</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="https://github.com/linux-test-project/lcov" target="_parent">LCOV version 1.16</a></td></tr>
  </table>
  <br>

</body>
</html>
