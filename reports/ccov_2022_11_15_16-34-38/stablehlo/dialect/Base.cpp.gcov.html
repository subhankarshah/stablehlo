<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - cov.info - stablehlo/dialect/Base.cpp</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">stablehlo/dialect</a> - Base.cpp<span style="font-size: 80%;"> (source / <a href="Base.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">cov.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">167</td>
            <td class="headerCovTableEntry">173</td>
            <td class="headerCovTableEntryHi">96.5 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2022-11-15 16:34:39</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">15</td>
            <td class="headerCovTableEntry">15</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* Copyright 2020 The TensorFlow Authors. All Rights Reserved.</a>
<a name="2"><span class="lineNum">       2 </span>            :    Copyright 2022 The StableHLO Authors.</a>
<a name="3"><span class="lineNum">       3 </span>            : </a>
<a name="4"><span class="lineNum">       4 </span>            : Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</a>
<a name="5"><span class="lineNum">       5 </span>            : you may not use this file except in compliance with the License.</a>
<a name="6"><span class="lineNum">       6 </span>            : You may obtain a copy of the License at</a>
<a name="7"><span class="lineNum">       7 </span>            : </a>
<a name="8"><span class="lineNum">       8 </span>            :     http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="9"><span class="lineNum">       9 </span>            : </a>
<a name="10"><span class="lineNum">      10 </span>            : Unless required by applicable law or agreed to in writing, software</a>
<a name="11"><span class="lineNum">      11 </span>            : distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</a>
<a name="12"><span class="lineNum">      12 </span>            : WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</a>
<a name="13"><span class="lineNum">      13 </span>            : See the License for the specific language governing permissions and</a>
<a name="14"><span class="lineNum">      14 </span>            : limitations under the License.</a>
<a name="15"><span class="lineNum">      15 </span>            : ==============================================================================*/</a>
<a name="16"><span class="lineNum">      16 </span>            : </a>
<a name="17"><span class="lineNum">      17 </span>            : #include &quot;stablehlo/dialect/Base.h&quot;</a>
<a name="18"><span class="lineNum">      18 </span>            : </a>
<a name="19"><span class="lineNum">      19 </span>            : #include &quot;llvm/ADT/TypeSwitch.h&quot;</a>
<a name="20"><span class="lineNum">      20 </span>            : #include &quot;mlir/Dialect/Quant/QuantTypes.h&quot;</a>
<a name="21"><span class="lineNum">      21 </span>            : #include &quot;mlir/Dialect/Shape/IR/Shape.h&quot;</a>
<a name="22"><span class="lineNum">      22 </span>            : #include &quot;mlir/IR/DialectImplementation.h&quot;</a>
<a name="23"><span class="lineNum">      23 </span>            : #include &quot;mlir/IR/TypeUtilities.h&quot;</a>
<a name="24"><span class="lineNum">      24 </span>            : #include &quot;mlir/Support/LLVM.h&quot;</a>
<a name="25"><span class="lineNum">      25 </span>            : </a>
<a name="26"><span class="lineNum">      26 </span>            : // Include order matters</a>
<a name="27"><span class="lineNum">      27 </span>            : #include &quot;stablehlo/dialect/BaseAttrInterfaces.cpp.inc&quot;</a>
<a name="28"><span class="lineNum">      28 </span>            : </a>
<a name="29"><span class="lineNum">      29 </span>            : namespace mlir {</a>
<a name="30"><span class="lineNum">      30 </span>            : namespace hlo {</a>
<a name="31"><span class="lineNum">      31 </span>            : </a>
<a name="32"><span class="lineNum">      32 </span>            : namespace {</a>
<a name="33"><span class="lineNum">      33 </span><span class="lineCov">      16102 : Type getExpressedTypeOrSelf(Type type) {</span></a>
<a name="34"><span class="lineNum">      34 </span><span class="lineCov">      16102 :   auto quantType = type.dyn_cast&lt;quant::QuantizedType&gt;();</span></a>
<a name="35"><span class="lineNum">      35 </span><span class="lineCov">      16102 :   return quantType ? quantType.getExpressedType() : type;</span></a>
<a name="36"><span class="lineNum">      36 </span><span class="lineCov">      16102 : }</span></a>
<a name="37"><span class="lineNum">      37 </span>            : </a>
<a name="38"><span class="lineNum">      38 </span><span class="lineCov">       7916 : LogicalResult verifyCompatibleShapeWithBounds(Type type1, Type type2) {</span></a>
<a name="39"><span class="lineNum">      39 </span><span class="lineCov">       7916 :   if (failed(verifyCompatibleShape(type1, type2))) return failure();</span></a>
<a name="40"><span class="lineNum">      40 </span>            : </a>
<a name="41"><span class="lineNum">      41 </span>            :   // Verify shapes against bounds</a>
<a name="42"><span class="lineNum">      42 </span><span class="lineCov">      23295 :   auto isCompatible = [](ArrayRef&lt;int64_t&gt; shape,</span></a>
<a name="43"><span class="lineNum">      43 </span><span class="lineCov">      15409 :                          BoundedAttrInterface boundedAttr) {</span></a>
<a name="44"><span class="lineNum">      44 </span><span class="lineCov">      15409 :     if (shape.empty() || !boundedAttr) return true;</span></a>
<a name="45"><span class="lineNum">      45 </span><span class="lineCov">        127 :     auto bounds = boundedAttr.getBounds();</span></a>
<a name="46"><span class="lineNum">      46 </span><span class="lineCov">        514 :     for (auto [dim_size, bound] : llvm::zip(shape, bounds))  // NOLINT</span></a>
<a name="47"><span class="lineNum">      47 </span><span class="lineCov">        387 :       if (!isDynamicDimSize(bound) &amp;&amp; bound &lt; dim_size) return false;</span></a>
<a name="48"><span class="lineNum">      48 </span><span class="lineCov">        125 :     return true;</span></a>
<a name="49"><span class="lineNum">      49 </span><span class="lineCov">      15409 :   };</span></a>
<a name="50"><span class="lineNum">      50 </span>            : </a>
<a name="51"><span class="lineNum">      51 </span><span class="lineCov">       7886 :   RankedTensorType rankedType1 = type1.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="52"><span class="lineNum">      52 </span><span class="lineCov">       7886 :   RankedTensorType rankedType2 = type2.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="53"><span class="lineNum">      53 </span><span class="lineCov">       7886 :   if (rankedType1 &amp;&amp; rankedType2) {</span></a>
<a name="54"><span class="lineNum">      54 </span><span class="lineCov">       7705 :     auto boundedAttr1 =</span></a>
<a name="55"><span class="lineNum">      55 </span><span class="lineCov">       7705 :         rankedType1.getEncoding().dyn_cast_or_null&lt;BoundedAttrInterface&gt;();</span></a>
<a name="56"><span class="lineNum">      56 </span><span class="lineCov">       7705 :     auto boundedAttr2 =</span></a>
<a name="57"><span class="lineNum">      57 </span><span class="lineCov">       7705 :         rankedType2.getEncoding().dyn_cast_or_null&lt;BoundedAttrInterface&gt;();</span></a>
<a name="58"><span class="lineNum">      58 </span><span class="lineCov">       7705 :     return LogicalResult::success(</span></a>
<a name="59"><span class="lineNum">      59 </span><span class="lineCov">       7705 :         isCompatible(rankedType1.getShape(), boundedAttr2) &amp;&amp;</span></a>
<a name="60"><span class="lineNum">      60 </span><span class="lineCov">       7704 :         isCompatible(rankedType2.getShape(), boundedAttr1));</span></a>
<a name="61"><span class="lineNum">      61 </span><span class="lineCov">       7705 :   }</span></a>
<a name="62"><span class="lineNum">      62 </span><span class="lineCov">        181 :   return success();</span></a>
<a name="63"><span class="lineNum">      63 </span><span class="lineCov">       7916 : }</span></a>
<a name="64"><span class="lineNum">      64 </span>            : }  // namespace</a>
<a name="65"><span class="lineNum">      65 </span>            : </a>
<a name="66"><span class="lineNum">      66 </span><span class="lineCov">      15969 : bool isCompatibleForHloTypeInference(Type tp1, Type tp2) {</span></a>
<a name="67"><span class="lineNum">      67 </span>            :   // Dynamism: We don't require shapes to be the same, we only require them</a>
<a name="68"><span class="lineNum">      68 </span>            :   // to be compatible, which means that:</a>
<a name="69"><span class="lineNum">      69 </span>            :   //   1) At least one of the shapes is unranked.</a>
<a name="70"><span class="lineNum">      70 </span>            :   //   2) Or both shapes have the same rank and their dimensions are compatible,</a>
<a name="71"><span class="lineNum">      71 </span>            :   //     i.e. for each pair of corresponding dimensions:</a>
<a name="72"><span class="lineNum">      72 </span>            :   //       2.1) At least one of the dimensions is dynamic,</a>
<a name="73"><span class="lineNum">      73 </span>            :   //       2.2) Or both dimensions are equal.</a>
<a name="74"><span class="lineNum">      74 </span>            :   // These relaxed rules simplify the implementation of type inference, allowing</a>
<a name="75"><span class="lineNum">      75 </span>            :   // ops with partially inferred types to pass verification.</a>
<a name="76"><span class="lineNum">      76 </span><span class="lineCov">      15969 :   auto stp1 = tp1.dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="77"><span class="lineNum">      77 </span><span class="lineCov">      15969 :   auto stp2 = tp2.dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="78"><span class="lineNum">      78 </span><span class="lineCov">      15969 :   if (stp1 &amp;&amp; stp2) {</span></a>
<a name="79"><span class="lineNum">      79 </span><span class="lineCov">       7916 :     return succeeded(verifyCompatibleShapeWithBounds(stp1, stp2)) &amp;&amp;</span></a>
<a name="80"><span class="lineNum">      80 </span><span class="lineCov">      15768 :            isCompatibleForHloTypeInference(stp1.getElementType(),</span></a>
<a name="81"><span class="lineNum">      81 </span><span class="lineCov">       7884 :                                            stp2.getElementType());</span></a>
<a name="82"><span class="lineNum">      82 </span>            :   }</a>
<a name="83"><span class="lineNum">      83 </span>            : </a>
<a name="84"><span class="lineNum">      84 </span>            :   // Quantization: In the most general case, we allow any combination of</a>
<a name="85"><span class="lineNum">      85 </span>            :   // quantized/non-quantized across any combination of operands/results,</a>
<a name="86"><span class="lineNum">      86 </span>            :   // and some differences in quantization parameters across operands/results.</a>
<a name="87"><span class="lineNum">      87 </span>            :   // Individual ops may introduce additional constraints.</a>
<a name="88"><span class="lineNum">      88 </span><span class="lineCov">       8053 :   auto qtp1 = tp1.dyn_cast&lt;quant::QuantizedType&gt;();</span></a>
<a name="89"><span class="lineNum">      89 </span><span class="lineCov">       8053 :   auto qtp2 = tp2.dyn_cast&lt;quant::QuantizedType&gt;();</span></a>
<a name="90"><span class="lineNum">      90 </span><span class="lineCov">       8053 :   if (qtp1 &amp;&amp; qtp2) {</span></a>
<a name="91"><span class="lineNum">      91 </span><span class="lineCov">         93 :     if (qtp1.getStorageType() != qtp2.getStorageType() ||</span></a>
<a name="92"><span class="lineNum">      92 </span><span class="lineCov">         46 :         qtp1.getStorageTypeMin() != qtp2.getStorageTypeMin() ||</span></a>
<a name="93"><span class="lineNum">      93 </span><span class="lineCov">         45 :         qtp1.getStorageTypeMax() != qtp2.getStorageTypeMax())</span></a>
<a name="94"><span class="lineNum">      94 </span><span class="lineCov">          2 :       return false;</span></a>
<a name="95"><span class="lineNum">      95 </span><span class="lineCov">         45 :   }</span></a>
<a name="96"><span class="lineNum">      96 </span><span class="lineCov">       8051 :   auto etp1 = getExpressedTypeOrSelf(tp1);</span></a>
<a name="97"><span class="lineNum">      97 </span><span class="lineCov">       8051 :   auto etp2 = getExpressedTypeOrSelf(tp2);</span></a>
<a name="98"><span class="lineNum">      98 </span>            : </a>
<a name="99"><span class="lineNum">      99 </span>            :   // Sparsity: In the most general case, we allow any combination of</a>
<a name="100"><span class="lineNum">     100 </span>            :   // sparsity/denseness across any combination of operands/results, as well as</a>
<a name="101"><span class="lineNum">     101 </span>            :   // differences in sparsity encodings for operands and results.</a>
<a name="102"><span class="lineNum">     102 </span>            :   // Individual ops may introduce additional constraints.</a>
<a name="103"><span class="lineNum">     103 </span>            :   // No additional code is needed to check this because of how sparsity is</a>
<a name="104"><span class="lineNum">     104 </span>            :   // currently implemented.</a>
<a name="105"><span class="lineNum">     105 </span>            : </a>
<a name="106"><span class="lineNum">     106 </span>            :   // Default case: Unless dynamism, quantization and/or sparsity are involved,</a>
<a name="107"><span class="lineNum">     107 </span>            :   // the types are required to be exactly equal.</a>
<a name="108"><span class="lineNum">     108 </span><span class="lineCov">       8051 :   return etp1 == etp2;</span></a>
<a name="109"><span class="lineNum">     109 </span><span class="lineCov">      15969 : }</span></a>
<a name="110"><span class="lineNum">     110 </span>            : </a>
<a name="111"><span class="lineNum">     111 </span><span class="lineCov">       3374 : bool isCompatibleForHloTypeInference(TypeRange tp1, TypeRange tp2) {</span></a>
<a name="112"><span class="lineNum">     112 </span><span class="lineCov">       3374 :   if (tp1.size() != tp2.size()) return false;</span></a>
<a name="113"><span class="lineNum">     113 </span><span class="lineCov">       7107 :   for (auto [lt, rt] : llvm::zip(tp1, tp2))</span></a>
<a name="114"><span class="lineNum">     114 </span><span class="lineCov">       7482 :     if (!isCompatibleForHloTypeInference(lt, rt)) return false;</span></a>
<a name="115"><span class="lineNum">     115 </span><span class="lineCov">       3326 :   return true;</span></a>
<a name="116"><span class="lineNum">     116 </span><span class="lineCov">       3374 : }</span></a>
<a name="117"><span class="lineNum">     117 </span>            : </a>
<a name="118"><span class="lineNum">     118 </span><span class="lineCov">          2 : LogicalResult deriveShapeFromOperand(</span></a>
<a name="119"><span class="lineNum">     119 </span>            :     OpBuilder* builder, Operation* op, Value operand,</a>
<a name="120"><span class="lineNum">     120 </span><span class="lineCov">          2 :     SmallVectorImpl&lt;Value&gt;* reifiedReturnShapes) {</span></a>
<a name="121"><span class="lineNum">     121 </span><span class="lineCov">          2 :   auto shapedTy = operand.getType().dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="122"><span class="lineNum">     122 </span><span class="lineCov">          2 :   if (!shapedTy) {</span></a>
<a name="123"><span class="lineNum">     123 </span><span class="lineNoCov">          0 :     op-&gt;emitOpError() &lt;&lt; &quot;operand is not a shaped type&quot;;</span></a>
<a name="124"><span class="lineNum">     124 </span><span class="lineNoCov">          0 :     return failure();</span></a>
<a name="125"><span class="lineNum">     125 </span>            :   }</a>
<a name="126"><span class="lineNum">     126 </span><span class="lineCov">          4 :   reifiedReturnShapes-&gt;assign(</span></a>
<a name="127"><span class="lineNum">     127 </span><span class="lineCov">          2 :       {builder-&gt;create&lt;shape::ShapeOfOp&gt;(op-&gt;getLoc(), operand)});</span></a>
<a name="128"><span class="lineNum">     128 </span><span class="lineCov">          2 :   return success();</span></a>
<a name="129"><span class="lineNum">     129 </span><span class="lineCov">          2 : }</span></a>
<a name="130"><span class="lineNum">     130 </span>            : </a>
<a name="131"><span class="lineNum">     131 </span><span class="lineCov">         77 : TensorType getSameShapeTensorType(TensorType tensorType, Type elementType) {</span></a>
<a name="132"><span class="lineNum">     132 </span><span class="lineCov">         77 :   if (auto rankedTensorTy = tensorType.dyn_cast&lt;RankedTensorType&gt;()) {</span></a>
<a name="133"><span class="lineNum">     133 </span><span class="lineCov">        146 :     return RankedTensorType::get(rankedTensorTy.getShape(), elementType,</span></a>
<a name="134"><span class="lineNum">     134 </span><span class="lineCov">         73 :                                  rankedTensorTy.getEncoding());</span></a>
<a name="135"><span class="lineNum">     135 </span>            :   }</a>
<a name="136"><span class="lineNum">     136 </span><span class="lineCov">          4 :   if (auto unrankedTensorTy = tensorType.dyn_cast&lt;UnrankedTensorType&gt;()) {</span></a>
<a name="137"><span class="lineNum">     137 </span><span class="lineCov">          4 :     return UnrankedTensorType::get(elementType);</span></a>
<a name="138"><span class="lineNum">     138 </span>            :   }</a>
<a name="139"><span class="lineNum">     139 </span><span class="lineNoCov">          0 :   llvm_unreachable(&quot;unhandled type&quot;);</span></a>
<a name="140"><span class="lineNum">     140 </span><span class="lineCov">         77 : }</span></a>
<a name="141"><span class="lineNum">     141 </span>            : </a>
<a name="142"><span class="lineNum">     142 </span>            : // createRealType takes a tensor type that may have complex elements and</a>
<a name="143"><span class="lineNum">     143 </span>            : // returns a type that maintains the shape, but with real numeric data types.</a>
<a name="144"><span class="lineNum">     144 </span>            : //   Ex: tensor&lt;4xcomplex&lt;f32&gt;&gt;  --&gt;  tensor&lt;4xf32&gt;</a>
<a name="145"><span class="lineNum">     145 </span><span class="lineCov">         47 : Type createRealType(TensorType type) {</span></a>
<a name="146"><span class="lineNum">     146 </span><span class="lineCov">         47 :   auto elementTy = type.getElementType();</span></a>
<a name="147"><span class="lineNum">     147 </span><span class="lineCov">         47 :   if (auto complexTy = elementTy.dyn_cast&lt;ComplexType&gt;()) {</span></a>
<a name="148"><span class="lineNum">     148 </span><span class="lineCov">         30 :     elementTy = complexTy.getElementType();</span></a>
<a name="149"><span class="lineNum">     149 </span><span class="lineCov">         30 :   }</span></a>
<a name="150"><span class="lineNum">     150 </span><span class="lineCov">         47 :   return hlo::getSameShapeTensorType(type, elementTy);</span></a>
<a name="151"><span class="lineNum">     151 </span><span class="lineCov">         47 : }</span></a>
<a name="152"><span class="lineNum">     152 </span>            : </a>
<a name="153"><span class="lineNum">     153 </span>            : // TODO(hinsu): Add verification for bounds that it has the same size as rank</a>
<a name="154"><span class="lineNum">     154 </span>            : // of the tensor and static dimensions don't have bounds.</a>
<a name="155"><span class="lineNum">     155 </span><span class="lineCov">        283 : LogicalResult verifyBounds(ArrayRef&lt;int64_t&gt; bounds, ShapedType type,</span></a>
<a name="156"><span class="lineNum">     156 </span><span class="lineCov">        283 :                            function_ref&lt;InFlightDiagnostic()&gt; emitError) {</span></a>
<a name="157"><span class="lineNum">     157 </span><span class="lineCov">        283 :   return success();</span></a>
<a name="158"><span class="lineNum">     158 </span>            : }</a>
<a name="159"><span class="lineNum">     159 </span>            : </a>
<a name="160"><span class="lineNum">     160 </span><span class="lineCov">       2924 : ArrayRef&lt;int64_t&gt; encodingToBounds(Attribute encoding) {</span></a>
<a name="161"><span class="lineNum">     161 </span><span class="lineCov">       2924 :   if (auto boundedAttr = encoding.dyn_cast_or_null&lt;BoundedAttrInterface&gt;())</span></a>
<a name="162"><span class="lineNum">     162 </span><span class="lineCov">        114 :     return boundedAttr.getBounds();</span></a>
<a name="163"><span class="lineNum">     163 </span><span class="lineCov">       2810 :   return {};</span></a>
<a name="164"><span class="lineNum">     164 </span><span class="lineCov">       2924 : }</span></a>
<a name="165"><span class="lineNum">     165 </span>            : </a>
<a name="166"><span class="lineNum">     166 </span><span class="lineCov">       1811 : Attribute boundsToEncoding(Attribute prototype, ArrayRef&lt;int64_t&gt; bounds) {</span></a>
<a name="167"><span class="lineNum">     167 </span><span class="lineCov">       1811 :   if (bounds.empty()) return prototype;</span></a>
<a name="168"><span class="lineNum">     168 </span><span class="lineCov">        224 :   if (llvm::all_of(bounds, [&amp;](auto b) { return isDynamicDimSize(b); }))</span></a>
<a name="169"><span class="lineNum">     169 </span><span class="lineCov">         32 :     return {};</span></a>
<a name="170"><span class="lineNum">     170 </span><span class="lineCov">         34 :   if (!prototype)</span></a>
<a name="171"><span class="lineNum">     171 </span><span class="lineNoCov">          0 :     llvm::report_fatal_error(</span></a>
<a name="172"><span class="lineNum">     172 </span>            :         &quot;Expect an prototype attribute to obtain the underlying dialect but &quot;</a>
<a name="173"><span class="lineNum">     173 </span>            :         &quot;got none&quot;);</a>
<a name="174"><span class="lineNum">     174 </span><span class="lineCov">         34 :   auto dialect = cast&lt;BoundedDialectInterface&gt;(&amp;prototype.getDialect());</span></a>
<a name="175"><span class="lineNum">     175 </span><span class="lineCov">         34 :   return dialect-&gt;createBoundedAttr(bounds);</span></a>
<a name="176"><span class="lineNum">     176 </span><span class="lineCov">       1811 : }</span></a>
<a name="177"><span class="lineNum">     177 </span>            : </a>
<a name="178"><span class="lineNum">     178 </span>            : // Inference rules to concat dimensions with bounds (lhs/rhs are commutative):</a>
<a name="179"><span class="lineNum">     179 </span>            : //       Dim of lhs     Dim of rhs      Infer</a>
<a name="180"><span class="lineNum">     180 </span>            : //  c0:  X              Y               X+Y</a>
<a name="181"><span class="lineNum">     181 </span>            : //  c1:  X              ?               ?</a>
<a name="182"><span class="lineNum">     182 </span>            : //  c2:  X              ?, B            ?, X+B</a>
<a name="183"><span class="lineNum">     183 </span>            : //  c3:  ?              ?               ?</a>
<a name="184"><span class="lineNum">     184 </span>            : //  c4:  ?              ?, B            ?</a>
<a name="185"><span class="lineNum">     185 </span>            : //  c5:  ?, B           ?, C            ?, B+C</a>
<a name="186"><span class="lineNum">     186 </span><span class="lineCov">        159 : std::pair&lt;int64_t, int64_t&gt; inferConcatenatedDimAndBound(int64_t leftSize,</span></a>
<a name="187"><span class="lineNum">     187 </span>            :                                                          int64_t rightSize,</a>
<a name="188"><span class="lineNum">     188 </span>            :                                                          int64_t leftBound,</a>
<a name="189"><span class="lineNum">     189 </span><span class="lineCov">        159 :                                                          int64_t rightBound) {</span></a>
<a name="190"><span class="lineNum">     190 </span><span class="lineCov">        159 :   bool isLeftStaticDim = !isDynamicDimSize(leftSize);</span></a>
<a name="191"><span class="lineNum">     191 </span><span class="lineCov">        159 :   bool isRightStaticDim = !isDynamicDimSize(rightSize);</span></a>
<a name="192"><span class="lineNum">     192 </span><span class="lineCov">        159 :   int64_t size = ShapedType::kDynamicSize;</span></a>
<a name="193"><span class="lineNum">     193 </span><span class="lineCov">        159 :   int64_t bound = ShapedType::kDynamicSize;</span></a>
<a name="194"><span class="lineNum">     194 </span>            : </a>
<a name="195"><span class="lineNum">     195 </span><span class="lineCov">        159 :   if (isLeftStaticDim &amp;&amp; isRightStaticDim) {</span></a>
<a name="196"><span class="lineNum">     196 </span><span class="lineCov">         83 :     size = leftSize + rightSize;</span></a>
<a name="197"><span class="lineNum">     197 </span><span class="lineCov">         83 :   } else {</span></a>
<a name="198"><span class="lineNum">     198 </span><span class="lineCov">         76 :     int64_t leftSizeOrBound = isLeftStaticDim ? leftSize : leftBound;</span></a>
<a name="199"><span class="lineNum">     199 </span><span class="lineCov">         76 :     int64_t rightSizeOrBound = isRightStaticDim ? rightSize : rightBound;</span></a>
<a name="200"><span class="lineNum">     200 </span><span class="lineCov">         76 :     if (!isDynamicDimSize(leftSizeOrBound) &amp;&amp;</span></a>
<a name="201"><span class="lineNum">     201 </span><span class="lineCov">         56 :         !isDynamicDimSize(rightSizeOrBound))</span></a>
<a name="202"><span class="lineNum">     202 </span><span class="lineCov">         24 :       bound = leftSizeOrBound + rightSizeOrBound;</span></a>
<a name="203"><span class="lineNum">     203 </span><span class="lineCov">         76 :   }</span></a>
<a name="204"><span class="lineNum">     204 </span><span class="lineCov">        159 :   return {size, bound};</span></a>
<a name="205"><span class="lineNum">     205 </span><span class="lineCov">        159 : }</span></a>
<a name="206"><span class="lineNum">     206 </span>            : </a>
<a name="207"><span class="lineNum">     207 </span>            : // Inference rules to merge dimensions with bounds (lhs/rhs are commutative):</a>
<a name="208"><span class="lineNum">     208 </span>            : //       Dim of lhs     Dim of rhs      Infer</a>
<a name="209"><span class="lineNum">     209 </span>            : //  c0:  X              X               X</a>
<a name="210"><span class="lineNum">     210 </span>            : //  c1:  X              ?               X</a>
<a name="211"><span class="lineNum">     211 </span>            : //  c2:  X              ?, B(&gt;=X)       X</a>
<a name="212"><span class="lineNum">     212 </span>            : //  c3:  X              ?, B(&lt;X)        Will error out by compatible checks</a>
<a name="213"><span class="lineNum">     213 </span>            : //  c4:  ?              ?               ?</a>
<a name="214"><span class="lineNum">     214 </span>            : //  c5:  ?              ?, B            ?, B</a>
<a name="215"><span class="lineNum">     215 </span>            : //  c6:  ?, B           ?, C            ?, min(B, C)</a>
<a name="216"><span class="lineNum">     216 </span><span class="lineCov">       2489 : FailureOr&lt;std::pair&lt;int64_t, int64_t&gt;&gt; inferMergedDimAndBound(</span></a>
<a name="217"><span class="lineNum">     217 </span>            :     Optional&lt;Location&gt; location, int64_t dim, int64_t leftSize,</a>
<a name="218"><span class="lineNum">     218 </span><span class="lineCov">       2489 :     int64_t rightSize, int64_t leftBound, int64_t rightBound) {</span></a>
<a name="219"><span class="lineNum">     219 </span><span class="lineCov">       2489 :   bool isLeftStaticDim = !isDynamicDimSize(leftSize);</span></a>
<a name="220"><span class="lineNum">     220 </span><span class="lineCov">       2489 :   bool isRightStaticDim = !isDynamicDimSize(rightSize);</span></a>
<a name="221"><span class="lineNum">     221 </span><span class="lineCov">       2489 :   bool isLeftStaticBound = !isDynamicDimSize(leftBound);</span></a>
<a name="222"><span class="lineNum">     222 </span><span class="lineCov">       2489 :   bool isRightStaticBound = !isDynamicDimSize(rightBound);</span></a>
<a name="223"><span class="lineNum">     223 </span><span class="lineCov">       2489 :   int64_t size = ShapedType::kDynamicSize;</span></a>
<a name="224"><span class="lineNum">     224 </span><span class="lineCov">       2489 :   int64_t bound = ShapedType::kDynamicSize;</span></a>
<a name="225"><span class="lineNum">     225 </span>            : </a>
<a name="226"><span class="lineNum">     226 </span><span class="lineCov">       2489 :   if (isLeftStaticDim || isRightStaticDim) {</span></a>
<a name="227"><span class="lineNum">     227 </span><span class="lineCov">       2387 :     if (isLeftStaticDim &amp;&amp; isRightStaticDim &amp;&amp; leftSize != rightSize)</span></a>
<a name="228"><span class="lineNum">     228 </span><span class="lineNoCov">          0 :       return emitOptionalError(location, &quot;Mismatched dimension sizes &quot;,</span></a>
<a name="229"><span class="lineNum">     229 </span>            :                                leftSize, &quot; and &quot;, rightSize, &quot; in dimension &quot;,</a>
<a name="230"><span class="lineNum">     230 </span>            :                                dim);</a>
<a name="231"><span class="lineNum">     231 </span><span class="lineCov">       2387 :     size = isLeftStaticDim ? leftSize : rightSize;</span></a>
<a name="232"><span class="lineNum">     232 </span><span class="lineCov">       2387 :     if (isLeftStaticBound || isRightStaticBound) {</span></a>
<a name="233"><span class="lineNum">     233 </span><span class="lineCov">          8 :       int64_t check_bound = isLeftStaticBound ? leftBound : rightBound;</span></a>
<a name="234"><span class="lineNum">     234 </span><span class="lineCov">          8 :       if (size &gt; check_bound)</span></a>
<a name="235"><span class="lineNum">     235 </span><span class="lineNoCov">          0 :         return emitOptionalError(location, &quot;Mismatched dimension size &quot;, size,</span></a>
<a name="236"><span class="lineNum">     236 </span>            :                                  &quot; and bound &quot;, check_bound, &quot; in dimension &quot;,</a>
<a name="237"><span class="lineNum">     237 </span>            :                                  dim);</a>
<a name="238"><span class="lineNum">     238 </span><span class="lineCov">          8 :     }</span></a>
<a name="239"><span class="lineNum">     239 </span><span class="lineCov">       2387 :   } else {</span></a>
<a name="240"><span class="lineNum">     240 </span><span class="lineCov">        102 :     if (isLeftStaticBound &amp;&amp; isRightStaticBound)</span></a>
<a name="241"><span class="lineNum">     241 </span><span class="lineCov">         18 :       bound = std::min(leftBound, rightBound);</span></a>
<a name="242"><span class="lineNum">     242 </span>            :     else</a>
<a name="243"><span class="lineNum">     243 </span><span class="lineCov">         84 :       bound = isLeftStaticBound ? leftBound : rightBound;</span></a>
<a name="244"><span class="lineNum">     244 </span>            :   }</a>
<a name="245"><span class="lineNum">     245 </span><span class="lineCov">       2489 :   return std::make_pair(size, bound);</span></a>
<a name="246"><span class="lineNum">     246 </span><span class="lineCov">       2489 : }</span></a>
<a name="247"><span class="lineNum">     247 </span>            : </a>
<a name="248"><span class="lineNum">     248 </span>            : // TODO(zhouxin) Refactor to better handle errors and return single type</a>
<a name="249"><span class="lineNum">     249 </span><span class="lineCov">       1638 : LogicalResult inferMostSpecificType(</span></a>
<a name="250"><span class="lineNum">     250 </span>            :     Optional&lt;Location&gt; location, TypeRange inputTypes,</a>
<a name="251"><span class="lineNum">     251 </span><span class="lineCov">       1638 :     SmallVectorImpl&lt;Type&gt;&amp; inferredReturnTypes) {</span></a>
<a name="252"><span class="lineNum">     252 </span><span class="lineCov">       1638 :   SmallVector&lt;RankedTensorType&gt; rankedTypes;</span></a>
<a name="253"><span class="lineNum">     253 </span><span class="lineCov">       4320 :   for (auto inputType : inputTypes)</span></a>
<a name="254"><span class="lineNum">     254 </span><span class="lineCov">       2682 :     if (auto rankedType = inputType.dyn_cast&lt;RankedTensorType&gt;())</span></a>
<a name="255"><span class="lineNum">     255 </span><span class="lineCov">       2682 :       rankedTypes.push_back(rankedType);</span></a>
<a name="256"><span class="lineNum">     256 </span><span class="lineCov">       1638 :   if (rankedTypes.empty()) {</span></a>
<a name="257"><span class="lineNum">     257 </span><span class="lineCov">         14 :     inferredReturnTypes.push_back(inputTypes[0]);</span></a>
<a name="258"><span class="lineNum">     258 </span><span class="lineCov">         14 :     return success();</span></a>
<a name="259"><span class="lineNum">     259 </span>            :   }</a>
<a name="260"><span class="lineNum">     260 </span>            : </a>
<a name="261"><span class="lineNum">     261 </span><span class="lineCov">       1624 :   auto rank = rankedTypes[0].getRank();</span></a>
<a name="262"><span class="lineNum">     262 </span><span class="lineCov">       1624 :   SmallVector&lt;int64_t&gt; inferredSizes(rank, ShapedType::kDynamicSize);</span></a>
<a name="263"><span class="lineNum">     263 </span><span class="lineCov">       1624 :   SmallVector&lt;int64_t&gt; inferredBounds(rank, ShapedType::kDynamicSize);</span></a>
<a name="264"><span class="lineNum">     264 </span><span class="lineCov">       1624 :   bool anyInputHaveBounds = false;</span></a>
<a name="265"><span class="lineNum">     265 </span>            : </a>
<a name="266"><span class="lineNum">     266 </span><span class="lineCov">       4278 :   for (const auto&amp; it : llvm::enumerate(rankedTypes)) {</span></a>
<a name="267"><span class="lineNum">     267 </span><span class="lineCov">       2654 :     RankedTensorType rankedType = it.value();</span></a>
<a name="268"><span class="lineNum">     268 </span><span class="lineCov">       2654 :     ArrayRef&lt;int64_t&gt; bounds = encodingToBounds(rankedType.getEncoding());</span></a>
<a name="269"><span class="lineNum">     269 </span><span class="lineCov">       2654 :     if (!bounds.empty()) anyInputHaveBounds = true;</span></a>
<a name="270"><span class="lineNum">     270 </span>            : </a>
<a name="271"><span class="lineNum">     271 </span><span class="lineCov">       5004 :     for (int dim = 0; dim &lt; rank; ++dim) {</span></a>
<a name="272"><span class="lineNum">     272 </span><span class="lineCov">       2350 :       std::pair&lt;int64_t, int64_t&gt; inferredDimAndBound;</span></a>
<a name="273"><span class="lineNum">     273 </span><span class="lineCov">       2350 :       int64_t leftSize = inferredSizes[dim];</span></a>
<a name="274"><span class="lineNum">     274 </span><span class="lineCov">       2350 :       int64_t rightSize = rankedType.getShape()[dim];</span></a>
<a name="275"><span class="lineNum">     275 </span><span class="lineCov">       2350 :       int64_t leftBound = inferredBounds[dim];</span></a>
<a name="276"><span class="lineNum">     276 </span><span class="lineCov">       4700 :       int64_t rightBound =</span></a>
<a name="277"><span class="lineNum">     277 </span><span class="lineCov">       2350 :           bounds.empty() ? ShapedType::kDynamicSize : bounds[dim];</span></a>
<a name="278"><span class="lineNum">     278 </span>            : </a>
<a name="279"><span class="lineNum">     279 </span><span class="lineCov">       4700 :       auto inferredDimAndBoundOrErr = inferMergedDimAndBound(</span></a>
<a name="280"><span class="lineNum">     280 </span><span class="lineCov">       2350 :           location, dim, leftSize, rightSize, leftBound, rightBound);</span></a>
<a name="281"><span class="lineNum">     281 </span><span class="lineCov">       2350 :       if (failed(inferredDimAndBoundOrErr)) return failure();</span></a>
<a name="282"><span class="lineNum">     282 </span><span class="lineCov">       2350 :       inferredDimAndBound = *inferredDimAndBoundOrErr;</span></a>
<a name="283"><span class="lineNum">     283 </span><span class="lineCov">       2350 :       inferredSizes[dim] = inferredDimAndBound.first;</span></a>
<a name="284"><span class="lineNum">     284 </span><span class="lineCov">       2350 :       inferredBounds[dim] = inferredDimAndBound.second;</span></a>
<a name="285"><span class="lineNum">     285 </span><span class="lineCov">       2350 :     }</span></a>
<a name="286"><span class="lineNum">     286 </span><span class="lineCov">       2654 :   }</span></a>
<a name="287"><span class="lineNum">     287 </span>            : </a>
<a name="288"><span class="lineNum">     288 </span><span class="lineCov">       3248 :   inferredReturnTypes.push_back(RankedTensorType::get(</span></a>
<a name="289"><span class="lineNum">     289 </span><span class="lineCov">       1624 :       inferredSizes, rankedTypes[0].getElementType(),</span></a>
<a name="290"><span class="lineNum">     290 </span><span class="lineCov">       1624 :       boundsToEncoding(</span></a>
<a name="291"><span class="lineNum">     291 </span><span class="lineCov">       1624 :           rankedTypes[0].getEncoding(),</span></a>
<a name="292"><span class="lineNum">     292 </span>            :           // Empty array as argument is an indicator to boundsToEncoding() that</a>
<a name="293"><span class="lineNum">     293 </span>            :           // there are no bounds at all in inputs, thus sparsity attributes will</a>
<a name="294"><span class="lineNum">     294 </span>            :           // be included in the return type</a>
<a name="295"><span class="lineNum">     295 </span><span class="lineCov">       1624 :           anyInputHaveBounds ? inferredBounds : llvm::ArrayRef&lt;int64_t&gt;({}))));</span></a>
<a name="296"><span class="lineNum">     296 </span><span class="lineCov">       1624 :   return success();</span></a>
<a name="297"><span class="lineNum">     297 </span><span class="lineCov">       1638 : }</span></a>
<a name="298"><span class="lineNum">     298 </span>            : </a>
<a name="299"><span class="lineNum">     299 </span>            : }  // namespace hlo</a>
<a name="300"><span class="lineNum">     300 </span>            : }  // namespace mlir</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
